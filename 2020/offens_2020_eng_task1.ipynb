{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "offens_2020_eng_task1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi29jeRMxM_s",
        "colab_type": "code",
        "outputId": "7c19de95-3805-4966-8c7b-a6055ac22e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MESIg6zsxc70",
        "outputId": "19d6bbcc-427d-4296-fba6-3af72969e47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTkjWBstxcf9",
        "outputId": "8ecbafe0-1d5c-4178-ae13-0874f94c9d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import io\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Conv1D, Conv2D\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
        "from keras.layers import average\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Average\n",
        "from keras.layers import Concatenate\n",
        "nltk.download('punkt')\n",
        "from numpy import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "from keras.layers import SpatialDropout1D, concatenate\n",
        "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import top_k_categorical_accuracy\n",
        "#plt.switch_backend('agg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzK80S4F7DdF",
        "colab_type": "code",
        "outputId": "c99f8d15-eed1-40a5-db7d-f2170b378a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install keras_metrics\n",
        "import keras_metrics as km"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRcYiWz-7JZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path='/content/drive/My Drive/offenseval/2020'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_8bCmn7N9f",
        "colab_type": "code",
        "outputId": "c0909899-fce9-407c-d7c7-29c4367175e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "list_df=os.listdir(root_path+\"/chunky\")\n",
        "print(list_df)\n",
        "print(len(list_df))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data_0', 'data_1', 'data_2', 'data_3', 'data_4', 'data_5', 'data_6', 'data_7', 'data_8', 'data_9', 'data_10', 'data_11', 'data_12', 'data_13', 'data_14', 'data_15', 'data_16', 'data_17', 'data_18', 'data_19', 'data_20', 'data_21', 'data_23', 'data_24', 'data_25', 'data_26', 'data_27', 'data_28', 'data_29', 'data_30', 'data_31', 'data_32', 'data_33', 'data_34', 'data_35', 'data_36', 'data_37', 'data_38', 'data_39', 'data_40', 'data_41', 'data_42', 'data_43', 'data_50', 'data_44', 'data_45', 'data_51', 'data_52', 'data_46', 'data_53', 'data_47', 'data_54', 'data_48', 'data_55', 'data_49', 'data_56', 'data_57', 'data_100', 'data_101', 'data_102', 'data_103', 'data_104', 'data_105', 'data_107', 'data_108', 'data_109', 'data_110', 'data_111', 'data_112', 'data_113', 'data_114', 'data_115', 'data_116', 'data_117', 'data_118', 'data_119', 'data_59', 'data_60', 'data_61', 'data_62', 'data_63', 'data_64', 'data_65', 'data_66', 'data_67', 'data_68', 'data_69', 'data_70', 'data_71', 'data_72', 'data_73', 'data_74', 'data_75', 'data_76', 'data_77', 'data_78', 'data_79', 'data_80', 'data_82', 'data_83', 'data_84', 'data_85', 'data_86', 'data_87', 'data_88', 'data_89', 'data_90', 'data_91', 'data_92', 'data_93', 'data_94', 'data_96', 'data_97', 'data_98', 'data_99']\n",
            "115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsZB-Dbp_W1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-EgYbr-98VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dummy=pd.read_csv(root_path+\"/chunky/data_0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "911He1ix_Xc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file_name in list_df:\n",
        "  if file_name != 'data_0':\n",
        "    df_dummy=df_dummy.append(pd.read_csv(root_path+\"/chunky/\"+file_name),ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t66g9pD-DWW",
        "colab_type": "code",
        "outputId": "41ef6cd8-7a86-4896-8804-d91bd4662a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_dummy.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user too much thoughts inside his headdd we c...</td>\n",
              "      <td>0.305954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>first time i heard his name in camp, he seems ...</td>\n",
              "      <td>0.194293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when i go to drink with tsubaki he would alway...</td>\n",
              "      <td>0.295330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user his ass need to stay up :face_with_tears...</td>\n",
              "      <td>0.833349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most important tweet of the day : fuck donald ...</td>\n",
              "      <td>0.564527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     label\n",
              "0  @user too much thoughts inside his headdd we c...  0.305954\n",
              "1  first time i heard his name in camp, he seems ...  0.194293\n",
              "2  when i go to drink with tsubaki he would alway...  0.295330\n",
              "3  @user his ass need to stay up :face_with_tears...  0.833349\n",
              "4  most important tweet of the day : fuck donald ...  0.564527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHxggQHy7a70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from zipfile import ZipFile\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-oZOquV85D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file_name = root_path+\"/task_a_distant.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHgBv7oj9d6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with ZipFile(file_name,'r') as zip:\n",
        "#   zip.printdir()\n",
        "#   zip.extractall(root_path,pwd=b'sem2020-t12')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TBcQvff9sqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data=pd.read_csv('/content/drive/My Drive/offenseval/2020/task_a_distant.tsv',delimiter='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w36B594KIomg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#labels=(data['average']>0.5).astype(int)\n",
        "#print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9aUHs-P2eeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_chunky=np.array_split(train_data,120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyEHBcqAJiap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max_1=0\n",
        "# for i in range(120):\n",
        "#   max_1=max(df_chunky[1].shape[0],max_1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN4ZDA9hIan0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgnJfpX8Ib88",
        "colab_type": "code",
        "outputId": "b5f9b690-8982-42ce-b145-a663cb6047b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# del(train_data)\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4m-I9yDmuJN",
        "colab_type": "text"
      },
      "source": [
        "## Twitter embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TGj5a5ylxOB",
        "colab_type": "code",
        "outputId": "3db7c042-d742-4dda-9ce3-dad07d5c13a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/Sentimix/word2vec_twitter_tokens.bin', binary=True,unicode_errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD-JkrV5m0Vu",
        "colab_type": "code",
        "outputId": "90900649-41b4-413c-ac95-1419fdd88427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model['fuck'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDvTes-Kn62L",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob8t7HZzvFwe",
        "colab_type": "code",
        "outputId": "b50f33ac-3b2d-433e-f7aa-26b6845dad9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !pip install tqdm\n",
        "# from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l0lIDviExdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NH5q2QnTq5",
        "colab_type": "code",
        "outputId": "d4ed7c68-b4be-4995-89ea-7ddedb30cd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def remove_pattern(input_txt, pattern,with_space=False):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    if with_space==False:\n",
        "      for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    else:\n",
        "      for i in r:\n",
        "        input_txt = re.sub(i, ' ', input_txt)\n",
        "    return input_txt \n",
        "!pip install emoji\n",
        "import emoji\n",
        "import pickle\n",
        "import re\n",
        "with open('/content/drive/My Drive/Sentimix/helper_data/contractions.pkl','rb')as f:\n",
        "  contractions=pickle.load(f)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "contractions=Counter(contractions)\n",
        "with open('/content/drive/My Drive/Sentimix/helper_data/acronyms.pkl','rb')as f:\n",
        "  acronyms=pickle.load(f)\n",
        "acronyms=Counter(acronyms)\n",
        "def acronym(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if acronyms[word]!=0:\n",
        "        w_l.append(acronyms[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "# with open('/content/drive/My Drive/Sentimix/hinglish_to_english.pickle','rb')as f:\n",
        "#   hing_to_eng=pickle.load(f)\n",
        "# hing_to_eng=Counter(hing_to_eng)\n",
        "def hindi_se_english(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    w_l=[]\n",
        "    sent=str(df[column][i])\n",
        "    for word in sent.split():\n",
        "      if hing_to_eng[word]!=0:\n",
        "        w_l.append(hing_to_eng[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "# with open('/content/drive/My Drive/Sentimix/Hinglish_utils/Hinglish_Profanity_dict.pkl', 'rb') as handle:\n",
        "#     cuss_dict=pickle.load(handle)\n",
        "# cuss_dict=Counter(cuss_dict)\n",
        "def replace_cuss(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if cuss_dict[word]!=0:\n",
        "        w_l.append('abuse')\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "def remove_contraction(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if contractions[word]!=0:\n",
        "        w_l.append(contractions[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "def remove_pattern_rep(input_txt, pattern,rep_pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "      input_txt = re.sub(i, rep_pattern, input_txt)\n",
        "\n",
        "    return input_txt \n",
        "def cleaning(data_f,cleaning_col,new_col):\n",
        "  data_f.reset_index(drop=True,inplace=True)\n",
        "  for i in tqdm(range(data_f.shape[0])):\n",
        "    data_f[cleaning_col][i]=emoji.demojize(str(data_f[cleaning_col][i]))\n",
        "  #data_f[cleaning_col]=replace_cuss(data_f,cleaning_col)\n",
        "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[cleaning_col],\"_\",with_space=True)\n",
        "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"-\",with_space=True)\n",
        "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\":\",with_space=True)\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"@[\\w]*\",\"<USR>\")\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"http\\S+\",\"<URL>\")\n",
        "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[cleaning_col], \"[0-9]+\",\"<NUM>\")\n",
        "  #data_f[new_col]=hindi_se_english(data_f,cleaning_col)\n",
        "  data_f[new_col]=remove_contraction(data_f,new_col)\n",
        "  data_f[new_col]=acronym(data_f,new_col)\n",
        "  data_f[new_col]=data_f[new_col].str.replace(\"[^a-zA-Z]<>\", \" \")\n",
        "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"~\",with_space=False)\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"!\",with_space=True)\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \".\",with_space=True)\n",
        "  #data_f[new_col] = data_f[new_col].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "  return data_f\n",
        "import numpy as np\n",
        "#a=cleaning(data,'text','clean_col')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p3kwFJpJHtQ",
        "colab_type": "code",
        "outputId": "a0249c7d-c2e7-4c14-c93d-cee9764b27ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# df_chunky[18].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75612, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jZWcngfJFWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp_USuba26I_",
        "colab_type": "code",
        "outputId": "692db3c8-d3cb-40c1-ad73-840df90c4cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# for i in range(96,100):\n",
        "#   print(i)\n",
        "#   a=cleaning(df_chunky[i],'text','clean_col')\n",
        "#   df=pd.DataFrame({'text':a['clean_col'],'label':a['average']})\n",
        "#   df.to_csv('/content/drive/My Drive/offenseval/2020/chunky/data_'+str(i),index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/75611 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  0%|          | 75/75611 [00:00<01:41, 743.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "96\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 75611/75611 [00:56<00:00, 1344.38it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 61150.02it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 59468.28it/s]\n",
            "  0%|          | 131/75611 [00:00<00:57, 1303.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 75611/75611 [00:57<00:00, 1316.93it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 60547.19it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 58265.06it/s]\n",
            "  0%|          | 135/75611 [00:00<00:56, 1346.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 75611/75611 [00:57<00:00, 1306.09it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 59774.23it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 57725.33it/s]\n",
            "  0%|          | 132/75611 [00:00<00:57, 1319.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 75611/75611 [00:56<00:00, 1329.55it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 59982.76it/s]\n",
            "100%|██████████| 75611/75611 [00:01<00:00, 58537.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdajs4zjqiF7",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization and Train test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cUy9gOioPdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8UpRqqXBPp8",
        "colab_type": "code",
        "outputId": "ee1ffa5f-ffb6-4cbf-95bc-e94e87a3b11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_dummy.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8695339, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGOZ-FwXq1-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_train,df_test=train_test_split(df_dummy,test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzfYrErFBWN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=(df_train['label']>=0.5).astype(int)\n",
        "y_test=(df_test['label']>0.5).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHeKckLprUHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_data=pd.DataFrame({'text':a['clean_col'],'labels':labels})\n",
        "# df_data.to_csv(root_path+\"/clean_eng_task_1.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEhsipVdB_Y0",
        "colab_type": "code",
        "outputId": "2d3e7a6e-0111-4c13-a259-df4daa1d47aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan 10 10:37:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40smU_LTHaS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words =100000\n",
        "max_len = 30\n",
        "tok = Tokenizer(max_words)\n",
        "tok.fit_on_texts(df_dummy['text'].astype(str))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTvcgJDxISzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_train = tok.texts_to_sequences(df_train['text'].astype(str))\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "sequences_matrix_train = sequence.pad_sequences(sequences_train,maxlen=max_len,padding='post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbvCd_GDIb9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_dev = tok.texts_to_sequences(df_test['text'].astype(str))\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "sequences_matrix_dev = sequence.pad_sequences(sequences_dev,maxlen=max_len,padding='post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AlHf383IfzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_S9zYeaIjCZ",
        "colab_type": "text"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB_DuGFzIiM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open(os.path.join('/content/drive/My Drive/IR_project/glove.6B', 'glove.6B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnExMh9BIrIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index=tok.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYbissiIs43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix_1 = np.zeros([max_words + 1, 300])\n",
        "for word, i in tok.word_index.items():\n",
        "    if word in embeddings_index.keys():\n",
        "      if i>max_words:\n",
        "        break\n",
        "      embedding_matrix_1[i] = embeddings_index[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ow_LVZCIugP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Concatenate\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rVZCNKIwOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.layers import CuDNNGRU,CuDNNLSTM,GlobalMaxPooling1D,GlobalAveragePooling1D\n",
        "from sklearn.utils import class_weight\n",
        "class Attention(Layer):\n",
        "    def __init__(self,step_dim=20,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, Dropout\n",
        "\n",
        "#max_len=\n",
        "\n",
        "def BidLstm(maxlen, max_features, embed_size):\n",
        "    inp1 = Input(shape=(maxlen, ))\n",
        "    #inp2=Input(shape=(1,))\n",
        "    #x=Embedding(len(word_index)+1,embed_size)(inp1)\n",
        "    x1 = Embedding(max_words + 1,embed_size,weights=[embedding_matrix_1],\n",
        "                  trainable=True)(inp1)\n",
        "    # x2 = Embedding(len(tok.word_index) + 1,embed_size_2,weights=[embedding_matrix_2],\n",
        "    #                trainable=True)(inp1)\n",
        "    # x3 = Embedding(len(tok.word_index) + 1,embed_size_3,weights=[embedding_matrix_3],\n",
        "    #                trainable=True)(inp1)\n",
        "    # x1 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x1)\n",
        "    # x2 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x2)\n",
        "    # x3 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x3)   \n",
        "    # x1 = Attention(maxlen)(x1)\n",
        "    # x2 = Attention(maxlen)(x2)\n",
        "    # x3 = Attention(maxlen)(x3)\n",
        "    # x=  Concatenate()([x1,x2,x3])\n",
        "    x1 = CuDNNLSTM(200, return_sequences=True)(x1)   \n",
        "    x2=  GlobalMaxPooling1D()(x1)\n",
        "    x3= GlobalAveragePooling1D()(x1)\n",
        "    x=  Concatenate()([x2,x3])\n",
        "    x = Dropout(0.1)(x)\n",
        "    #x = Attention(maxlen)(x)\n",
        "    # layer = Dense(600,name='FC1')(x)\n",
        "    # layer = Dense(300,activation='relu')(layer)\n",
        "    layer = Dense(128,activation='relu')(x)\n",
        " #   layer = BatchNormalization(name = 'BN1')(layer)\n",
        "    #layer = Activation('relu')(layer)\n",
        "    #layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(64,name='FC2')(layer)\n",
        "#    layer = BatchNormalization(name = 'BN2')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "   # layer=  Concatenate()([layer,inp2])\n",
        "    # layer=Dense(256,activation='relu')(layer)\n",
        "    # layer=Dense(128,activation='relu')(layer)\n",
        "    layer = Dense(1,name='out_layer',activation='sigmoid')(layer)\n",
        "\n",
        "    model = Model(inputs=[inp1],outputs=layer)\n",
        "\n",
        "    return model\n",
        "model_bi=BidLstm(max_len,max_features=max_words,embed_size=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVuU-dqQI0kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_bi.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc',km.f1_score()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MOxZ2KlI3XQ",
        "colab_type": "code",
        "outputId": "8660709f-cca2-4482-95f9-8153aa65dc7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "model_bi.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 30)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 30, 300)      30000300    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)        (None, 30, 200)      401600      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 200)          0           cu_dnnlstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 200)          0           cu_dnnlstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 400)          0           global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 400)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          51328       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "FC2 (Dense)                     (None, 64)           8256        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64)           0           FC2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64)           0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "out_layer (Dense)               (None, 1)            65          dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 30,461,549\n",
            "Trainable params: 30,461,549\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSjy1UG5I5C5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ig7ivSoI7BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp_filepath='/content/drive/My Drive/offenseval/'+'checkpoints/lstm_model_2020a.h5'\n",
        "cp_check_point=keras.callbacks.ModelCheckpoint(cp_filepath, monitor='val_f1_score', verbose=0, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
        "es = EarlyStopping(monitor='val_f1_score', mode='max', min_delta=0,patience=2,restore_best_weights=True)\n",
        "reduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiaFhksjI-EZ",
        "colab_type": "code",
        "outputId": "b64424d7-0c33-45e2-9f40-2c6a15c448cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model_bi.fit([sequences_matrix_train],y_train,validation_data=([sequences_matrix_dev],y_test),epochs=10,batch_size=1024,class_weight=class_weights,callbacks=[es,cp_check_point])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7825805 samples, validate on 869534 samples\n",
            "Epoch 1/10\n",
            "7825805/7825805 [==============================] - 253s 32us/step - loss: 0.1227 - acc: 0.9501 - f1_score: 0.8599 - val_loss: 0.1015 - val_acc: 0.9584 - val_f1_score: 0.8808\n",
            "Epoch 2/10\n",
            "7825805/7825805 [==============================] - 253s 32us/step - loss: 0.0964 - acc: 0.9605 - f1_score: 0.8867 - val_loss: 0.0975 - val_acc: 0.9607 - val_f1_score: 0.8868\n",
            "Epoch 3/10\n",
            "7825805/7825805 [==============================] - 253s 32us/step - loss: 0.0838 - acc: 0.9653 - f1_score: 0.8997 - val_loss: 0.0904 - val_acc: 0.9634 - val_f1_score: 0.8933\n",
            "Epoch 4/10\n",
            "7825805/7825805 [==============================] - 253s 32us/step - loss: 0.0722 - acc: 0.9702 - f1_score: 0.9130 - val_loss: 0.1014 - val_acc: 0.9621 - val_f1_score: 0.8899\n",
            "Epoch 5/10\n",
            "7825805/7825805 [==============================] - 253s 32us/step - loss: 0.0623 - acc: 0.9744 - f1_score: 0.9244 - val_loss: 0.1027 - val_acc: 0.9634 - val_f1_score: 0.8925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe916cd13c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LETjIZuJBiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds_dl=model_bi.predict(sequences_matrix_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdU00r0WJvzV",
        "colab_type": "code",
        "outputId": "58ac5bc9-17f9-4371-9745-cef747d4c76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#y_pred = model_bi.predict(X_dev, batch_size=30, verbose=1)\n",
        "\n",
        "print(classification_report(y_test, y_preds_dl.round()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98    730838\n",
            "           1       0.84      0.96      0.89    138696\n",
            "\n",
            "    accuracy                           0.96    869534\n",
            "   macro avg       0.91      0.96      0.94    869534\n",
            "weighted avg       0.97      0.96      0.96    869534\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kz3eI_JyTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}