{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "offens_2020_danish.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asking28/offenseval2020/blob/master/offens_2020_danish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0BLcJep5y5Z",
        "colab_type": "code",
        "outputId": "d62a34d2-6d14-47b8-c1d9-a4ac745ea974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAypiho1V6pr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a2a37ee-928c-4766-b01d-5b9fd0c93ef3"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhHvBtlLvj1a",
        "colab_type": "code",
        "outputId": "2baf06c2-946e-4f1c-8124-b041796ef0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-tcn==2.8.3\n",
        "!pip install keras-multi-head\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-tcn==2.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.18.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-2.8.3\n",
            "Collecting keras-multi-head\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (1.18.2)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (2.3.1)\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.1.0)\n",
            "Building wheels for collected packages: keras-multi-head, keras-self-attention\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=bcf41dd16a4d1e6443b14ef4c5ebcc03a0452ba04ab3ed4e5813344ec64c061a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=b891999bd64cb1c72dfd01897d603ee56f5e0886ec67731ea9ca533298551a5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-multi-head keras-self-attention\n",
            "Installing collected packages: keras-self-attention, keras-multi-head\n",
            "Successfully installed keras-multi-head-0.22.0 keras-self-attention-0.41.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3mWlV357Bw",
        "colab_type": "code",
        "outputId": "fd8c1941-e19c-404e-c6de-d673eee65000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import io\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Conv1D, Conv2D\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
        "from keras.layers import average\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Average\n",
        "from keras.layers import Concatenate\n",
        "nltk.download('punkt')\n",
        "from numpy import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "from keras.layers import SpatialDropout1D, concatenate\n",
        "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import top_k_categorical_accuracy\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from keras_multi_head import MultiHeadAttention\n",
        "from keras_multi_head import MultiHead\n",
        "#plt.switch_backend('agg')\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ZRPEX16GqP",
        "colab_type": "code",
        "outputId": "2a54a84f-8d38-4e3a-edfa-99f73e92db0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install keras_metrics\n",
        "import keras_metrics as km"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.18.2)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU4vkM4u6Wln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "root_path='/content/drive/My Drive/offenseval/2020'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWhJIr16hwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=pd.read_csv(root_path+'/non_english_data/Danish/offenseval-da-training-v1.tsv',delimiter='\\t',quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f0kkyko-uv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data=pd.read_csv(root_path+'/non_english_data/Danish/offenseval-da-test-v1-nolabels.tsv',delimiter='\\t',quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmjDV4MfikiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_labels=pd.read_csv(root_path+'/non_english_data/Danish/danish-goldlabels.csv',header=None,quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQPlZ_Y2-33f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(root_path+'/non_english_data/Danish/offenseval-da-test-v1-nolabels.tsv','r') as f:\n",
        "#   lines=f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc636TWCABvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFlhPGsD_jSP",
        "colab_type": "code",
        "outputId": "db7c9a10-fd4e-4c76-8d6d-a2e98c68a89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(329, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kJeDyJS_rnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ7OozNa7iOJ",
        "colab_type": "code",
        "outputId": "b8ebad48-a12b-41d3-9528-183292518966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "print(train_data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id                                              tweet subtask_a\n",
            "0  3131  Jeg tror det vil være dejlig køligt, men jeg v...       NOT\n",
            "1   711  Så kommer de nok til at investere i en ny cyke...       NOT\n",
            "2  2500  Nu er det jo også de Ikea-aber der har lavet s...       OFF\n",
            "3  2678  128 Varme emails, er vi enige om at det er sex...       NOT\n",
            "4   784  Desværre tyder det på, at amerikanerne er helt...       NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gILGZUQ099gv",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoF5hph99Pt",
        "colab_type": "code",
        "outputId": "8dac4278-586b-49d5-97bd-6772930820c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.38.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgmvM4P3-CA6",
        "colab_type": "code",
        "outputId": "8ecc77b7-16b8-41f0-95a6-ae35d7fc0c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def remove_pattern(input_txt, pattern,with_space=False):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    if with_space==False:\n",
        "      for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    else:\n",
        "      for i in r:\n",
        "        input_txt = re.sub(i, ' ', input_txt)\n",
        "    return input_txt \n",
        "!pip install emoji\n",
        "import emoji\n",
        "import pickle\n",
        "import re\n",
        "with open('/content/drive/My Drive/Sentimix/helper_data/contractions.pkl','rb')as f:\n",
        "  contractions=pickle.load(f)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "contractions=Counter(contractions)\n",
        "with open('/content/drive/My Drive/Sentimix/helper_data/acronyms.pkl','rb')as f:\n",
        "  acronyms=pickle.load(f)\n",
        "acronyms=Counter(acronyms)\n",
        "def acronym(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if acronyms[word]!=0:\n",
        "        w_l.append(acronyms[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "# with open('/content/drive/My Drive/Sentimix/hinglish_to_english.pickle','rb')as f:\n",
        "#   hing_to_eng=pickle.load(f)\n",
        "# hing_to_eng=Counter(hing_to_eng)\n",
        "def hindi_se_english(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    w_l=[]\n",
        "    sent=str(df[column][i])\n",
        "    for word in sent.split():\n",
        "      if hing_to_eng[word]!=0:\n",
        "        w_l.append(hing_to_eng[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "# with open('/content/drive/My Drive/Sentimix/Hinglish_utils/Hinglish_Profanity_dict.pkl', 'rb') as handle:\n",
        "#     cuss_dict=pickle.load(handle)\n",
        "# cuss_dict=Counter(cuss_dict)\n",
        "def replace_cuss(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if cuss_dict[word]!=0:\n",
        "        w_l.append('abuse')\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "def remove_contraction(df,column):\n",
        "  s_l=[]\n",
        "  for i in tqdm(range(df.shape[0])):\n",
        "    sent=str(df[column][i]).lower()\n",
        "    w_l=[]\n",
        "    for word in sent.split():\n",
        "      if contractions[word]!=0:\n",
        "        w_l.append(contractions[word])\n",
        "      else:\n",
        "        w_l.append(word)\n",
        "    s_l.append(' '.join(w_l))\n",
        "  return s_l\n",
        "def remove_pattern_rep(input_txt, pattern,rep_pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "      input_txt = re.sub(i, rep_pattern, input_txt)\n",
        "\n",
        "    return input_txt \n",
        "def cleaning(data_f,cleaning_col,new_col):\n",
        "  data_f.reset_index(drop=True,inplace=True)\n",
        "  for i in tqdm(range(data_f.shape[0])):\n",
        "    data_f[cleaning_col][i]=emoji.demojize(str(data_f[cleaning_col][i]))\n",
        "  #data_f[cleaning_col]=replace_cuss(data_f,cleaning_col)\n",
        "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[cleaning_col],\"_\",with_space=True)\n",
        "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"-\",with_space=True)\n",
        "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\":\",with_space=True)\n",
        "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"@[\\w]*\",\"<USR>\")\n",
        "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"http\\S+\",\"<URL>\")\n",
        "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[cleaning_col], \"[0-9]+\",\"<NUM>\")\n",
        "  #data_f[new_col]=hindi_se_english(data_f,cleaning_col)\n",
        "  data_f[new_col]=remove_contraction(data_f,new_col)\n",
        "  data_f[new_col]=acronym(data_f,new_col)\n",
        "  data_f[new_col]=data_f[new_col].str.replace(\"[^a-zA-Z]<>\", \" \")\n",
        "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"~\",with_space=False)\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"!\",with_space=True)\n",
        "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \".\",with_space=True)\n",
        "  #data_f[new_col] = data_f[new_col].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "  return data_f\n",
        "import numpy as np\n",
        "#a=cleaning(data,'text','clean_col')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=0d71875da7275c1a9753b6a1e5d19ad52dfea85056145f330f43deb3ebf43205\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7KFLqDW-Qv5",
        "colab_type": "code",
        "outputId": "238ee1f6-7a78-4ac8-ef9f-0b1a2b48851e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data=cleaning(train_data,'tweet','clean_col')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2961/2961 [00:01<00:00, 2146.92it/s]\n",
            "100%|██████████| 2961/2961 [00:00<00:00, 30811.55it/s]\n",
            "100%|██████████| 2961/2961 [00:00<00:00, 26768.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W206RnsxAUvB",
        "colab_type": "code",
        "outputId": "fc637532-a7f8-4bee-fd04-5ca537c7693b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test_data=cleaning(test_data,'tweet','clean_col')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/329 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "100%|██████████| 329/329 [00:00<00:00, 2604.38it/s]\n",
            "100%|██████████| 329/329 [00:00<00:00, 24928.66it/s]\n",
            "100%|██████████| 329/329 [00:00<00:00, 22636.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMf96xQZAc8z",
        "colab_type": "code",
        "outputId": "9b5054af-7189-4294-aeff-3668cb727c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import re, random\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "to_sample = False # if you're impatient switch this flag\n",
        "\n",
        "def spacy_tokenize(text):\n",
        "    return [token.text for token in nlp.tokenizer(text)]\n",
        "    \n",
        "def dameraulevenshtein(seq1, seq2):\n",
        "    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n",
        "    This method has not been modified from the original.\n",
        "    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n",
        "    This distance is the number of additions, deletions, substitutions,\n",
        "    and transpositions needed to transform the first sequence into the\n",
        "    second. Although generally used with strings, any sequences of\n",
        "    comparable objects will work.\n",
        "    Transpositions are exchanges of *consecutive* characters; all other\n",
        "    operations are self-explanatory.\n",
        "    This implementation is O(N*M) time and O(M) space, for N and M the\n",
        "    lengths of the two sequences.\n",
        "    >>> dameraulevenshtein('ba', 'abc')\n",
        "    2\n",
        "    >>> dameraulevenshtein('fee', 'deed')\n",
        "    2\n",
        "    It works with arbitrary sequences too:\n",
        "    >>> dameraulevenshtein('abcd', ['b', 'a', 'c', 'd', 'e'])\n",
        "    2\n",
        "    \"\"\"\n",
        "    # codesnippet:D0DE4716-B6E6-4161-9219-2903BF8F547F\n",
        "    # Conceptually, this is based on a len(seq1) + 1 * len(seq2) + 1 matrix.\n",
        "    # However, only the current and two previous rows are needed at once,\n",
        "    # so we only store those.\n",
        "    oneago = None\n",
        "    thisrow = list(range(1, len(seq2) + 1)) + [0]\n",
        "    for x in range(len(seq1)):\n",
        "        # Python lists wrap around for negative indices, so put the\n",
        "        # leftmost column at the *end* of the list. This matches with\n",
        "        # the zero-indexed strings and saves extra calculation.\n",
        "        twoago, oneago, thisrow = (oneago, thisrow, [0] * len(seq2) + [x + 1])\n",
        "        for y in range(len(seq2)):\n",
        "            delcost = oneago[y] + 1\n",
        "            addcost = thisrow[y - 1] + 1\n",
        "            subcost = oneago[y - 1] + (seq1[x] != seq2[y])\n",
        "            thisrow[y] = min(delcost, addcost, subcost)\n",
        "            # This block deals with transpositions\n",
        "            if (x > 0 and y > 0 and seq1[x] == seq2[y - 1]\n",
        "                    and seq1[x - 1] == seq2[y] and seq1[x] != seq2[y]):\n",
        "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
        "    return thisrow[len(seq2) - 1]\n",
        "\n",
        "\n",
        "class SymSpell:\n",
        "    def __init__(self, max_edit_distance=3, verbose=0):\n",
        "        self.max_edit_distance = max_edit_distance\n",
        "        self.verbose = verbose\n",
        "        # 0: top suggestion\n",
        "        # 1: all suggestions of smallest edit distance\n",
        "        # 2: all suggestions <= max_edit_distance (slower, no early termination)\n",
        "\n",
        "        self.dictionary = {}\n",
        "        self.longest_word_length = 0\n",
        "\n",
        "    def get_deletes_list(self, w):\n",
        "        \"\"\"given a word, derive strings with up to max_edit_distance characters\n",
        "           deleted\"\"\"\n",
        "\n",
        "        deletes = []\n",
        "        queue = [w]\n",
        "        for d in range(self.max_edit_distance):\n",
        "            temp_queue = []\n",
        "            for word in queue:\n",
        "                if len(word) > 1:\n",
        "                    for c in range(len(word)):  # character index\n",
        "                        word_minus_c = word[:c] + word[c + 1:]\n",
        "                        if word_minus_c not in deletes:\n",
        "                            deletes.append(word_minus_c)\n",
        "                        if word_minus_c not in temp_queue:\n",
        "                            temp_queue.append(word_minus_c)\n",
        "            queue = temp_queue\n",
        "\n",
        "        return deletes\n",
        "\n",
        "    def create_dictionary_entry(self, w):\n",
        "        '''add word and its derived deletions to dictionary'''\n",
        "        # check if word is already in dictionary\n",
        "        # dictionary entries are in the form: (list of suggested corrections,\n",
        "        # frequency of word in corpus)\n",
        "        new_real_word_added = False\n",
        "        if w in self.dictionary:\n",
        "            # increment count of word in corpus\n",
        "            self.dictionary[w] = (self.dictionary[w][0], self.dictionary[w][1] + 1)\n",
        "        else:\n",
        "            self.dictionary[w] = ([], 1)\n",
        "            self.longest_word_length = max(self.longest_word_length, len(w))\n",
        "\n",
        "        if self.dictionary[w][1] == 1:\n",
        "            # first appearance of word in corpus\n",
        "            # n.b. word may already be in dictionary as a derived word\n",
        "            # (deleting character from a real word)\n",
        "            # but counter of frequency of word in corpus is not incremented\n",
        "            # in those cases)\n",
        "            new_real_word_added = True\n",
        "            deletes = self.get_deletes_list(w)\n",
        "            for item in deletes:\n",
        "                if item in self.dictionary:\n",
        "                    # add (correct) word to delete's suggested correction list\n",
        "                    self.dictionary[item][0].append(w)\n",
        "                else:\n",
        "                    # note frequency of word in corpus is not incremented\n",
        "                    self.dictionary[item] = ([w], 0)\n",
        "\n",
        "        return new_real_word_added\n",
        "\n",
        "    def create_dictionary_from_arr(self, arr, token_pattern=r'[a-z]+'):\n",
        "        total_word_count = 0\n",
        "        unique_word_count = 0\n",
        "\n",
        "        for line in arr:\n",
        "            # separate by words by non-alphabetical characters\n",
        "            words = re.findall(token_pattern, line.lower())\n",
        "            for word in words:\n",
        "                total_word_count += 1\n",
        "                if self.create_dictionary_entry(word):\n",
        "                    unique_word_count += 1\n",
        "\n",
        "        print(\"total words processed: %i\" % total_word_count)\n",
        "        print(\"total unique words in corpus: %i\" % unique_word_count)\n",
        "        print(\"total items in dictionary (corpus words and deletions): %i\" % len(self.dictionary))\n",
        "        print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
        "        print(\"  length of longest word in corpus: %i\" % self.longest_word_length)\n",
        "        return self.dictionary\n",
        "\n",
        "    def create_dictionary(self, fname):\n",
        "        total_word_count = 0\n",
        "        unique_word_count = 0\n",
        "\n",
        "        with open(fname) as file:\n",
        "            for line in file:\n",
        "                # separate by words by non-alphabetical characters\n",
        "                words = re.findall('[a-z]+', line.lower())\n",
        "                for word in words:\n",
        "                    total_word_count += 1\n",
        "                    if self.create_dictionary_entry(word):\n",
        "                        unique_word_count += 1\n",
        "\n",
        "        print(\"total words processed: %i\" % total_word_count)\n",
        "        print(\"total unique words in corpus: %i\" % unique_word_count)\n",
        "        print(\"total items in dictionary (corpus words and deletions): %i\" % len(self.dictionary))\n",
        "        print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
        "        print(\"  length of longest word in corpus: %i\" % self.longest_word_length)\n",
        "        return self.dictionary\n",
        "\n",
        "    def get_suggestions(self, string, silent=False):\n",
        "        \"\"\"return list of suggested corrections for potentially incorrectly\n",
        "           spelled word\"\"\"\n",
        "        if (len(string) - self.longest_word_length) > self.max_edit_distance:\n",
        "            if not silent:\n",
        "                print(\"no items in dictionary within maximum edit distance\")\n",
        "            return []\n",
        "\n",
        "        suggest_dict = {}\n",
        "        min_suggest_len = float('inf')\n",
        "\n",
        "        queue = [string]\n",
        "        q_dictionary = {}  # items other than string that we've checked\n",
        "\n",
        "        while len(queue) > 0:\n",
        "            q_item = queue[0]  # pop\n",
        "            queue = queue[1:]\n",
        "\n",
        "            # early exit\n",
        "            if ((self.verbose < 2) and (len(suggest_dict) > 0) and\n",
        "                    ((len(string) - len(q_item)) > min_suggest_len)):\n",
        "                break\n",
        "\n",
        "            # process queue item\n",
        "            if (q_item in self.dictionary) and (q_item not in suggest_dict):\n",
        "                if self.dictionary[q_item][1] > 0:\n",
        "                    # word is in dictionary, and is a word from the corpus, and\n",
        "                    # not already in suggestion list so add to suggestion\n",
        "                    # dictionary, indexed by the word with value (frequency in\n",
        "                    # corpus, edit distance)\n",
        "                    # note q_items that are not the input string are shorter\n",
        "                    # than input string since only deletes are added (unless\n",
        "                    # manual dictionary corrections are added)\n",
        "                    assert len(string) >= len(q_item)\n",
        "                    suggest_dict[q_item] = (self.dictionary[q_item][1],\n",
        "                                            len(string) - len(q_item))\n",
        "                    # early exit\n",
        "                    if (self.verbose < 2) and (len(string) == len(q_item)):\n",
        "                        break\n",
        "                    elif (len(string) - len(q_item)) < min_suggest_len:\n",
        "                        min_suggest_len = len(string) - len(q_item)\n",
        "\n",
        "                # the suggested corrections for q_item as stored in\n",
        "                # dictionary (whether or not q_item itself is a valid word\n",
        "                # or merely a delete) can be valid corrections\n",
        "                for sc_item in self.dictionary[q_item][0]:\n",
        "                    if sc_item not in suggest_dict:\n",
        "\n",
        "                        # compute edit distance\n",
        "                        # suggested items should always be longer\n",
        "                        # (unless manual corrections are added)\n",
        "                        assert len(sc_item) > len(q_item)\n",
        "\n",
        "                        # q_items that are not input should be shorter\n",
        "                        # than original string\n",
        "                        # (unless manual corrections added)\n",
        "                        assert len(q_item) <= len(string)\n",
        "\n",
        "                        if len(q_item) == len(string):\n",
        "                            assert q_item == string\n",
        "                            item_dist = len(sc_item) - len(q_item)\n",
        "\n",
        "                        # item in suggestions list should not be the same as\n",
        "                        # the string itself\n",
        "                        assert sc_item != string\n",
        "\n",
        "                        # calculate edit distance using, for example,\n",
        "                        # Damerau-Levenshtein distance\n",
        "                        item_dist = dameraulevenshtein(sc_item, string)\n",
        "\n",
        "                        # do not add words with greater edit distance if\n",
        "                        # verbose setting not on\n",
        "                        if (self.verbose < 2) and (item_dist > min_suggest_len):\n",
        "                            pass\n",
        "                        elif item_dist <= self.max_edit_distance:\n",
        "                            assert sc_item in self.dictionary  # should already be in dictionary if in suggestion list\n",
        "                            suggest_dict[sc_item] = (self.dictionary[sc_item][1], item_dist)\n",
        "                            if item_dist < min_suggest_len:\n",
        "                                min_suggest_len = item_dist\n",
        "\n",
        "                        # depending on order words are processed, some words\n",
        "                        # with different edit distances may be entered into\n",
        "                        # suggestions; trim suggestion dictionary if verbose\n",
        "                        # setting not on\n",
        "                        if self.verbose < 2:\n",
        "                            suggest_dict = {k: v for k, v in suggest_dict.items() if v[1] <= min_suggest_len}\n",
        "\n",
        "            # now generate deletes (e.g. a substring of string or of a delete)\n",
        "            # from the queue item\n",
        "            # as additional items to check -- add to end of queue\n",
        "            assert len(string) >= len(q_item)\n",
        "\n",
        "            # do not add words with greater edit distance if verbose setting\n",
        "            # is not on\n",
        "            if (self.verbose < 2) and ((len(string) - len(q_item)) > min_suggest_len):\n",
        "                pass\n",
        "            elif (len(string) - len(q_item)) < self.max_edit_distance and len(q_item) > 1:\n",
        "                for c in range(len(q_item)):  # character index\n",
        "                    word_minus_c = q_item[:c] + q_item[c + 1:]\n",
        "                    if word_minus_c not in q_dictionary:\n",
        "                        queue.append(word_minus_c)\n",
        "                        q_dictionary[word_minus_c] = None  # arbitrary value, just to identify we checked this\n",
        "\n",
        "        # queue is now empty: convert suggestions in dictionary to\n",
        "        # list for output\n",
        "        if not silent and self.verbose != 0:\n",
        "            print(\"number of possible corrections: %i\" % len(suggest_dict))\n",
        "            print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
        "\n",
        "        # output option 1\n",
        "        # sort results by ascending order of edit distance and descending\n",
        "        # order of frequency\n",
        "        #     and return list of suggested word corrections only:\n",
        "        # return sorted(suggest_dict, key = lambda x:\n",
        "        #               (suggest_dict[x][1], -suggest_dict[x][0]))\n",
        "\n",
        "        # output option 2\n",
        "        # return list of suggestions with (correction,\n",
        "        #                                  (frequency in corpus, edit distance)):\n",
        "        as_list = suggest_dict.items()\n",
        "        # outlist = sorted(as_list, key=lambda (term, (freq, dist)): (dist, -freq))\n",
        "        outlist = sorted(as_list, key=lambda x: (x[1][1], -x[1][0]))\n",
        "\n",
        "        if self.verbose == 0:\n",
        "            return outlist[0]\n",
        "        else:\n",
        "            return outlist\n",
        "\n",
        "        '''\n",
        "        Option 1:\n",
        "        ['file', 'five', 'fire', 'fine', ...]\n",
        "        Option 2:\n",
        "        [('file', (5, 0)),\n",
        "         ('five', (67, 1)),\n",
        "         ('fire', (54, 1)),\n",
        "         ('fine', (17, 1))...]  \n",
        "        '''\n",
        "\n",
        "    def best_word(self, s, silent=False):\n",
        "        try:\n",
        "            return self.get_suggestions(s, silent)[0]\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "def spell_corrector(word_list, words_d) -> str:\n",
        "    result_list = []\n",
        "    for word in word_list:\n",
        "        if word not in words_d:\n",
        "            suggestion = ss.best_word(word, silent=True)\n",
        "            if suggestion is not None:\n",
        "                result_list.append(suggestion)\n",
        "        else:\n",
        "            result_list.append(word)\n",
        "            \n",
        "    return \" \".join(result_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # build symspell tree \n",
        "    ss = SymSpell(max_edit_distance=2)\n",
        "    \n",
        "    # fetch list of bad words\n",
        "    with open('/content/drive/My Drive/offenseval/2020/cleaner_data/bad-words.csv') as bf:\n",
        "        bad_words = bf.readlines()\n",
        "    bad_words = [word.strip() for word in bad_words]    \n",
        "    \n",
        "    # fetch english words dictionary\n",
        "    with open('/content/drive/My Drive/offenseval/2020/cleaner_data/english_words_479k.txt') as f:\n",
        "        words = f.readlines()\n",
        "    eng_words = [word.strip() for word in words]\n",
        "    \n",
        "    # Print some examples\n",
        "    print(eng_words[:5])\n",
        "    print(bad_words[:5])\n",
        "\n",
        "    print('Total english words: {}'.format(len(eng_words)))\n",
        "    print('Total bad words: {}'.format(len(bad_words)))\n",
        "    \n",
        "    print('create symspell dict...')\n",
        "    \n",
        "    if to_sample:\n",
        "        # sampling from list for kernel runtime\n",
        "        sample_idxs = random.sample(range(len(eng_words)), 100)\n",
        "        eng_words = [eng_words[i] for i in sorted(sample_idxs)] + \\\n",
        "            'to infinity and beyond'.split() # make sure our sample misspell is in there\n",
        "    \n",
        "    all_words_list = list(set(bad_words + eng_words))\n",
        "    silence = ss.create_dictionary_from_arr(all_words_list, token_pattern=r'.+')\n",
        "    \n",
        "    # create a dictionary of rightly spelled words for lookup\n",
        "    words_dict = {k: 0 for k in all_words_list}\n",
        "    \n",
        "    sample_text = 'to infifity and byond'\n",
        "    \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2', '1080', '&c', '10-point', '10th']\n",
            "['jigaboo', 'mound of venus', 'asslover', 's&m', 'queaf']\n",
            "Total english words: 466544\n",
            "Total bad words: 1617\n",
            "create symspell dict...\n",
            "total words processed: 467594\n",
            "total unique words in corpus: 467394\n",
            "total items in dictionary (corpus words and deletions): 20250415\n",
            "  edit distance for deletions: 2\n",
            "  length of longest word in corpus: 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyiZpLVAAtfQ",
        "colab_type": "code",
        "outputId": "5f341bfa-c62a-4fe0-a9a3-e18864cbb2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_data['tokens'] = test_data['clean_col'].apply(spacy_tokenize)\n",
        "    \n",
        "print('run spell checker...')\n",
        "print()\n",
        "#print('original text: ' + sample_text)\n",
        "print()\n",
        "test_data['clean'] = test_data.apply(lambda row:spell_corrector(row['tokens'],words_dict),axis=1)\n",
        "#print('corrected text: ' + correct_text)\n",
        "\n",
        "print('Done.')  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run spell checker...\n",
            "\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MvVfKANAyiM",
        "colab_type": "code",
        "outputId": "158a9ba2-15f6-47f2-9432-6f8eed3a7ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_data['tokens'] = train_data['clean_col'].apply(spacy_tokenize)\n",
        "    \n",
        "print('run spell checker...')\n",
        "print()\n",
        "#print('original text: ' + sample_text)\n",
        "print()\n",
        "train_data['clean'] = train_data.apply(lambda row:spell_corrector(row['tokens'],words_dict),axis=1)\n",
        "#print('corrected text: ' + correct_text)\n",
        "\n",
        "print('Done.')  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run spell checker...\n",
            "\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmKLSZ1ZCmlr",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization and Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAYPsuH7Cwqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1lQnedCazcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgRrcqFTa8JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG69bfBpCmCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train,df_dev=train_test_split(train_data,test_size=0.1,random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwwGLvpC0MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=(df_train['subtask_a']==\"OFF\").astype(int)\n",
        "y_dev=(df_dev['subtask_a']==\"OFF\").astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdqoLiIqj2cH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f78c8f01-57c5-4911-98d9-57a071aef2b0"
      },
      "source": [
        "test_data_labels.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1382</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1384</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>547</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1269</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1695</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1\n",
              "0  1382  NOT\n",
              "1  1384  NOT\n",
              "2   547  NOT\n",
              "3  1269  NOT\n",
              "4  1695  OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2F2ttOpjxkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=(test_data_labels[1]==\"OFF\").astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Y2drVDDMOJ",
        "colab_type": "code",
        "outputId": "4e27d680-fd10-407c-d6dd-da21cab8370a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_data.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2961, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeSkMR5rDFGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words =3000\n",
        "max_len = 45\n",
        "tok = Tokenizer(max_words)\n",
        "tok.fit_on_texts(train_data['clean'].astype(str))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECe8Cw7PDWzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_train = tok.texts_to_sequences(df_train['clean'].astype(str))\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "sequences_matrix_train = sequence.pad_sequences(sequences_train,maxlen=max_len,padding='post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97BorB4kDgyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_dev = tok.texts_to_sequences(df_dev['clean'].astype(str))\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "sequences_matrix_dev = sequence.pad_sequences(sequences_dev,maxlen=max_len,padding='post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xni5tuPKkC6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_test = tok.texts_to_sequences(test_data['clean'].astype(str))\n",
        "# vocab_size = len(tok.word_index) + 1\n",
        "sequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len,padding='post',truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IoEQG-rDlwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gK1z32GN_O",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0R0kDUkGMNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index=tok.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckaNnpbVGbjo",
        "colab_type": "code",
        "outputId": "20cab8db-b04d-43c1-8f99-74918cda431d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(word_index)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': 1, 'er': 2, 'det': 3, 'at': 4, 'i': 5, 'original': 6, 'gangster': 7, 'en': 8, 'jeg': 9, 'p': 10, 'kike': 11, 'de': 12, 'there': 13, 'until': 14, 'for': 15, 's': 16, 'med': 17, 'hear': 18, 'den': 19, 'aface': 20, 'som': 21, 'kan': 22, 'num': 23, 'du': 24, 'et': 25, 'vi': 26, 'men': 27, 'man': 28, 'e': 29, 'om': 30, 'var': 31, 'skal': 32, 'vare': 33, 'the': 34, 'a': 35, 'h': 36, 'god': 37, 'r': 38, 'how': 39, 'about': 40, 'now': 41, 'vis': 42, 'heller': 43, 'vor': 44, 'bare': 45, 'togs': 46, 'her': 47, 'fra': 48, 'vad': 49, 'jo': 50, 'soget': 51, 'w': 52, 'nr': 53, 'lige': 54, 'user': 55, 'dansker': 56, 'veld': 57, 'danmark': 58, 'ud': 59, 'vil': 60, 'alle': 61, 'fr': 62, 'gr': 63, 'reget': 64, 'new': 65, 'signature': 66, 'mig': 67, 'honey': 68, 'gunne': 69, 'have': 70, 'ladt': 71, 'over': 72, 'selv': 73, 'blijver': 74, 'xeres': 75, 'm': 76, 'svensen': 77, 'dig': 78, 'nook': 79, 'them': 80, 'ville': 81, 'minute': 82, 'fu': 83, 'se': 84, 'operator': 85, 'kummer': 86, 'hell': 87, 'dansk': 88, 'hade': 89, 'ja': 90, \"m'\": 91, 'vories': 92, 'skulled': 93, 'mere': 94, 'folk': 95, 'ser': 96, 'alt': 97, 'mange': 98, 'end': 99, 'ural': 100, 'andre': 101, \"n't\": 102, 'aldrin': 103, 'kun': 104, 'sudan': 105, 'did': 106, 'mand': 107, 'b': 108, 'gang': 109, 'defter': 110, 'dag': 111, 'system': 112, 'sverige': 113, 'norgen': 114, 'operating': 115, 'niger': 116, 'gre': 117, 'fordid': 118, 'ind': 119, 'horror': 120, 'vernet': 121, 'forster': 122, 'hele': 123, 'vel': 124, 'jem': 125, 'trior': 126, 'burden': 127, 'muskie': 128, 'ogle': 129, 'vigen': 130, 'sammie': 131, 'dog': 132, 'belive': 133, 'mod': 134, 'dette': 135, 'gu': 136, 'auden': 137, 'ort': 138, 'chlordan': 139, 'mde': 140, 'lille': 141, 'tanker': 142, 'altaid': 143, 'inguen': 144, 'bedare': 145, 'finder': 146, 'dennet': 147, 'lere': 148, 'hans': 149, 'sin': 150, 'peenge': 151, 'lev': 152, 'andert': 153, 'ynes': 154, 'alts': 155, 'pom': 156, 'ret': 157, 'tak': 158, 'g': 159, 'ham': 160, 'kkk': 161, 'mit': 162, 'asiden': 163, 'pomme': 164, 'tid': 165, 'set': 166, 'mender': 167, 'seige': 168, 'igerne': 169, 'tillage': 170, 'verden': 171, 'ensete': 172, 'andean': 173, 'hiver': 174, 'fisk': 175, 'ned': 176, 'land': 177, 'staig': 178, 'fuck': 179, 'ting': 180, 'nejd': 181, 'stage': 182, 'under': 183, 'side': 184, 'to': 185, 'levet': 186, 'op': 187, 'der': 188, 'n': 189, 'hold': 190, 'haber': 191, 'sellers': 192, 'stedt': 193, 'nester': 194, 'linge': 195, 'bruges': 196, 'par': 197, 'fucking': 198, 'vide': 199, 'bennu': 200, 'och': 201, 'chende': 202, 'norge': 203, 'bedsite': 204, 'd': 205, 'give': 206, 'feldt': 207, 'hem': 208, 'sovetsk': 209, 'sten': 210, 'angang': 211, 'lad': 212, 'dem': 213, 'smut': 214, 'iinden': 215, 'mine': 216, 'saktism': 217, 'in': 218, 'att': 219, 'kruger': 220, 'perform': 221, 'billete': 222, 'giver': 223, 'hjerpe': 224, 'sidder': 225, 'jag': 226, 'del': 227, 'burn': 228, 'unger': 229, 'govt': 230, 'fadme': 231, 'str': 232, 'agt': 233, 'rode': 234, 'fet': 235, 'nu': 236, 'laveta': 237, 'ground': 238, 'tager': 239, 'til': 240, 'get': 241, 'lare': 242, 'mindset': 243, 'af': 244, 'mens': 245, 'flag': 246, 'abede': 247, 'no': 248, 'sidestep': 249, 'sickert': 250, 'lande': 251, 'mendes': 252, 'families': 253, 'fag': 254, 'mest': 255, 'you': 256, 'satan': 257, 'politist': 258, 'intue': 259, 'beale': 260, 'kinder': 261, 'lant': 262, 'regen': 263, 'sku': 264, 'kft': 265, 'politicker': 266, 'st': 267, 'hole': 268, 'kure': 269, 'drug': 270, 'know': 271, 'homering': 272, 'fantasist': 273, 'lakke': 274, 'sker': 275, 'gode': 276, 'abegge': 277, 'sade': 278, 'zandt': 279, \"'s\": 280, 'samen': 281, 'righting': 282, 'store': 283, 'x': 284, 'bag': 285, 'efrem': 286, 'scanmag': 287, 'sited': 288, 'evert': 289, 'ryder': 290, 'stole': 291, 'glad': 292, 'esker': 293, 'dr': 294, 'synths': 295, 'dago': 296, 'meindre': 297, 'hr': 298, 'intent': 299, 'l': 300, 'martin': 301, 'engels': 302, 'ha': 303, 'lave': 304, 'stor': 305, 'out': 306, 'idea': 307, 'ligger': 308, 'mangler': 309, 'hicket': 310, 'vanden': 311, 'lingered': 312, 'respelt': 313, 'dumb': 314, 'sit': 315, 'br': 316, 'ifint': 317, 'og': 318, 'target': 319, 'lade': 320, 'kr': 321, 'skat': 322, 'gange': 323, 'often': 324, 'edit': 325, 'lancet': 326, 'bor': 327, 'sklar': 328, 'of': 329, 'gamble': 330, 'gin': 331, 'brandt': 332, 'rdt': 333, 'leve': 334, 'tog': 335, 'plaids': 336, 'ord': 337, 'kobenhavn': 338, 'laver': 339, 'slete': 340, 'hre': 341, 'husk': 342, 'hort': 343, 'flot': 344, 'mon': 345, 'mad': 346, 'muslim': 347, 'blot': 348, 'is': 349, 'alder': 350, 'grader': 351, 'ailleret': 352, 'stemmer': 353, 'haha': 354, 'tro': 355, 'kort': 356, 'sv': 357, 'ortet': 358, 'forst': 359, 'bedder': 360, 'ventre': 361, 'mandean': 362, 'kinde': 363, 'sig': 364, 'scyld': 365, 'karrer': 366, 'memel': 367, 'tyre': 368, 'vista': 369, 'venner': 370, 'spillet': 371, 'bundt': 372, 'ender': 373, 't': 374, 'laughing': 375, 'blart': 376, 'slags': 377, 'likesome': 378, 'sorter': 379, 'stortz': 380, 'j': 381, 'lorate': 382, 'seldom': 383, 'mujik': 384, 'started': 385, 'hirer': 386, 'thread': 387, 'esten': 388, 'gad': 389, 'os': 390, 'dele': 391, 'up': 392, 'minuter': 393, 'lars': 394, 'bude': 395, 'bde': 396, 'usa': 397, 'it': 398, 'kirker': 399, 'pga': 400, 'rese': 401, 'oppen': 402, 'verste': 403, 'kone': 404, 'rightist': 405, 'hurting': 406, 'melled': 407, 'alberene': 408, 'tekke': 409, 'uck': 410, 'isr': 411, 'good': 412, 'vianden': 413, 'tyg': 414, 'ringtime': 415, 'tag': 416, 'leste': 417, 'retails': 418, 'jul': 419, 'barn': 420, 'hj': 421, 'ny': 422, 'horner': 423, 'shikker': 424, 'generalty': 425, 'holder': 426, 'jemmie': 427, 'halp': 428, 'hiv': 429, 'loud': 430, 'sart': 431, 'snake': 432, 'grammel': 433, 'stopped': 434, 'norsk': 435, 'tale': 436, 'live': 437, 'hellene': 438, 'alla': 439, 'khalde': 440, 'njorth': 441, 'avrit': 442, 'dissue': 443, 'alg': 444, 'sommer': 445, 'hos': 446, 'taiden': 447, 'love': 448, 'lide': 449, 'kwamme': 450, 'blirt': 451, 'sturte': 452, 'dine': 453, 'trump': 454, 'spenser': 455, 'vedet': 456, 'top': 457, 'bl': 458, 'bering': 459, 'reduit': 460, 'stetted': 461, 'skid': 462, 'sine': 463, 'pulser': 464, 'england': 465, 'roede': 466, 'suttee': 467, 'paske': 468, 'nig': 469, 'mulita': 470, 'vise': 471, 'rd': 472, 'strut': 473, 'problem': 474, 'alene': 475, 'folger': 476, 'thanks': 477, 'vert': 478, 'dd': 479, 'hvac': 480, 'genonema': 481, 'raven': 482, 'ens': 483, 'limens': 484, 'historied': 485, 'intil': 486, 'marked': 487, 'ferie': 488, 'shit': 489, 'pasta': 490, 'gte': 491, 'sager': 492, 'my': 493, 'handler': 494, 'silken': 495, 'skagen': 496, 'unvote': 497, 'ju': 498, 'prover': 499, 'unset': 500, 'tnt': 501, 'taler': 502, 'fouldre': 503, 'whedder': 504, 'felske': 505, 'metaler': 506, 'timer': 507, 'verdins': 508, 'girder': 509, 'fred': 510, 'fylde': 511, 'aligner': 512, 'soldat': 513, 'ln': 514, 'filer': 515, 'roger': 516, 'bra': 517, 'liv': 518, 'snaker': 519, 'pct': 520, 'ligge': 521, 'carme': 522, 'genial': 523, 'wendt': 524, 'patten': 525, 'stod': 526, 'forgan': 527, 'ridered': 528, 'darling': 529, 'strafe': 530, 'eu': 531, 'smidge': 532, 'agen': 533, 'galt': 534, 'gentling': 535, 'avn': 536, 'forbade': 537, 'livest': 538, 'bergander': 539, 'jer': 540, 'skene': 541, 'finders': 542, 'sm': 543, 'gratis': 544, 'undog': 545, 'perfect': 546, 'kaj': 547, 'veldt': 548, 'prove': 549, 'tonk': 550, 'denmark': 551, 'synge': 552, 'foregoer': 553, 'viand': 554, 'starred': 555, 'pis': 556, 'al': 557, 'dredge': 558, 'kigger': 559, 'dannebrog': 560, 'hereafter': 561, 'exostra': 562, 'sex': 563, 'dukker': 564, 'scriver': 565, 'forker': 566, 'ben': 567, 'sole': 568, 'forbit': 569, 'reste': 570, 'more': 571, 'tv': 572, 'reiser': 573, 'worden': 574, 'seder': 575, 'trid': 576, 'sag': 577, 'meaning': 578, 'person': 579, 'strive': 580, 'ver': 581, 'pulse': 582, 'lse': 583, 'frst': 584, 'verre': 585, 'husky': 586, 'typist': 587, 'ithiel': 588, 'minder': 589, 'miming': 590, 'solen': 591, 'tikker': 592, 'kam': 593, 'funded': 594, 'servist': 595, 'haft': 596, 'me': 597, 'sprong': 598, 'fast': 599, 'europa': 600, 'munden': 601, 'inde': 602, 'vj': 603, 'veen': 604, 'tur': 605, 'kempe': 606, 'behaver': 607, 'tolt': 608, 'sad': 609, 'hen': 610, 'fauld': 611, 'billeter': 612, 'nye': 613, 'file': 614, 'krieg': 615, 'spise': 616, 'slemmer': 617, 'farver': 618, 'trev': 619, 'fasted': 620, 'national': 621, 'donning': 622, 'bjorne': 623, 'dramme': 624, 'sidest': 625, 'ven': 626, 'lader': 627, 'raver': 628, 'lger': 629, 'stutter': 630, 'graine': 631, 'twalt': 632, 'total': 633, 'fan': 634, 'fatter': 635, 'spurger': 636, 'fjorded': 637, 'personalist': 638, 'rbor': 639, 'fx': 640, 'ndt': 641, 'forehold': 642, 'starter': 643, 'endeign': 644, 'nd': 645, 'lang': 646, 'absolute': 647, 'visier': 648, 'island': 649, 'smukler': 650, 'finland': 651, 'frederik': 652, 'fat': 653, 'menninger': 654, 'islam': 655, 'av': 656, 'visite': 657, 'commentary': 658, 'sl': 659, 'tanite': 660, 'passe': 661, 'emt': 662, 'helved': 663, 'horrent': 664, 'vr': 665, 'politick': 666, 'normal': 667, 'fytte': 668, 'perinde': 669, 'extreme': 670, 'droll': 671, 'fell': 672, 'brute': 673, 'far': 674, 'check': 675, 'thujene': 676, 'jeres': 677, 'guld': 678, 'harte': 679, 'venter': 680, 'body': 681, 'passer': 682, 'groningen': 683, 'foskett': 684, 'aalborg': 685, 'post': 686, 'oh': 687, 'kloster': 688, 'harahan': 689, 'spiller': 690, 'jt': 691, 'fransen': 692, 'luge': 693, 'sang': 694, 'on': 695, 'norden': 696, 'akonge': 697, 'je': 698, 'grin': 699, 'trt': 700, 'voled': 701, 'kbe': 702, 'sleet': 703, 'matte': 704, 'gullet': 705, 'go': 706, 'verd': 707, 'grivet': 708, 'spail': 709, 'he': 710, 'synd': 711, 'tryster': 712, 'hh': 713, 'form': 714, 'holding': 715, 'gav': 716, 'umt': 717, 'ass': 718, 'chance': 719, 'kim': 720, 'not': 721, 'lign': 722, 'sterk': 723, 'ene': 724, 'lst': 725, 'bara': 726, 'photoscope': 727, 'sort': 728, 'dover': 729, 'probeer': 730, 'market': 731, 'anlage': 732, 'killing': 733, 'samto': 734, 'header': 735, 'antiager': 736, 'fjord': 737, 'prev': 738, 'suk': 739, 'bil': 740, 'sendle': 741, 'stilled': 742, 'ingene': 743, 'fried': 744, 'idiot': 745, 'lever': 746, 'styr': 747, 'directer': 748, 'all': 749, 'varmint': 750, 'delight': 751, 'listen': 752, 'reclame': 753, 'argument': 754, 'dick': 755, 'urgent': 756, 'bysen': 757, 'regna': 758, 'sware': 759, 'sken': 760, 'bange': 761, 'hurrah': 762, 'freda': 763, 'regaler': 764, 'billen': 765, 'scene': 766, 'ung': 767, 'dealing': 768, 'situation': 769, 'an': 770, 'fare': 771, 'goggle': 772, 'revise': 773, 'slr': 774, 'ses': 775, 'odour': 776, 'ren': 777, 'sq': 778, 'neglige': 779, 'netop': 780, 'pessoner': 781, 'niveau': 782, 'pangene': 783, 'teener': 784, 'amen': 785, 'gelding': 786, 'subedit': 787, 'ostende': 788, 'alcohol': 789, 'slavenska': 790, 'vet': 791, 'ovid': 792, 'stet': 793, 'dk': 794, 'tr': 795, 'debt': 796, 'margarethe': 797, 'masse': 798, 'tirer': 799, 'dyke': 800, 'ilmen': 801, 'your': 802, 'solgel': 803, 'balister': 804, 'forslack': 805, 'tragics': 806, 'syndet': 807, 'specialty': 808, 'kente': 809, 'dt': 810, 'lekker': 811, 'dresden': 812, 'kroner': 813, 'kakke': 814, 'idiometer': 815, 'fenks': 816, 'venere': 817, 'interesse': 818, 'look': 819, 'enver': 820, 'nyet': 821, 'till': 822, 'contest': 823, 'sike': 824, 'bolger': 825, 'viler': 826, 'didst': 827, 'job': 828, 'sloken': 829, 'video': 830, 'savin': 831, 'linene': 832, 'pisser': 833, 'dren': 834, 'hooved': 835, 'ad': 836, 'sestet': 837, 'kurten': 838, 'haje': 839, 'avner': 840, 'da': 841, 'deviser': 842, 'vivl': 843, 'permed': 844, 'let': 845, 'holst': 846, 'hymie': 847, 'lange': 848, 'billings': 849, 'laser': 850, 'again': 851, 'dummel': 852, 'magot': 853, 'tidder': 854, 'dere': 855, 'co': 856, 'fri': 857, 'fuld': 858, 'dom': 859, 'okay': 860, 'trek': 861, 'wongen': 862, 'fin': 863, 'kors': 864, 'kristine': 865, 'mid': 866, 'morgen': 867, 'kb': 868, 'blow': 869, 'henter': 870, 'flask': 871, 'medizer': 872, 'nidder': 873, 'held': 874, 'farlie': 875, 'trist': 876, 'aklog': 877, 'arm': 878, 'heidt': 879, 'piste': 880, 'davens': 881, 'overfar': 882, 'do': 883, 'fugit': 884, 'uplander': 885, 'luter': 886, 'kn': 887, 'eb': 888, 'veliger': 889, 'moste': 890, 'forger': 891, 'grippe': 892, 'smit': 893, 'trodden': 894, 'religion': 895, 'send': 896, 'rydder': 897, 'kalat': 898, 'seiser': 899, 'corruption': 900, 'bordet': 901, 'kong': 902, 'majestic': 903, 'forlet': 904, 'forbare': 905, 'pegger': 906, 'saddened': 907, 'flasket': 908, 'sub': 909, 'evulge': 910, 'underlight': 911, 'parti': 912, 'yuft': 913, 'ls': 914, 'historian': 915, 'teskere': 916, 'lobale': 917, 'indenting': 918, 'skyfte': 919, 'denten': 920, 'pist': 921, 'fokker': 922, 'tabut': 923, 'foge': 924, 'lamper': 925, 'tide': 926, 'parent': 927, 'joke': 928, 'rods': 929, 'angrite': 930, 'reigner': 931, 'militar': 932, 'larsen': 933, 'momma': 934, 'megan': 935, 'golder': 936, 'rent': 937, 'folketing': 938, 'brut': 939, 'super': 940, 'stammels': 941, 'sur': 942, 'egret': 943, 'sinsyne': 944, 'and': 945, 'sherie': 946, 'rushland': 947, 'glent': 948, 'bornholm': 949, 'betalk': 950, 'test': 951, 'sov': 952, 'veskit': 953, 'claret': 954, 'yakker': 955, 'vent': 956, 'lot': 957, 'start': 958, 'relevant': 959, 'antal': 960, 'sket': 961, 'tyke': 962, 'petto': 963, 'case': 964, 'engold': 965, 'vt': 966, 'or': 967, 'kassel': 968, 'sieges': 969, 'andersen': 970, 'emes': 971, 'grundel': 972, 'eldred': 973, 'indentor': 974, 'tortille': 975, 'angareb': 976, 'mommet': 977, 'casebook': 978, 'fourteener': 979, 'hemmel': 980, 'fake': 981, 'news': 982, 'jove': 983, 'novene': 984, 'madsen': 985, 'o': 986, 'what': 987, 'han': 988, 'undrest': 989, 'adet': 990, 'this': 991, 'arling': 992, 'skel': 993, 'titlene': 994, 'lubet': 995, 'husker': 996, 'pangen': 997, 'amund': 998, 'ede': 999, 'humor': 1000, 'fucked': 1001, 'overkeen': 1002, 'skit': 1003, 'pledger': 1004, 'taken': 1005, 'etc': 1006, 'hundreder': 1007, 'jigged': 1008, 'muridism': 1009, 'dde': 1010, 'ikey': 1011, 'enage': 1012, 'olsen': 1013, 'malden': 1014, 'forestville': 1015, 'slut': 1016, 'retard': 1017, 'sd': 1018, 'solve': 1019, 'tiersten': 1020, 'bobet': 1021, 'rest': 1022, 'flyting': 1023, 'slap': 1024, 'neglig': 1025, 'bank': 1026, 'invader': 1027, 'tar': 1028, 'roggen': 1029, 'hanska': 1030, 'gymnasiast': 1031, 'studier': 1032, 'stouffer': 1033, 'precent': 1034, 'gylden': 1035, 'vla': 1036, 'articled': 1037, 'sludder': 1038, 'debat': 1039, 'brere': 1040, 'imager': 1041, 'havent': 1042, 'lurer': 1043, 'beg': 1044, 'fed': 1045, 'unkinger': 1046, 'henrik': 1047, 'propaganda': 1048, 'partier': 1049, 'bte': 1050, 'order': 1051, 'frt': 1052, 'viander': 1053, 'vulgare': 1054, 'linker': 1055, 'retted': 1056, 'stilu': 1057, 'link': 1058, 'vannet': 1059, 'nordine': 1060, 'rv': 1061, 'information': 1062, 'skere': 1063, 'sakta': 1064, 'mmm': 1065, 'jenkel': 1066, 'pendens': 1067, 'firmer': 1068, 'find': 1069, 'postie': 1070, 'by': 1071, 'danish': 1072, 'anders': 1073, 'bede': 1074, 'please': 1075, 'overage': 1076, 'here': 1077, 'alternative': 1078, 'wow': 1079, 'derust': 1080, 'inbbred': 1081, 'putter': 1082, 'but': 1083, 'klimt': 1084, 'firmest': 1085, 'version': 1086, 'norse': 1087, 'sn': 1088, 'feminise': 1089, 'fname': 1090, 'relig': 1091, 'international': 1092, 'normand': 1093, 'eigne': 1094, 'flattest': 1095, 'viking': 1096, 'jade': 1097, 'unden': 1098, 'longsome': 1099, 'boomster': 1100, 'snover': 1101, 'yst': 1102, 'ariege': 1103, 'tucket': 1104, 'like': 1105, 'prints': 1106, 'pr': 1107, 'saner': 1108, 'klowet': 1109, 'batture': 1110, 'gif': 1111, 'artlike': 1112, 'forekeel': 1113, 'inulin': 1114, 'nedda': 1115, 'takken': 1116, 'sifter': 1117, 'klister': 1118, 'ytter': 1119, 'k': 1120, 'modist': 1121, 'eatme': 1122, 'kurt': 1123, 'hmm': 1124, 'point': 1125, 'rig': 1126, 'ofter': 1127, 'life': 1128, 'hey': 1129, 'so': 1130, 'internetted': 1131, 'originable': 1132, 'japan': 1133, 'unde': 1134, 'union': 1135, 'pointmen': 1136, 'ca': 1137, 'russene': 1138, 'engen': 1139, 'partaken': 1140, 'interview': 1141, 'mesked': 1142, 'flyte': 1143, 'tennisy': 1144, 'endite': 1145, 'herra': 1146, 'inket': 1147, 'pinge': 1148, 'ore': 1149, 'fore': 1150, 'kammeu': 1151, 'oversalt': 1152, 'welford': 1153, 'u': 1154, 'setter': 1155, 'eysk': 1156, 'overget': 1157, 'grint': 1158, 'drinker': 1159, 'nazism': 1160, 'juglar': 1161, 'paget': 1162, 'glade': 1163, 'fair': 1164, 'patter': 1165, 'sociales': 1166, 'ironish': 1167, 'antidepressive': 1168, 'banner': 1169, 'socialise': 1170, 'sgt': 1171, 'koines': 1172, 'ringe': 1173, 'lig': 1174, 'lav': 1175, 'id': 1176, 'billing': 1177, 'ative': 1178, 'flotter': 1179, 'muslims': 1180, 'revet': 1181, 'sattle': 1182, 'gyge': 1183, 'going': 1184, 'gym': 1185, 'abort': 1186, 'control': 1187, 'stave': 1188, 'gesning': 1189, 'moder': 1190, 'ende': 1191, 'onfre': 1192, 'blade': 1193, 'oldster': 1194, 'formel': 1195, 'ide': 1196, 'bixler': 1197, 'lege': 1198, 'hun': 1199, 'gammelost': 1200, 'sparge': 1201, 'juha': 1202, 'play': 1203, 'arrogate': 1204, 'ho': 1205, 'bankmen': 1206, 'lene': 1207, 'tormenter': 1208, 'inholder': 1209, 'fanlight': 1210, 'strafes': 1211, 'fretten': 1212, 'holla': 1213, 'karyaster': 1214, 'lasse': 1215, 'sure': 1216, 'sider': 1217, 'lite': 1218, 'lego': 1219, 'gunnen': 1220, 'sangei': 1221, 'cloven': 1222, 'ferde': 1223, 'upstem': 1224, 'renninogen': 1225, 'satire': 1226, 'grintern': 1227, 'sunken': 1228, 'ivdt': 1229, 'millioner': 1230, 'too': 1231, 'gut': 1232, 'bi': 1233, 'gule': 1234, 'remoulade': 1235, 'forbearing': 1236, 'vestige': 1237, 'glans': 1238, 'munger': 1239, 'foreslow': 1240, 'lisere': 1241, 'jesus': 1242, 'info': 1243, 'pn': 1244, 'spilled': 1245, 'yurak': 1246, 'north': 1247, 'nelse': 1248, 'mer': 1249, 'tenn': 1250, 'lobe': 1251, 'senesce': 1252, 'billet': 1253, 'sos': 1254, 'radio': 1255, 'glassen': 1256, 'hotdog': 1257, 'ideologic': 1258, 'well': 1259, 'drove': 1260, 'red': 1261, 'armen': 1262, 'grand': 1263, 'hand': 1264, 'jorgensen': 1265, 'nice': 1266, 'bli': 1267, 'assen': 1268, 'steger': 1269, 'sanded': 1270, 'sweden': 1271, 'hour': 1272, 'tack': 1273, 'morten': 1274, 'programmer': 1275, 'scandinavian': 1276, 'ry': 1277, 'kanona': 1278, 'rop': 1279, 'emmerie': 1280, 'lolo': 1281, 'reaction': 1282, 'stillest': 1283, 'simule': 1284, 'blusher': 1285, 'evict': 1286, 'stradiot': 1287, 'grimme': 1288, 'ellinger': 1289, 'sharia': 1290, 'dirige': 1291, 'toothed': 1292, 'rammer': 1293, 'broken': 1294, 'cool': 1295, 'priciest': 1296, 'hopper': 1297, 'hengyang': 1298, 'beare': 1299, 'magen': 1300, 'sharet': 1301, 'andvar': 1302, 'vote': 1303, 'federate': 1304, 'hushed': 1305, 'rede': 1306, 'pantalet': 1307, 'pedaller': 1308, 'miljee': 1309, 'frank': 1310, 'ist': 1311, 'jorden': 1312, 'hus': 1313, 'rap': 1314, 'fledge': 1315, 'halt': 1316, 'lett': 1317, 'smt': 1318, 'dyer': 1319, 'flock': 1320, 'trode': 1321, 'trav': 1322, 'overresist': 1323, 'staten': 1324, 'president': 1325, 'britta': 1326, 'meltage': 1327, 'paster': 1328, 'derned': 1329, 'toller': 1330, 'va': 1331, 'planer': 1332, 'felder': 1333, 'yd': 1334, 'vdt': 1335, 'brok': 1336, 'karma': 1337, 'arvel': 1338, 'hive': 1339, 'broke': 1340, 'samlet': 1341, 'tallet': 1342, 'kristen': 1343, 'lignes': 1344, 'herd': 1345, 'skryer': 1346, 'knight': 1347, 'bringed': 1348, 'mund': 1349, 'drunker': 1350, 'v': 1351, 'offerer': 1352, 're': 1353, 'stop': 1354, 'boller': 1355, 'besmutting': 1356, 'salt': 1357, 'branden': 1358, 'pendom': 1359, 'lancets': 1360, 'mohammed': 1361, 'kamp': 1362, 'loyde': 1363, 'lengest': 1364, 'upbid': 1365, 'classism': 1366, 'slag': 1367, 'bitch': 1368, 'flaglet': 1369, 'unvoted': 1370, 'dmt': 1371, 'armer': 1372, 'undight': 1373, 'basenet': 1374, 'krone': 1375, 'dowcote': 1376, 'one': 1377, 'dropper': 1378, 'sjaelland': 1379, 'communed': 1380, 'din': 1381, 'halve': 1382, 'sande': 1383, 'chur': 1384, 'john': 1385, 'faldetta': 1386, 'valet': 1387, 'problemist': 1388, 'greenland': 1389, 'konde': 1390, 'benares': 1391, 'laved': 1392, 'rinser': 1393, 'afterend': 1394, 'welcome': 1395, 'mg': 1396, 'vera': 1397, 'jone': 1398, 'grad': 1399, 'religiose': 1400, 'ilke': 1401, 'musicker': 1402, 'lg': 1403, 'files': 1404, 'helvite': 1405, 'filles': 1406, 'enorm': 1407, 'forbidden': 1408, 'halper': 1409, 'oc': 1410, 'frisk': 1411, 'teenager': 1412, 'loot': 1413, 'robbert': 1414, 'stringer': 1415, 'f': 1416, 'laverne': 1417, 'andelee': 1418, 'gemot': 1419, 'rias': 1420, 'rapporteur': 1421, 'vended': 1422, 'cocks': 1423, 'afrika': 1424, 'sabe': 1425, 'cagester': 1426, 'forrader': 1427, 'natura': 1428, 'ateknia': 1429, 'klam': 1430, 'malm': 1431, 'damn': 1432, 'totterer': 1433, 'nolde': 1434, 'outvotes': 1435, 'shrift': 1436, 'retuning': 1437, 'inhumane': 1438, 'bible': 1439, 'corrupt': 1440, 'links': 1441, 'goldwater': 1442, 'nation': 1443, 'inducer': 1444, 'paramere': 1445, 'liftmen': 1446, 'privet': 1447, 'online': 1448, 'anger': 1449, 'interne': 1450, 'nappe': 1451, 'bot': 1452, 'spriglet': 1453, 'beshag': 1454, 'rate': 1455, 'knaster': 1456, 'lb': 1457, 'keep': 1458, 'umgang': 1459, 'timeling': 1460, 'kl': 1461, 'igor': 1462, 'batik': 1463, 'roskilde': 1464, 'overfee': 1465, 'vender': 1466, 'perfected': 1467, 'postyard': 1468, 'fere': 1469, 'asben': 1470, 'universite': 1471, 'su': 1472, 'scuppet': 1473, 'shikken': 1474, 'wyver': 1475, 'indre': 1476, 'ogt': 1477, 'ska': 1478, 'mulk': 1479, 'personed': 1480, 'soften': 1481, 'investure': 1482, 'cyke': 1483, 'aberr': 1484, 'opaled': 1485, 'skiv': 1486, 'bruyere': 1487, 'lede': 1488, 'gigget': 1489, 'wilfred': 1490, 'gilded': 1491, 'gt': 1492, 'saltie': 1493, 'svr': 1494, 'svante': 1495, 'same': 1496, 'old': 1497, 'stoppit': 1498, 'damager': 1499, 'foreland': 1500, 'best': 1501, 'slog': 1502, 'snyder': 1503, 'liber': 1504, 'computer': 1505, 'km': 1506, 'ok': 1507, 'historism': 1508, 'beget': 1509, 'rodent': 1510, 'software': 1511, 'oooo': 1512, 'finns': 1513, 'underer': 1514, 'brand': 1515, 'moussaka': 1516, 'homeland': 1517, 'bevis': 1518, 'was': 1519, 'ein': 1520, 'die': 1521, 'ut': 1522, 'vl': 1523, 'era': 1524, 'mester': 1525, 'bad': 1526, '2': 1527, 'kanake': 1528, 'intro': 1529, 'forbodes': 1530, 'penlight': 1531, 'menthe': 1532, 'spurl': 1533, 'ask': 1534, 'workfare': 1535, 'fest': 1536, 'cringe': 1537, 'tosser': 1538, 'gris': 1539, 'edirne': 1540, 'grinter': 1541, 'gun': 1542, 'janene': 1543, 'triller': 1544, 'tyken': 1545, 'communist': 1546, 'sf': 1547, 'jaala': 1548, 'verdi': 1549, 'msmgte': 1550, 'klber': 1551, 'fun': 1552, 'famille': 1553, 'senders': 1554, 'thorsten': 1555, 'kerve': 1556, 'driver': 1557, 'bagge': 1558, 'niels': 1559, 'renet': 1560, 'severe': 1561, 'fire': 1562, 'glassier': 1563, 'maj': 1564, 'restauranteur': 1565, 'flusk': 1566, 'politi': 1567, 'droplet': 1568, 'yv': 1569, 'sahh': 1570, 'journalistic': 1571, 'clyve': 1572, 'ryde': 1573, 'ph': 1574, 'idlest': 1575, 'design': 1576, 'sender': 1577, 'private': 1578, 'off': 1579, 'led': 1580, 'rigel': 1581, 'nere': 1582, 'mesoderm': 1583, 'ferne': 1584, 'lurdan': 1585, 'forbiddal': 1586, 'times': 1587, 'bringer': 1588, 'fordeal': 1589, 'mods': 1590, 'letter': 1591, 'king': 1592, 'posts': 1593, 'acceptee': 1594, 'loligo': 1595, 'mucket': 1596, 'dunois': 1597, 'drer': 1598, 'liner': 1599, 'firma': 1600, 'pind': 1601, 'wtf': 1602, 'gul': 1603, 'bastille': 1604, 'perstand': 1605, 'skint': 1606, 'patriotism': 1607, 'fortunite': 1608, 'autist': 1609, 'dram': 1610, 'detailer': 1611, 'smorebro': 1612, 'mary': 1613, 'museum': 1614, 'interessee': 1615, 'reserve': 1616, 'rs': 1617, 'mosette': 1618, 'kontakia': 1619, 'organisation': 1620, 'identism': 1621, 'bedust': 1622, 'overleer': 1623, 'lugger': 1624, 'glenden': 1625, 'rhus': 1626, 'varment': 1627, 'abune': 1628, 'inhold': 1629, 'folkies': 1630, 'linsk': 1631, 'lvov': 1632, 'edeline': 1633, 'am': 1634, 'awesome': 1635, 'thenne': 1636, 'oversight': 1637, 'lsd': 1638, 'nat': 1639, 'neger': 1640, 'kliber': 1641, 'overset': 1642, 'meninges': 1643, 'debatter': 1644, 'serifs': 1645, 'skills': 1646, 'banker': 1647, 'banket': 1648, 'mokane': 1649, 'smils': 1650, 'randers': 1651, 'gold': 1652, 'tit': 1653, 'shitty': 1654, 'drake': 1655, 'paradox': 1656, 'gutte': 1657, 'odense': 1658, 'alyse': 1659, 'amende': 1660, 'ku': 1661, 'dens': 1662, 'selmore': 1663, 'involvement': 1664, 'avell': 1665, 'bestar': 1666, 'global': 1667, 'kliman': 1668, 'angrier': 1669, 'fang': 1670, 'hansen': 1671, 'vindex': 1672, 'gavan': 1673, 'magism': 1674, 'attinge': 1675, 'forreston': 1676, 'intersecant': 1677, 'trask': 1678, 'vee': 1679, 'fanglet': 1680, 'posnet': 1681, 'hyde': 1682, 'come': 1683, 'neven': 1684, 'dogate': 1685, 'rant': 1686, 'flitted': 1687, 'hel': 1688, 'constant': 1689, 'congerie': 1690, 'internet': 1691, 'skillet': 1692, 'adret': 1693, 'station': 1694, 'administration': 1695, 'zoo': 1696, 'kalmar': 1697, 'kriege': 1698, 'norborne': 1699, 'render': 1700, 'rere': 1701, 'trinket': 1702, 'stryker': 1703, 'ursulette': 1704, 'network': 1705, 'storemen': 1706, 'lerne': 1707, 'flogster': 1708, 'kantor': 1709, 'syren': 1710, 'aarhus': 1711, 'vild': 1712, 'sansen': 1713, 'nature': 1714, 'canada': 1715, 'df': 1716, 'murk': 1717, 'arsenide': 1718, 'radiale': 1719, 'mitt': 1720, 'alltud': 1721, 'la': 1722, 'bork': 1723, 'folded': 1724, 'syd': 1725, 'grove': 1726, 'podarge': 1727, 'negro': 1728, 'crafter': 1729, 'gurnet': 1730, 'bla': 1731, 'referrer': 1732, 'sledges': 1733, 'generation': 1734, 'straight': 1735, 'stader': 1736, 'can': 1737, 'brocket': 1738, 'bronte': 1739, 'foreseer': 1740, 'togt': 1741, 'tandemer': 1742, 'flarer': 1743, 'nato': 1744, 'hnd': 1745, 'ring': 1746, 'fended': 1747, 'kaos': 1748, 'resultant': 1749, 'maligned': 1750, 'operette': 1751, 'plat': 1752, 'nationalist': 1753, 'frit': 1754, 'marianne': 1755, 'kallinge': 1756, 'essede': 1757, 'diagnose': 1758, 'danese': 1759, 'verdie': 1760, 'qu': 1761, 'algate': 1762, 'ramate': 1763, 'neb': 1764, 'distil': 1765, 'sat': 1766, 'verditer': 1767, 'sant': 1768, 'ferrer': 1769, 'rask': 1770, 'restaurant': 1771, 'herrle': 1772, 'crosspost': 1773, 'systemed': 1774, 'bseng': 1775, 'coroutines': 1776, 'opinion': 1777, 'streen': 1778, 'benzin': 1779, 'meg': 1780, 'tarten': 1781, 'melder': 1782, 'dank': 1783, 'million': 1784, 'are': 1785, 'forgette': 1786, 'aneale': 1787, 'lieder': 1788, 'onstage': 1789, 'fiske': 1790, 'utta': 1791, 'varese': 1792, 'erlene': 1793, 'radford': 1794, 'drisko': 1795, 'lagen': 1796, 'folks': 1797, 'forthset': 1798, 'repost': 1799, 'vogt': 1800, 'passenger': 1801, 'striffen': 1802, 'peter': 1803, 'busket': 1804, 'skinner': 1805, 'stodder': 1806, 'skete': 1807, 'grebes': 1808, 'amerika': 1809, 'augen': 1810, 'imelle': 1811, 'plus': 1812, 'film': 1813, 'spiled': 1814, 'skald': 1815, 'bog': 1816, 'mister': 1817, 'win': 1818, \"t's\": 1819, 'hebe': 1820, 'middler': 1821, 'selig': 1822, 'pilsen': 1823, 'andel': 1824, 'nudger': 1825, 'indene': 1826, 'bar': 1827, 'shemite': 1828, 'andres': 1829, 'precis': 1830, 'hulk': 1831, 'ranere': 1832, 'udaler': 1833, 'larum': 1834, 'leyden': 1835, 'country': 1836, 'venezuela': 1837, 'pointe': 1838, 'treen': 1839, 'spinder': 1840, 'reb': 1841, 'bo': 1842, 'unget': 1843, 'abo': 1844, 'ond': 1845, 'regearing': 1846, 'forsung': 1847, 'beholder': 1848, 'underviewer': 1849, 'suck': 1850, 'dragnet': 1851, 'foraneen': 1852, 'counter': 1853, 'trekker': 1854, 'corrupted': 1855, 'gerdeen': 1856, 'has': 1857, 'comedy': 1858, 'temperature': 1859, 'surg': 1860, 'bn': 1861, 'vire': 1862, 'loge': 1863, 'hitler': 1864, 'biggety': 1865, 'mandlen': 1866, 'carteret': 1867, 'navet': 1868, 'rapper': 1869, 'skye': 1870, 'compleat': 1871, 'star': 1872, 'pyne': 1873, 'folie': 1874, 'bordiuk': 1875, 'grd': 1876, 'stilling': 1877, 'iden': 1878, 'beglide': 1879, 'dike': 1880, 'downcomes': 1881, 'midst': 1882, 'filter': 1883, 'ruelle': 1884, 'forestate': 1885, 'sire': 1886, 'luket': 1887, 'nh': 1888, 'mark': 1889, 'misken': 1890, 'spreader': 1891, 'sport': 1892, 'estreat': 1893, 'amok': 1894, 'faxen': 1895, 'jensen': 1896, 'sharer': 1897, 'commenter': 1898, 'honger': 1899, 'streaks': 1900, 'lokshen': 1901, 'rip': 1902, 'show': 1903, 'popcorn': 1904, 'fertil': 1905, 'sake': 1906, 'remelt': 1907, 'ranket': 1908, 'em': 1909, 'branen': 1910, 'golem': 1911, 'batten': 1912, 'kid': 1913, 'dartre': 1914, 'us': 1915, 'blandburg': 1916, 'kursk': 1917, 'done': 1918, 'immigrator': 1919, 'fryd': 1920, 'glide': 1921, 'factum': 1922, 'remover': 1923, 'bye': 1924, 'osteome': 1925, 'riotist': 1926, 'fb': 1927, 'ole': 1928, 'plagate': 1929, 'americans': 1930, 'shut': 1931, 'tidling': 1932, 'overjacket': 1933, 'skuld': 1934, 'savage': 1935, 'nope': 1936, 'yep': 1937, 'stof': 1938, 'danner': 1939, 'ever': 1940, 'rerise': 1941, 'sommers': 1942, 'ireland': 1943, 'type': 1944, 'denom': 1945, 'forstand': 1946, 'ruc': 1947, 'kcal': 1948, 'kilo': 1949, 'olli': 1950, 'curling': 1951, 'murdering': 1952, 'fremt': 1953, 'ryke': 1954, 'remails': 1955, 'egon': 1956, 'spree': 1957, 'idiotic': 1958, 'blobbed': 1959, 'bed': 1960, 'loket': 1961, 'forswat': 1962, 'ribbet': 1963, 'revender': 1964, 'fans': 1965, 'joachim': 1966, 'motorcycler': 1967, 'unitage': 1968, 'soviet': 1969, 'gristede': 1970, 'stolen': 1971, 'div': 1972, 'silages': 1973, 'idl': 1974, 'spurge': 1975, 'navite': 1976, 'carlsborg': 1977, 'figge': 1978, 'hider': 1979, 'grounden': 1980, 'vort': 1981, 'bergen': 1982, 'amene': 1983, 'stofler': 1984, 'peace': 1985, 'mdre': 1986, 'japanese': 1987, 'installer': 1988, 'klapp': 1989, 'semi': 1990, 'sunderer': 1991, 'undye': 1992, 'just': 1993, 'le': 1994, 'progressive': 1995, 'ronen': 1996, 'syncs': 1997, 'jat': 1998, 'institution': 1999, 'moral': 2000, 'bayer': 2001, 'osaka': 2002, 'optic': 2003, 'censure': 2004, 'nationalities': 2005, 'hm': 2006, 'hester': 2007, 'subs': 2008, 'succesful': 2009, 'overtaught': 2010, 'initiative': 2011, 'relever': 2012, 'lisiere': 2013, 'inapt': 2014, 'misruler': 2015, 'misrun': 2016, 'artiller': 2017, 'spare': 2018, 'stemmeries': 2019, 'grammatist': 2020, 'fluer': 2021, 'ruller': 2022, 'wedeling': 2023, 'dealer': 2024, 'kariti': 2025, 'foretold': 2026, 'reference': 2027, 'never': 2028, 'willem': 2029, 'posteen': 2030, 'rynd': 2031, 'nabber': 2032, 'devinct': 2033, 'sampler': 2034, 'materiable': 2035, 'fatting': 2036, 'alleles': 2037, 'bravo': 2038, 'feak': 2039, 'kankrej': 2040, 'dyester': 2041, 'downloaded': 2042, 'spaghetti': 2043, 'ellinge': 2044, 'finger': 2045, 'feel': 2046, 'nasty': 2047, 'hall': 2048, 'neet': 2049, 'styrene': 2050, 'principate': 2051, 'return': 2052, 'lely': 2053, 'jylland': 2054, 'tengere': 2055, 'dame': 2056, 'formal': 2057, 'mulet': 2058, 'epsom': 2059, 'vestures': 2060, 'dreher': 2061, 'gott': 2062, 'halland': 2063, 'betinge': 2064, 'overhasten': 2065, 'minders': 2066, 'manager': 2067, 'tour': 2068, 'eleganter': 2069, 'leverer': 2070, 'sauce': 2071, 'spruer': 2072, 'bohr': 2073, 'statue': 2074, 'letted': 2075, 'rio': 2076, 'odin': 2077, 'tor': 2078, 'freyja': 2079, 'omen': 2080, 'naturing': 2081, 'hest': 2082, 'dos': 2083, 'snivel': 2084, 'gay': 2085, 'syn': 2086, 'beent': 2087, 'rummest': 2088, 'jakob': 2089, 'honor': 2090, 'berget': 2091, 'stilbum': 2092, 'ramet': 2093, 'frida': 2094, 'eluder': 2095, 'pet': 2096, 'limpet': 2097, 'leede': 2098, 'underling': 2099, 'besagne': 2100, 'leger': 2101, 'class': 2102, 'ungt': 2103, 'trit': 2104, 'holland': 2105, 'beekite': 2106, 'streamer': 2107, 'oken': 2108, 'report': 2109, 'angelet': 2110, 'enrobe': 2111, 'that': 2112, 'once': 2113, 'part': 2114, 'bigwig': 2115, 'outgave': 2116, 'blok': 2117, 'regards': 2118, 'saanen': 2119, 'kanten': 2120, 'skerret': 2121, 'behold': 2122, 'trajet': 2123, 'sagene': 2124, 'broder': 2125, 'blanding': 2126, 'socializer': 2127, 'hemmed': 2128, 'whistle': 2129, 'blower': 2130, 'pepe': 2131, 'shorts': 2132, 'kokan': 2133, 'rahul': 2134, 'sammel': 2135, 'talter': 2136, 'stupid': 2137, 'ked': 2138, 'prost': 2139, 'forestaller': 2140, 'router': 2141, 'pipeage': 2142, 'anlages': 2143, 'yperite': 2144, 'flet': 2145, 'denna': 2146, 'solute': 2147, 'icken': 2148, 'fogus': 2149, 'ligne': 2150, 'pong': 2151, 'polonaise': 2152, 'solange': 2153, 'competence': 2154, 'potato': 2155, 'feller': 2156, 'naunt': 2157, 'penda': 2158, 'plage': 2159, 'relending': 2160, 'familiar': 2161, 'onker': 2162, 'futter': 2163, 'mor': 2164, 'sprue': 2165, 'blanket': 2166, 'cancer': 2167, 'boobs': 2168, 'brenden': 2169, 'masser': 2170, 'tom': 2171, 'taj': 2172, 'mortgager': 2173, 'pt': 2174, 'kindles': 2175, 'caution': 2176, 'elfie': 2177, 'remmer': 2178, 'resource': 2179, 'corsage': 2180, 'antisemitism': 2181, 'unstilled': 2182, 'burka': 2183, 'attitude': 2184, 'understrewed': 2185, 'stemlet': 2186, 'dte': 2187, 'flurt': 2188, 'bh': 2189, 'halsen': 2190, 'kval': 2191, 'tekken': 2192, 'nip': 2193, 'pint': 2194, 'lukas': 2195, 'velte': 2196, 'trailer': 2197, 'kill': 2198, 'yourself': 2199, 'bernie': 2200, 'monster': 2201, 'mitten': 2202, 'reigning': 2203, 'plight': 2204, 'holy': 2205, 'gud': 2206, 'besmutted': 2207, 'seler': 2208, 'anyways': 2209, 'stiller': 2210, 'discipling': 2211, 'elevener': 2212, 'forra': 2213, 'snit': 2214, 'python': 2215, 'formular': 2216, 'volvo': 2217, 'crupper': 2218, 'dels': 2219, 'stampede': 2220, 'vinter': 2221, 'ol': 2222, 'lands': 2223, '4': 2224, 'flooder': 2225, 'xc': 2226, 'trails': 2227, 'rober': 2228, 'staler': 2229, 'asshat': 2230, 'mtb': 2231, 'local': 2232, 'cyler': 2233, 'yeisk': 2234, 'poret': 2235, 'skinned': 2236, 'paraplegy': 2237, 'hoarder': 2238, 'spaniel': 2239, 'finale': 2240, 'deutschland': 2241, 'talles': 2242, 'corbeil': 2243, 'jfs': 2244, 'think': 2245, 'bedstand': 2246, 'tortur': 2247, 'detente': 2248, 'relative': 2249, 'bill': 2250, 'statistics': 2251, 'jet': 2252, 'favorite': 2253, 'granose': 2254, 'von': 2255, 'milde': 2256, 'gas': 2257, 'sumage': 2258, 'major': 2259, 'australis': 2260, 'assistanted': 2261, 'bigger': 2262, 'lemper': 2263, 'tustin': 2264, 'skout': 2265, 'benoite': 2266, 'friedelite': 2267, 'mudland': 2268, 'surger': 2269, 'henge': 2270, 'bodrage': 2271, 'dauner': 2272, 'dies': 2273, 'deutsche': 2274, 'knoll': 2275, 'knoller': 2276, 'lr': 2277, 'haded': 2278, 'pulsejet': 2279, 'forehand': 2280, 'whisky': 2281, 'glider': 2282, 'gellert': 2283, 'trilled': 2284, 'grummel': 2285, 'age': 2286, 'damien': 2287, 'vill': 2288, 'varier': 2289, 'tunder': 2290, 'lund': 2291, 'hyped': 2292, 'big': 2293, 'deal': 2294, 'overloved': 2295, 'jap': 2296, 'frike': 2297, 'nella': 2298, 'bemist': 2299, 'arriere': 2300, 'grinder': 2301, 'redleg': 2302, 'molestor': 2303, 'ungot': 2304, 'unioned': 2305, 'lys': 2306, 'sindee': 2307, 'impede': 2308, 'polska': 2309, 'slesvig': 2310, 'holstein': 2311, 'duhl': 2312, 'trigere': 2313, 'misset': 2314, 'republic': 2315, 'bilsteds': 2316, 'minimal': 2317, 'orselle': 2318, 'randene': 2319, 'patriot': 2320, 'ost': 2321, 'sirgang': 2322, 'emmeline': 2323, 'tavers': 2324, 'stank': 2325, 'derobe': 2326, 'deth': 2327, 'overlade': 2328, 'gruesome': 2329, 'smarten': 2330, 'varlet': 2331, 'ht': 2332, 'sent': 2333, 'personalize': 2334, 'beyond': 2335, 'snaked': 2336, 'primitive': 2337, 'scat': 2338, 'augmenter': 2339, 'overmast': 2340, 'forsta': 2341, 'tungan': 2342, 'cadere': 2343, 'sane': 2344, 'plastic': 2345, 'milnet': 2346, 'fillander': 2347, 'kinesis': 2348, 'lytten': 2349, 'art': 2350, 'stopper': 2351, 'nya': 2352, 'helling': 2353, 'elset': 2354, 'hillet': 2355, 'nord': 2356, 'hei': 2357, 'innes': 2358, 'noxen': 2359, 'radii': 2360, 'femmes': 2361, 'manuel': 2362, 'subjective': 2363, 'irked': 2364, 'negative': 2365, 'kleig': 2366, 'brasen': 2367, 'dunst': 2368, 'andrea': 2369, 'pia': 2370, 'jurgen': 2371, 'argenter': 2372, 'bere': 2373, 'numen': 2374, 'racists': 2375, 'stillstand': 2376, 'vde': 2377, 'blob': 2378, 'misate': 2379, 'alkanet': 2380, 'invitee': 2381, 'presser': 2382, 'movent': 2383, 'producement': 2384, 'dummerer': 2385, 'sprig': 2386, 'vs': 2387, 'betide': 2388, 'filtered': 2389, 'communization': 2390, 'loges': 2391, 'formelt': 2392, 'listred': 2393, 'who': 2394, 'oftest': 2395, 'fodder': 2396, 'helder': 2397, 'sifted': 2398, 'eskil': 2399, 'hb': 2400, 'trent': 2401, 'forfalt': 2402, 'fem': 2403, 'bud': 2404, 'introducement': 2405, 'nidiot': 2406, 'sotik': 2407, 'fujis': 2408, 'fod': 2409, 'confirm': 2410, 'irak': 2411, 'tringle': 2412, 'andvare': 2413, 'ekes': 2414, 'boling': 2415, 'godsent': 2416, 'heder': 2417, 'gymnasium': 2418, 'warfaring': 2419, 'fall': 2420, 'anser': 2421, 'grum': 2422, 'puns': 2423, 'anything': 2424, 'smrrebrd': 2425, 'got': 2426, 'brad': 2427, 'unpopular': 2428, 'ancome': 2429, 'overlick': 2430, 'markan': 2431, 'wendeline': 2432, 'koner': 2433, 'voeten': 2434, 'hynder': 2435, 'nam': 2436, 'taber': 2437, 'content': 2438, 'fougere': 2439, 'svres': 2440, 'candidate': 2441, 'caserne': 2442, 'fine': 2443, 'garonne': 2444, 'vintages': 2445, 'lune': 2446, 'ringer': 2447, 'manter': 2448, 'starlet': 2449, 'evolutions': 2450, 'pastas': 2451, 'kosti': 2452, 'brat': 2453, 'opera': 2454, 'ensampler': 2455, 'rh': 2456, 'bro': 2457, 'plan': 2458, 'mello': 2459, 'gujar': 2460, 'whit': 2461, 'luck': 2462, 'tot': 2463, 'addressed': 2464, 'positive': 2465, 'steaning': 2466, 'soupiere': 2467, 'mord': 2468, 'gteborg': 2469, 'mantid': 2470, 'pret': 2471, 'frust': 2472, 'listed': 2473, 'forbearer': 2474, 'frutage': 2475, 'slapper': 2476, 'reclaimer': 2477, 'tema': 2478, 'pink': 2479, 'lj': 2480, 'delete': 2481, 'blick': 2482, 'grike': 2483, 'mors': 2484, 'historier': 2485, 'klemme': 2486, 'glimp': 2487, 'rigsdag': 2488, 'conservative': 2489, 'mount': 2490, 'everest': 2491, 'rort': 2492, 'avant': 2493, 'silvester': 2494, 'bull': 2495, 'vodka': 2496, 'blesseder': 2497, 'everything': 2498, 'monarski': 2499, 'camister': 2500, 'if': 2501, 'strake': 2502, 'fator': 2503, 'yukked': 2504, 'smuggle': 2505, 'relevate': 2506, 'reformation': 2507, 'sondage': 2508, 'swiftlet': 2509, 'lozere': 2510, 'from': 2511, 'helse': 2512, 'drisk': 2513, 'regine': 2514, 'bon': 2515, 'democratise': 2516, 'dictature': 2517, 'islamise': 2518, 'kiss': 2519, 'subedits': 2520, 'forrest': 2521, 'rationale': 2522, 'aldermen': 2523, 'jest': 2524, 'truest': 2525, 'sir': 2526, 'ifs': 2527, 'tubelike': 2528, 'englanders': 2529, 'landsmen': 2530, 'kingdom': 2531, 'spag': 2532, 'amiret': 2533, 'simplest': 2534, 'mistake': 2535, 'flyman': 2536, 'americanese': 2537, 'mdt': 2538, 'christiansburg': 2539, 'gag': 2540, 'landholder': 2541, 'lackering': 2542, 'lister': 2543, 'host': 2544, 'overrake': 2545, 'brande': 2546, 'virden': 2547, 'tip': 2548, 'sofa': 2549, 'kaffer': 2550, 'liberal': 2551, 'kendre': 2552, 'luk': 2553, 'parleyer': 2554, 'fordoes': 2555, 'speak': 2556, 'tradition': 2557, 'porer': 2558, 'noma': 2559, 'farfara': 2560, 'bunker': 2561, 'lapper': 2562, 'sk': 2563, 'henig': 2564, 'christian': 2565, 'gitter': 2566, 'senate': 2567, 'benighted': 2568, 'kimper': 2569, 'merope': 2570, 'stunt': 2571, 'flathat': 2572, 'hund': 2573, 'potentiate': 2574, 'cludder': 2575, 'fren': 2576, 'tacker': 2577, 'sitta': 2578, 'talar': 2579, 'hamlen': 2580, 'bade': 2581, 'bus': 2582, 'drud': 2583, 'time': 2584, 'rbe': 2585, 'sortlige': 2586, 'atter': 2587, 'kler': 2588, 'ballerine': 2589, 'bitte': 2590, 'korbut': 2591, 'punter': 2592, 'alemite': 2593, 'flanken': 2594, 'interfinger': 2595, 'sinker': 2596, 'fyrd': 2597, 'fanger': 2598, 'dane': 2599, 'ama': 2600, 'ftw': 2601, 'foramens': 2602, 'landes': 2603, 'apostasis': 2604, 'islamism': 2605, 'minorite': 2606, 'acceptable': 2607, 'kumler': 2608, 'oven': 2609, 'delton': 2610, 'respondents': 2611, 'crime': 2612, 'high': 2613, 'marten': 2614, 'duo': 2615, 'yb': 2616, 'bengt': 2617, 'forgemen': 2618, 'ac': 2619, 'blase': 2620, 'holpen': 2621, 'asset': 2622, 'individed': 2623, 'undigne': 2624, 'stranded': 2625, 'slaver': 2626, 'traditionally': 2627, 'ug': 2628, 'hypho': 2629, 'grissen': 2630, 'usednt': 2631, 'jams': 2632, 'battles': 2633, 'demobbed': 2634, 'pudgier': 2635, 'oaklet': 2636, 'appere': 2637, 'lyrid': 2638, 'flow': 2639, 'playlist': 2640, 'hungerer': 2641, 'prestige': 2642, 'minister': 2643, 'fugling': 2644, 'passade': 2645, 'kum': 2646, 'foreset': 2647, 'pm': 2648, 'unsight': 2649, 'bastide': 2650, 'points': 2651, 'blist': 2652, 'chef': 2653, 'verlag': 2654, 'fronter': 2655, 'bonus': 2656, 'yes': 2657, 'ak': 2658, 'incede': 2659, 'site': 2660, 'horde': 2661, 'stropper': 2662, 'misbede': 2663, 'tsk': 2664, 'blip': 2665, 'sett': 2666, 'respecter': 2667, 'evenlight': 2668, 'reedits': 2669, 'unglad': 2670, 'kaenel': 2671, 'kelder': 2672, 'posen': 2673, 'oslo': 2674, 'producer': 2675, 'menald': 2676, 'rundle': 2677, 'feminist': 2678, 'taxmen': 2679, 'anderssen': 2680, 'myrt': 2681, 'melded': 2682, 'ammelide': 2683, 'nerves': 2684, 'bigwigs': 2685, 'triaster': 2686, 'riden': 2687, 'stites': 2688, 'burger': 2689, 'transport': 2690, 'tasked': 2691, 'latrede': 2692, 'copperware': 2693, 'lod': 2694, 'min': 2695, 'refunder': 2696, 'jason': 2697, 'aortal': 2698, 'farding': 2699, 'martins': 2700, 'skibbet': 2701, 'plankage': 2702, 'cordele': 2703, 'sold': 2704, 'fallout': 2705, 'dree': 2706, 'killig': 2707, 'cycle': 2708, 'force': 2709, 'foutre': 2710, 'tantra': 2711, 'lentisk': 2712, 'nationalism': 2713, 'harm': 2714, 'communise': 2715, 'madag': 2716, 'osset': 2717, 'vd': 2718, 'terror': 2719, 'vest': 2720, 'dashed': 2721, 'lykes': 2722, 'felt': 2723, 'coke': 2724, 'trike': 2725, 'glogg': 2726, 'hollands': 2727, 'overall': 2728, 'safe': 2729, 'baud': 2730, 'lift': 2731, 'drongo': 2732, 'apropos': 2733, 'nette': 2734, 'reality': 2735, 'mr': 2736, 'urgers': 2737, 'rain': 2738, 'kythed': 2739, 'thai': 2740, 'fly': 2741, 'karim': 2742, 'hultgren': 2743, 'crazy': 2744, 'forlane': 2745, 'proportioner': 2746, 'hinder': 2747, 'atlas': 2748, 'bulten': 2749, 'salting': 2750, 'flt': 2751, 'drunkest': 2752, 'kristien': 2753, 'sand': 2754, 'turne': 2755, 'jagat': 2756, 'sindle': 2757, 'spindell': 2758, 'segment': 2759, 'muset': 2760, 'drive': 2761, 'via': 2762, 'parapsis': 2763, 'blander': 2764, 'smalt': 2765, 'podvin': 2766, 'stationer': 2767, 'prisere': 2768, 'varan': 2769, 'urlar': 2770, 'dum': 2771, 'rg': 2772, 'lammer': 2773, 'legitimizer': 2774, 'marker': 2775, 'also': 2776, 'known': 2777, 'as': 2778, 'mohammad': 2779, 'boxes': 2780, 'gambling': 2781, 'ww': 2782, 'kedge': 2783, 'call': 2784, 'dropped': 2785, 'forbidder': 2786, 'greatest': 2787, 'cv': 2788, 'overeager': 2789, 'white': 2790, 'trash': 2791, 'matson': 2792, 'susanne': 2793, 'samale': 2794, 'studerite': 2795, 'sneak': 2796, 'oo': 2797, 'hate': 2798, 'rehandling': 2799, 'ryter': 2800, 'nisen': 2801, 'organise': 2802, 'translate': 2803, 'spearlike': 2804, 'enseam': 2805, 'slave': 2806, 'tilture': 2807, 'crosne': 2808, 'world': 2809, 'lyse': 2810, 'ligget': 2811, 've': 2812, 'hiren': 2813, 'punkt': 2814, 'lowmen': 2815, 'biograph': 2816, 'typer': 2817, 'markmen': 2818, 'innuendo': 2819, 'some': 2820, 'spor': 2821, 'truller': 2822, 'tomme': 2823, 'moliere': 2824, 'helenus': 2825, 'unsevere': 2826, 'annat': 2827, 'osteen': 2828, 'juang': 2829, 'munster': 2830, 'overswift': 2831, 'explat': 2832, 'immigrant': 2833, 'bast': 2834, 'data': 2835, 'podanger': 2836, 'abstaining': 2837, 'salterns': 2838, 'oversated': 2839, 'drennen': 2840, 'skegger': 2841, 'orange': 2842, 'rigelian': 2843, 'fools': 2844, 'figury': 2845, 'kru': 2846, 'cumshot': 2847, 'profiler': 2848, 'hylist': 2849, 'beset': 2850, 'tal': 2851, 'gusle': 2852, 'see': 2853, 'gives': 2854, 'rene': 2855, 'nasser': 2856, 'overhauling': 2857, 'tentage': 2858, 'sticket': 2859, 'moderne': 2860, 'nordheim': 2861, 'jpeg': 2862, 'trusser': 2863, 'bedrift': 2864, 'christ': 2865, 'be': 2866, 'uu': 2867, 'gtingen': 2868, 'application': 2869, 'menkar': 2870, 'oss': 2871, 'staffete': 2872, 'restating': 2873, 'messere': 2874, 'pape': 2875, 'april': 2876, 'sprank': 2877, 'potent': 2878, 'ta': 2879, 'leveret': 2880, 'heddle': 2881, 'aller': 2882, 'sterne': 2883, 'twyver': 2884, 'grylle': 2885, 'wildered': 2886, 'emilie': 2887, 'oto': 2888, 'typeform': 2889, 'per': 2890, 'salat': 2891, 'affret': 2892, 'bajer': 2893, 'pol': 2894, 'banneret': 2895, 'kultur': 2896, 'eurotas': 2897, 'gres': 2898, 'ky': 2899, 'retter': 2900, 'mild': 2901, 'leftest': 2902, 'longing': 2903, 'nudens': 2904, 'episode': 2905, 'sisson': 2906, 'spurt': 2907, 'interfere': 2908, 'hubba': 2909, 'marius': 2910, 'temne': 2911, 'tyr': 2912, 'escort': 2913, 'caffein': 2914, 'rander': 2915, 'beton': 2916, 'couture': 2917, 'li': 2918, 'mudra': 2919, 'kildee': 2920, 'ah': 2921, 'nde': 2922, 'rosene': 2923, 'duende': 2924, 'visit': 2925, 'superhet': 2926, 'fayre': 2927, 'tintage': 2928, 'barden': 2929, 'debind': 2930, 'surprise': 2931, 'gondolet': 2932, 'aborter': 2933, 'keligot': 2934, 'kemme': 2935, 'salute': 2936, 'malet': 2937, 'foredoes': 2938, 'oldsters': 2939, 'morgens': 2940, 'neg': 2941, 'gudren': 2942, 'traer': 2943, 'ringlet': 2944, 'spatter': 2945, 'sekyere': 2946, 'lette': 2947, 'michella': 2948, 'fister': 2949, 'unbold': 2950, 'lag': 2951, 'larimer': 2952, 'westerner': 2953, 'gypped': 2954, 'topper': 2955, 'strunted': 2956, 'heitler': 2957, 'trick': 2958, 'menders': 2959, 'hustled': 2960, 'alids': 2961, 'strammer': 2962, 'cursen': 2963, 'droit': 2964, 'bogan': 2965, 'speller': 2966, 'ingester': 2967, 'sportsmen': 2968, 'unganged': 2969, 'massacre': 2970, 'jef': 2971, 'rum': 2972, 'bort': 2973, 'single': 2974, 'russine': 2975, 'date': 2976, 'microcoat': 2977, 'fixe': 2978, 'stlg': 2979, 'merop': 2980, 'maglev': 2981, 'flensburg': 2982, 'august': 2983, 'krys': 2984, 'calenderer': 2985, 'ex': 2986, 'goddam': 2987, 'abends': 2988, 'springlet': 2989, 'hundreds': 2990, 'tourist': 2991, 'woffington': 2992, 'hoppet': 2993, 'dae': 2994, 'havener': 2995, 'profitter': 2996, 'ughten': 2997, 'oke': 2998, 'judder': 2999, 'november': 3000, 'oysterage': 3001, 'stung': 3002, 'upholden': 3003, 'surge': 3004, 'censurer': 3005, 'underages': 3006, 'um': 3007, 'thier': 3008, 'gbt': 3009, 'ich': 3010, 'moche': 3011, 'schone': 3012, 'zimmer': 3013, 'flagger': 3014, 'ulen': 3015, 'fattiest': 3016, 'chanst': 3017, 'portioner': 3018, 'foller': 3019, 'erund': 3020, 'mage': 3021, 'brave': 3022, 'craftint': 3023, 'casual': 3024, 'cilka': 3025, 'regrede': 3026, 'santalin': 3027, 'yeah': 3028, 'parsoness': 3029, 'sorry': 3030, 'roman': 3031, 'tandle': 3032, 'uppard': 3033, 'lichens': 3034, 'trish': 3035, 'regan': 3036, 'fiel': 3037, 'sistren': 3038, 'lissom': 3039, 'numine': 3040, 'february': 3041, 'numa': 3042, 'juli': 3043, 'datum': 3044, 'eade': 3045, 'course': 3046, 'owsen': 3047, 'hammel': 3048, 'missend': 3049, 'amsterdam': 3050, 'team': 3051, 'easy': 3052, 'staver': 3053, 'begar': 3054, 'wastrels': 3055, 'humorists': 3056, 'shortest': 3057, 'saucisse': 3058, 'funky': 3059, 'success': 3060, 'breeds': 3061, 'jealousy': 3062, 'arendt': 3063, 'trots': 3064, 'orante': 3065, 'trimmest': 3066, 'inclusive': 3067, 'marksmen': 3068, 'direst': 3069, 'discrete': 3070, 'seistan': 3071, 'granter': 3072, 'ment': 3073, 'stl': 3074, 'imperial': 3075, 'imperialise': 3076, 'compenser': 3077, 'ministrer': 3078, 'ges': 3079, 'astert': 3080, 'karmen': 3081, 'broker': 3082, 'slounge': 3083, 'shohet': 3084, 'lipped': 3085, 'xtc': 3086, 'lap': 3087, 'finesse': 3088, 'kvarner': 3089, 'auslese': 3090, 'registered': 3091, 'streamed': 3092, 'digital': 3093, 'tele': 3094, 'pain': 3095, 'skidder': 3096, 'exit': 3097, 'montagne': 3098, 'royalton': 3099, 'redrag': 3100, 'sensist': 3101, 'renelle': 3102, 'kaser': 3103, 'regreet': 3104, 'pris': 3105, 'stevia': 3106, 'labroids': 3107, 'reagree': 3108, 'rissian': 3109, 'esbjerg': 3110, 'line': 3111, 'indenture': 3112, 'universal': 3113, 'foreside': 3114, 'godart': 3115, 'stopples': 3116, 'asp': 3117, 'atom': 3118, 'bomb': 3119, 'fucker': 3120, 'pst': 3121, 'ahlgren': 3122, 'bildar': 3123, 'nederland': 3124, 'lps': 3125, 'el': 3126, 'metal': 3127, 'worcestershire': 3128, 'steno': 3129, 'lastrup': 3130, 'landed': 3131, 'royalist': 3132, 'nazis': 3133, 'fise': 3134, 'whatten': 3135, 'omar': 3136, 'anglings': 3137, 'guider': 3138, 'atheist': 3139, 'hilsa': 3140, 'tattoos': 3141, 'alumni': 3142, 'trojans': 3143, 'captan': 3144, 'kasper': 3145, 'kattegat': 3146, 'downloads': 3147, 'cpu': 3148, 'foresinger': 3149, 'delicatesse': 3150, 'supermarket': 3151, 'carolina': 3152, 'foreorder': 3153, 'entete': 3154, 'gi': 3155, 'smeek': 3156, 'lumpen': 3157, 'park': 3158, 'kohens': 3159, 'minke': 3160, 'fraken': 3161, 'blv': 3162, 'vessel': 3163, 'nationalty': 3164, 'sushi': 3165, 'dunder': 3166, 'gilding': 3167, 'burket': 3168, 'tegan': 3169, 'krieger': 3170, 'tossed': 3171, 'befriz': 3172, 'billard': 3173, 'ium': 3174, 'bounden': 3175, 'medinas': 3176, 'tester': 3177, 'folksiest': 3178, 'sumerco': 3179, 'overtalk': 3180, 'mentalities': 3181, 'oversand': 3182, 'canaler': 3183, 'untaken': 3184, 'underdig': 3185, 'advocaat': 3186, 'budget': 3187, 'contort': 3188, 'business': 3189, 'bilks': 3190, 'trend': 3191, 'modeller': 3192, 'uptide': 3193, 'signaler': 3194, 'ambassador': 3195, 'millionary': 3196, 'pyrene': 3197, 'lederer': 3198, 'melamin': 3199, 'honorer': 3200, 'yens': 3201, 'bedelve': 3202, 'kindrend': 3203, 'ledget': 3204, 'pingo': 3205, 'klops': 3206, 'midday': 3207, 'offspring': 3208, 'charge': 3209, 'unstring': 3210, 'stilbene': 3211, 'skats': 3212, 'sea': 3213, 'empire': 3214, 'ruled': 3215, 'cnut': 3216, 'victoria': 3217, 'cross': 3218, 'birddom': 3219, 'forme': 3220, 'dfs': 3221, 'tenementer': 3222, 'upmarket': 3223, 'alen': 3224, 'ransome': 3225, 'montre': 3226, 'fourer': 3227, 'luverne': 3228, 'pregnant': 3229, 'bornan': 3230, 'further': 3231, 'enquiries': 3232, 'hesitate': 3233, 'contact': 3234, 'phone': 3235, 'numbed': 3236, 'profession': 3237, 'lablab': 3238, 'gynecologist': 3239, 'punctum': 3240, 'driller': 3241, 'z': 3242, 'blatt': 3243, 'undercrypt': 3244, 'nelken': 3245, 'vend': 3246, 'ideologies': 3247, 'absurd': 3248, 'legitimizes': 3249, 'stoven': 3250, 'vivien': 3251, 'kilgore': 3252, 'rod': 3253, 'representant': 3254, 'bronder': 3255, 'preminister': 3256, 'fear': 3257, 'undercart': 3258, 'lycia': 3259, 'iraf': 3260, 'jolivet': 3261, 'lama': 3262, 'socialist': 3263, 'airposts': 3264, 'runecraft': 3265, 'miler': 3266, 'opiates': 3267, 'heard': 3268, 'first': 3269, 'sniffer': 3270, 'wagerers': 3271, 'horstes': 3272, 'ordeal': 3273, 'tatta': 3274, 'gnesen': 3275, 'bluffest': 3276, 'noe': 3277, 'sextet': 3278, 'serene': 3279, 'stralet': 3280, 'moji': 3281, 'msn': 3282, 'concept': 3283, 'triture': 3284, 'pingos': 3285, 'throatlet': 3286, 'ambit': 3287, 'upload': 3288, 'torrents': 3289, 'vpn': 3290, 'uploaded': 3291, 'bridge': 3292, 'mode': 3293, 'combination': 3294, 'tis': 3295, 'siret': 3296, 'revises': 3297, 'bakke': 3298, 'libken': 3299, 'skanda': 3300, 'unnapt': 3301, 'gra': 3302, 'inne': 3303, 'hora': 3304, 'universalis': 3305, 'dosis': 3306, 'barong': 3307, 'bugler': 3308, 'wisdom': 3309, 'skipper': 3310, 'cowboy': 3311, 'henka': 3312, 'usself': 3313, 'spurrers': 3314, 'respecters': 3315, 'brancher': 3316, 'skulker': 3317, 'different': 3318, 'name': 3319, 'hygeist': 3320, 'viren': 3321, 'parks': 3322, 'recreation': 3323, 'seiren': 3324, 'basest': 3325, 'helli': 3326, 'ble': 3327, 'importer': 3328, 'haddie': 3329, 'maidens': 3330, 'regisseur': 3331, 'knut': 3332, 'beswim': 3333, 'rikk': 3334, 'odeen': 3335, 'murlin': 3336, 'underlie': 3337, 'zygotes': 3338, 'mousee': 3339, 'patterned': 3340, 'hug': 3341, 'mangle': 3342, 'otlf': 3343, 'millard': 3344, 'affirmer': 3345, 'lustrum': 3346, 'godunov': 3347, 'geraldine': 3348, 'smr': 3349, 'uni': 3350, 'clinkerer': 3351, 'finner': 3352, 'cumulite': 3353, 'privata': 3354, 'forman': 3355, 'rendering': 3356, 'gooder': 3357, 'graver': 3358, 'perret': 3359, 'venine': 3360, 'epic': 3361, 'laban': 3362, 'chevet': 3363, 'mandates': 3364, 'forbad': 3365, 'eisk': 3366, 'feezed': 3367, 'signe': 3368, 'folden': 3369, 'bernt': 3370, 'tideling': 3371, 'bret': 3372, 'staw': 3373, 'segar': 3374, 'bucket': 3375, 'aidde': 3376, 'candour': 3377, 'low': 3378, 'altman': 3379, 'agaric': 3380, 'tendre': 3381, 'black': 3382, 'army': 3383, 'medle': 3384, 'bc': 3385, 'sociologese': 3386, 'bipedal': 3387, 'bide': 3388, 'kilimanjaro': 3389, 'mosier': 3390, 'mangled': 3391, 'graham': 3392, 'summerhouse': 3393, 'eye': 3394, 'q': 3395, 'funker': 3396, 'skivie': 3397, 'protid': 3398, 'sie': 3399, 'mein': 3400, 'gunter': 3401, 'herr': 3402, 'corruptions': 3403, 'bulge': 3404, 'chokered': 3405, 'examiner': 3406, 'nemo': 3407, 'hamler': 3408, 'grisset': 3409, 'grinners': 3410, 'skilken': 3411, 'graders': 3412, 'october': 3413, 'multi': 3414, 'messin': 3415, 'renaldo': 3416, 'kobold': 3417, 'discussions': 3418, 'relater': 3419, 'alibi': 3420, 'orgasm': 3421, 'tacket': 3422, 'kraut': 3423, 'provokee': 3424, 'whimmy': 3425, 'travest': 3426, 'skinhead': 3427, 'tave': 3428, 'bowstave': 3429, 'jeeps': 3430, 'ghetto': 3431, 'dan': 3432, 'fugitive': 3433, 'slattern': 3434, 'morale': 3435, 'monde': 3436, 'gymnasts': 3437, 'spilite': 3438, 'zirkelite': 3439, 'instilling': 3440, 'happy': 3441, 'sibrede': 3442, 'scorser': 3443, 'mrna': 3444, 'casebooks': 3445, 'tales': 3446, 'belage': 3447, 'stilb': 3448, 'athletic': 3449, 'formenti': 3450, 'medalled': 3451, 'racer': 3452, 'full': 3453, 'suspensions': 3454, 'gyppo': 3455, 'lub': 3456, 'regional': 3457, 'roff': 3458, 'tillered': 3459, 'kj': 3460, 'campagne': 3461, 'twitch': 3462, 'interactive': 3463, 'seabank': 3464, 'spore': 3465, 'hallouf': 3466, 'pile': 3467, 'antifat': 3468, 'ashkum': 3469, 'kylen': 3470, 'dj': 3471, 'represents': 3472, 'sommering': 3473, 'elat': 3474, 'fingered': 3475, 'motorcycle': 3476, 'knock': 3477, 'adamsen': 3478, 'figure': 3479, 'trees': 3480, 'filters': 3481, 'pu': 3482, 'branding': 3483, 'copain': 3484, 'closed': 3485, 'usk': 3486, 'franking': 3487, 'clinton': 3488, 'singer': 3489, 'slyke': 3490, 'mena': 3491, 'orten': 3492, 'dario': 3493, 'jurel': 3494, 'admiral': 3495, 'mn': 3496, 'orsk': 3497, 'programme': 3498, 'container': 3499, 'mysteries': 3500, 'perverse': 3501, 'roasters': 3502, 'colleger': 3503, 'lobes': 3504, 'primwort': 3505, 'kluang': 3506, 'campaigner': 3507, 'tent': 3508, 'cfht': 3509, 'drifter': 3510, 'maja': 3511, 'matilde': 3512, 'gto': 3513, 'flosser': 3514, 'evendale': 3515, 'memo': 3516, 'secret': 3517, 'service': 3518, 'handseling': 3519, 'tidelike': 3520, 'leesport': 3521, 'peternet': 3522, 'bacon': 3523, 'breakfast': 3524, 'raid': 3525, 'keyster': 3526, 'handicapped': 3527, 'civilization': 3528, 'yy': 3529, 'belleter': 3530, 'benny': 3531, 'anjan': 3532, 'jetty': 3533, 'interlaces': 3534, 'aidman': 3535, 'habdalah': 3536, 'als': 3537, 'buren': 3538, 'herscher': 3539, 'huloist': 3540, 'abe': 3541, 'optant': 3542, 'revokes': 3543, 'doling': 3544, 'detta': 3545, 'inge': 3546, 'para': 3547, 'prostitute': 3548, 'fadaise': 3549, 'berstel': 3550, 'portwin': 3551, 'wingback': 3552, 'chairs': 3553, 'rifart': 3554, 'tweed': 3555, 'underlapper': 3556, 'overgaard': 3557, 'miseno': 3558, 'unalert': 3559, 'bette': 3560, 'punch': 3561, 'ditted': 3562, 'femme': 3563, 'vendetta': 3564, 'muktuk': 3565, 'endurant': 3566, 'hauge': 3567, 'krs': 3568, 'stormberg': 3569, 'ovality': 3570, 'separatist': 3571, 'slobber': 3572, 'karolina': 3573, 'obligatorily': 3574, 'sdp': 3575, 'remord': 3576, 'grille': 3577, 'gloat': 3578, 'leiter': 3579, 'ranker': 3580, 'aefald': 3581, 'riddance': 3582, 'loader': 3583, 'proxy': 3584, 'ramses': 3585, 'dope': 3586, 'accepter': 3587, 'evolution': 3588, 'unvended': 3589, 'reorient': 3590, 'brune': 3591, 'landre': 3592, 'benighter': 3593, 'snort': 3594, 'mina': 3595, 'blond': 3596, 'andvari': 3597, 'rutan': 3598, 'geneina': 3599, 'coastmen': 3600, 'spindles': 3601, 'photo': 3602, 'bueno': 3603, 'tokyo': 3604, 'slanter': 3605, 'stager': 3606, 'parten': 3607, 'belibel': 3608, 'aldis': 3609, 'tortil': 3610, 'sparges': 3611, 'montale': 3612, 'moralise': 3613, 'renes': 3614, 'sok': 3615, 'boxen': 3616, 'sparklet': 3617, 'figl': 3618, 'upshove': 3619, 'finn': 3620, 'jamil': 3621, 'umpire': 3622, 'batlike': 3623, 'iaverne': 3624, 'fronton': 3625, 'manet': 3626, 'overline': 3627, 'stratege': 3628, 'fregit': 3629, 'evident': 3630, 'sheds': 3631, 'lagered': 3632, 'sampled': 3633, 'militate': 3634, 'hamfatter': 3635, 'koser': 3636, 'zeus': 3637, 'banderma': 3638, 'gid': 3639, 'madame': 3640, 'britt': 3641, 'sier': 3642, 'theia': 3643, 'cocklet': 3644, 'tandem': 3645, 'past': 3646, 'kreg': 3647, 'flagellator': 3648, 'skillern': 3649, 'cajun': 3650, 'sounds': 3651, 'fresne': 3652, 'spener': 3653, 'drab': 3654, 'ridges': 3655, 'precision': 3656, 'slipped': 3657, 'koktaite': 3658, 'spooner': 3659, 'orm': 3660, 'upsetter': 3661, 'klossner': 3662, 'brander': 3663, 'arsenal': 3664, 'effet': 3665, 'uprisen': 3666, 'raser': 3667, 'guldens': 3668, 'nilot': 3669, 'suspect': 3670, 'industries': 3671, 'overfag': 3672, 'assimilation': 3673, 'arenae': 3674, 'aligned': 3675, 'rhytta': 3676, 'forge': 3677, 'sams': 3678, 'slutter': 3679, 'kempas': 3680, 'farer': 3681, 'forfar': 3682, 'barbar': 3683, 'rager': 3684, 'slider': 3685, 'hilarious': 3686, 'barbarise': 3687, 'sparer': 3688, 'im': 3689, 'lendu': 3690, 'degradement': 3691, 'macron': 3692, 'sol': 3693, 'reducer': 3694, 'unfalse': 3695, 'gasket': 3696, 'cavaliere': 3697, 'collapse': 3698, 'kina': 3699, 'canadian': 3700, 'chocolate': 3701, 'computerese': 3702, 'krever': 3703, 'asat': 3704, 'kel': 3705, 'levi': 3706, 'detentive': 3707, 'jazeran': 3708, 'araise': 3709, 'pik': 3710, 'talker': 3711, 'hiper': 3712, 'pravda': 3713, 'ke': 3714, 'epner': 3715, 'gtt': 3716, 'sprew': 3717, 'baaskap': 3718, 'senn': 3719, 'brusker': 3720, 'superior': 3721, 'vendor': 3722, 'garbage': 3723, 'collecting': 3724, 'overfold': 3725, 'moldavia': 3726, 'barcelona': 3727, 'catalase': 3728, 'spanker': 3729, 'journalise': 3730, 'steere': 3731, 'zoos': 3732, 'scams': 3733, 'feature': 3734, 'summerset': 3735, 'localite': 3736, 'formeret': 3737, 'verst': 3738, 'pederast': 3739, 'meth': 3740, 'holders': 3741, 'brilliant': 3742, 'vatted': 3743, 'bohemian': 3744, 'hygiene': 3745, 'zymogen': 3746, 'undertone': 3747, 'raglans': 3748, 'rex': 3749, 'dinosaur': 3750, 'dyaster': 3751, 'begrave': 3752, 'defensive': 3753, 'mission': 3754, 'gurnard': 3755, 'yellow': 3756, 'fisken': 3757, 'element': 3758, 'sonarmen': 3759, 'gutter': 3760, 'pilgrimize': 3761, 'toke': 3762, 'apparat': 3763, 'generable': 3764, 'anode': 3765, 'deers': 3766, 'dubbeltje': 3767, 'betiding': 3768, 'haa': 3769, 'shadowland': 3770, 'borger': 3771, 'mudslinger': 3772, 'overgrew': 3773, 'vending': 3774, 'foreign': 3775, 'forestial': 3776, 'enarme': 3777, 'pasterned': 3778, 'compliment': 3779, 'fuckit': 3780, 'behoved': 3781, 'cordoning': 3782, 'flagg': 3783, 'gemeled': 3784, 'waner': 3785, 'tevet': 3786, 'bilbo': 3787, 'charles': 3788, 'solideo': 3789, 'geometrise': 3790, 'former': 3791, 'itel': 3792, 'destroy': 3793, 'interweld': 3794, 'ban': 3795, 'ro': 3796, 'mca': 3797, 'copyrighted': 3798, 'sausage': 3799, 'diastole': 3800, 'filtering': 3801, 'mv': 3802, 'function': 3803, 'megen': 3804, 'principe': 3805, 'incompetence': 3806, 'lugmark': 3807, 'henson': 3808, 'intelligence': 3809, 'scanned': 3810, 'moderner': 3811, 'andeee': 3812, 'forenote': 3813, 'testier': 3814, 'stands': 3815, 'gem': 3816, 'tie': 3817, 'reads': 3818, 'does': 3819, 'reply': 3820, 'kans': 3821, 'marijuana': 3822, 'jane': 3823, 'fart': 3824, 'joints': 3825, 'bund': 3826, 'madder': 3827, 'otte': 3828, 'ti': 3829, 'mix': 3830, 'filmset': 3831, 'sussing': 3832, 'brisken': 3833, 'latin': 3834, 'dfd': 3835, 'dispensation': 3836, 'strider': 3837, 'kraken': 3838, 'hockey': 3839, 'evener': 3840, 'rosette': 3841, 'behove': 3842, 'taraf': 3843, 'humph': 3844, 'lintel': 3845, 'helilift': 3846, 'capitaled': 3847, 'demands': 3848, 'femi': 3849, 'robot': 3850, 'smiled': 3851, 'disquiet': 3852, 'overton': 3853, 'fortress': 3854, 'pfunde': 3855, 'frigage': 3856, 'eagerer': 3857, 'cartoon': 3858, 'verier': 3859, 'easterners': 3860, 'statistic': 3861, 'kalle': 3862, 'faggot': 3863, 'windlings': 3864, 'ierne': 3865, 'manumitter': 3866, 'triggered': 3867, 'precise': 3868, 'trin': 3869, 'positival': 3870, 'smeller': 3871, 'handsaws': 3872, 'pigeon': 3873, 'podite': 3874, 'yorker': 3875, 'klick': 3876, 'knuffe': 3877, 'severed': 3878, 'skimmer': 3879, 'sisten': 3880, 'bokom': 3881, 'skims': 3882, 'edgerman': 3883, 'snaps': 3884, 'brunt': 3885, 'fatted': 3886, 'operation': 3887, 'unseat': 3888, 'patienter': 3889, 'localiser': 3890, 'aerostat': 3891, 'majesta': 3892, 'billed': 3893, 'sc': 3894, 'nurl': 3895, 'binded': 3896, 'async': 3897, 'await': 3898, 'es': 3899, 'coroutine': 3900, 'contrast': 3901, 'callbacks': 3902, 'futures': 3903, 'humble': 3904, 'alignment': 3905, 'chaotic': 3906, 'populist': 3907, 'slippery': 3908, 'slope': 3909, 'forheed': 3910, 'ter': 3911, 'maniere': 3912, 'frate': 3913, 'keiser': 3914, 'vamp': 3915, 'terne': 3916, 'fesels': 3917, 'kepped': 3918, 'invasion': 3919, 'managee': 3920, 'cordons': 3921, 'berte': 3922, 'integrities': 3923, 'smitten': 3924, 'vintner': 3925, 'context': 3926, 'applause': 3927, 'baum': 3928, 'reserene': 3929, 'hamleted': 3930, 'profile': 3931, 'ghost': 3932, 'henwise': 3933, 'takt': 3934, 'bnet': 3935, 'diverse': 3936, 'melote': 3937, 'toll': 3938, 'stearins': 3939, 'trets': 3940, 'tret': 3941, 'seidler': 3942, 'bassein': 3943, 'irrelevant': 3944, 'phyre': 3945, 'msf': 3946, 'symbols': 3947, 'upsend': 3948, 'olivia': 3949, 'propped': 3950, 'poudret': 3951, 'fernery': 3952, 'ramos': 3953, 'bayern': 3954, 'evangelise': 3955, 'evidence': 3956, 'labredt': 3957, 'enisle': 3958, 'dean': 3959, 'kooning': 3960, 'catalogic': 3961, 'forsake': 3962, 'ingenier': 3963, 'lanford': 3964, 'sister': 3965, 'amoret': 3966, 'kanter': 3967, 'serer': 3968, 'unsubscribed': 3969, 'himene': 3970, 'bolte': 3971, 'muling': 3972, 'whine': 3973, 'cringes': 3974, 'personable': 3975, 'craber': 3976, 'joser': 3977, 'infer': 3978, 'checkpoints': 3979, 'nykobing': 3980, 'formulizing': 3981, 'wisse': 3982, 'sneds': 3983, 'accept': 3984, 'gemmiest': 3985, 'cautioned': 3986, 'nazi': 3987, 'pressmen': 3988, 'indan': 3989, 'stedfast': 3990, 'london': 3991, 'severin': 3992, 'kamikaze': 3993, 'would': 3994, 'danes': 3995, 'won': 3996, 'landfast': 3997, 'mother': 3998, 'starost': 3999, 'bre': 4000, 'ribe': 4001, 'burns': 4002, 'distiller': 4003, 'religions': 4004, 'sheder': 4005, 'satanize': 4006, 'assentient': 4007, 'spin': 4008, 'ditherer': 4009, 'dehydrating': 4010, 'conference': 4011, 'messer': 4012, 'shaven': 4013, 'bandlet': 4014, 'fever': 4015, 'dreams': 4016, 'postage': 4017, 'invite': 4018, 'skinneries': 4019, 'formation': 4020, 'callet': 4021, 'sude': 4022, 'eldermen': 4023, 'skive': 4024, 'sorgo': 4025, 'mayonnaise': 4026, 'hoveler': 4027, 'improved': 4028, 'edition': 4029, 'diamante': 4030, 'fattest': 4031, 'herne': 4032, 'nomen': 4033, 'vernen': 4034, 'holt': 4035, 'hedvige': 4036, 'fresh': 4037, 'prince': 4038, 'eventually': 4039, 'doe': 4040, 'zulinde': 4041, 'abilene': 4042, 'maximum': 4043, 'deste': 4044, 'cpff': 4045, 'vector': 4046, 'iq': 4047, 'redive': 4048, 'anno': 4049, 'hollinger': 4050, 'way': 4051, 'bestill': 4052, 'stabile': 4053, 'berglund': 4054, 'falern': 4055, 'agates': 4056, 'stressed': 4057, 'overtense': 4058, 'godwin': 4059, 'law': 4060, 'discursion': 4061, 'pillarist': 4062, 'pizza': 4063, 'umset': 4064, 'postmundane': 4065, 'reoblige': 4066, 'knute': 4067, 'char': 4068, 'meeten': 4069, 'fjare': 4070, 'fires': 4071, 'sleep': 4072, 'pod': 4073, 'aliens': 4074, 'edmonton': 4075, 'alberta': 4076, 'obama': 4077, 'sign': 4078, 'friskier': 4079, 'frisure': 4080, 'burster': 4081, 'hairspray': 4082, 'margarine': 4083, 'smerked': 4084, 'ed': 4085, 'pacifist': 4086, 'whole': 4087, 'foods': 4088, 'hat': 4089, 'laden': 4090, 'santir': 4091, 'allvar': 4092, 'javler': 4093, 'porno': 4094, 'condolences': 4095, 'czech': 4096, 'navis': 4097, 'browser': 4098, 'sayette': 4099, 'underhang': 4100, 'scenter': 4101, 'telefilms': 4102, 'molar': 4103, 'bruno': 4104, 'mars': 4105, 'tilter': 4106, 'guillen': 4107, 'mums': 4108, 'suffer': 4109, 'overtalker': 4110, 'ronnie': 4111, 'trs': 4112, 'jaime': 4113, 'bien': 4114, 'longue': 4115, 'vie': 4116, 'au': 4117, 'datemark': 4118, 'drs': 4119, 'spiraster': 4120, 'sporeformer': 4121, 'broomer': 4122, 'tabel': 4123, 'stib': 4124, 'gender': 4125, 'stinger': 4126, 'ge': 4127, 'lavette': 4128, 'allene': 4129, 'medicine': 4130, 'evovae': 4131, 'bragite': 4132, 'asteroidea': 4133, 'vanner': 4134, 'brnaby': 4135, 'versta': 4136, 'rock': 4137, 'stammel': 4138, 'svend': 4139, 'spot': 4140, 'loke': 4141, 'farfet': 4142, 'pakse': 4143, 'hugest': 4144, 'mler': 4145, 'spengler': 4146, 'corrige': 4147, 'bastard': 4148, 'boy': 4149, 'against': 4150, 'solidated': 4151, 'prestation': 4152, 'dalar': 4153, 'meter': 4154, 'calmer': 4155, 'alansen': 4156, 'batlet': 4157, 'vibes': 4158, 'children': 4159, 'fellable': 4160, 'practisant': 4161, 'talkfest': 4162, 'idgah': 4163, 'fultz': 4164, 'ovules': 4165, 'huse': 4166, 'vagnera': 4167, 'vamped': 4168, 'matisse': 4169, 'troue': 4170, 'politest': 4171, 'finstad': 4172, 'evene': 4173, 'kravits': 4174, 'izar': 4175, 'hemipenis': 4176, 'gates': 4177, 'donald': 4178, 'knuth': 4179, 'tim': 4180, 'bernese': 4181, 'lee': 4182, 'diose': 4183, 'crush': 4184, 'seance': 4185, 'studite': 4186, 'auditories': 4187, 'alme': 4188, 'violet': 4189, 'spotty': 4190, 'eads': 4191, 'misplay': 4192, 'tier': 4193, 'voids': 4194, 'talien': 4195, 'guitar': 4196, 'cerises': 4197, 'starker': 4198, 'aaberg': 4199, 'splitter': 4200, 'escape': 4201, 'radke': 4202, 'steal': 4203, 'arisen': 4204, 'william': 4205, 'older': 4206, 'rollo': 4207, 'bum': 4208, 'stains': 4209, 'blastemic': 4210, 'aaaaaa': 4211, 'civiliser': 4212, 'edgy': 4213, 'bosone': 4214, 'forsete': 4215, 'tinges': 4216, 'trailers': 4217, 'mocker': 4218, 'trf': 4219, 'afrikaner': 4220, 'overhover': 4221, 'centrum': 4222, 'soleret': 4223, 'beginger': 4224, 'portrait': 4225, 'anaconda': 4226, 'elite': 4227, 'dangerous': 4228, 'disco': 4229, 'drasco': 4230, 'fuel': 4231, 'several': 4232, 'variants': 4233, 'gittle': 4234, 'afa': 4235, 'overlander': 4236, 'terrorise': 4237, 'pedagogish': 4238, 'knap': 4239, 'gram': 4240, 'bugle': 4241, 'pandean': 4242, 'copy': 4243, 'kinfolk': 4244, 'rejiggering': 4245, 'special': 4246, 'knotted': 4247, 'bonk': 4248, 'semmet': 4249, 'varien': 4250, 'lute': 4251, 'dresser': 4252, 'jas': 4253, 'ni': 4254, 'superbia': 4255, 'hymen': 4256, 'mast': 4257, 'arne': 4258, 'jacobsen': 4259, 'stol': 4260, 'stk': 4261, 'signor': 4262, 'haldes': 4263, 'damped': 4264, 'mail': 4265, 'haori': 4266, 'besiren': 4267, 'coloniser': 4268, 'legitim': 4269, 'civilisation': 4270, 'sverre': 4271, 'kulda': 4272, 'confirmed': 4273, 'typika': 4274, 'leaguering': 4275, 'gen': 4276, 'mus': 4277, 'valsa': 4278, 'perron': 4279, 'rumper': 4280, 'tappoon': 4281, 'ollen': 4282, 'vaulter': 4283, 'grinds': 4284, 'gears': 4285, 'bubber': 4286, 'choose': 4287, 'ties': 4288, 'overbar': 4289, 'danseur': 4290, 'ignorance': 4291, 'bliss': 4292, 'centetid': 4293, 'dulse': 4294, 'derived': 4295, 'attester': 4296, 'handful': 4297, 'nutters': 4298, 'sight': 4299, 'regel': 4300, 'underpinning': 4301, 'ajaja': 4302, 'bespatter': 4303, 'nb': 4304, 'rampler': 4305, 'kraft': 4306, 'mands': 4307, 'planulate': 4308, 'letta': 4309, 'yere': 4310, 'enjoy': 4311, 'kale': 4312, 'frays': 4313, 'golf': 4314, 'overleave': 4315, 'liters': 4316, 'hanover': 4317, 'fraser': 4318, 'hilde': 4319, 'liter': 4320, 'sob': 4321, 'unkent': 4322, 'isolt': 4323, 'kulmet': 4324, 'strega': 4325, 'paulsen': 4326, 'siderin': 4327, 'stirrers': 4328, 'chafing': 4329, 'abbrev': 4330, 'hypoderm': 4331, 'cocktail': 4332, 'piazzaed': 4333, 'poppet': 4334, 'krym': 4335, 'ogaden': 4336, 'panade': 4337, \"'m\": 4338, 'fredrik': 4339, 'rarp': 4340, 'franke': 4341, 'trevor': 4342, 'noah': 4343, 'agave': 4344, 'spy': 4345, 'trussell': 4346, 'citron': 4347, 'vag': 4348, 'dampen': 4349, 'champ': 4350, 'hearthstone': 4351, 'jodl': 4352, 'bucko': 4353, 'popular': 4354, 'dock': 4355, 'creaser': 4356, 'maneuvre': 4357, 'emmet': 4358, 'herbie': 4359, 'claim': 4360, \"'re\": 4361, 'naam': 4362, 'van': 4363, 'cso': 4364, 'been': 4365, 'linked': 4366, 'elsewhere': 4367, 'follow': 4368, 'any': 4369, 'above': 4370, 'respect': 4371, 'rules': 4372, \"don't\": 4373, 'comment': 4374, 'questions': 4375, 'abuse': 4376, 'message': 4377, 'tramp': 4378, 'disney': 4379, 'manurer': 4380, 'meannesses': 4381, 'pleat': 4382, 'were': 4383, 'asked': 4384, 'serious': 4385, 'level': 4386, 'higher': 4387, 'value': 4388, 'survey': 4389, 'believe': 4390, 'their': 4391, 'mlt': 4392, 'manage': 4393, 'reasoning': 4394, 'stalin': 4395, 'mao': 4396, 'blemmyes': 4397, 'millionist': 4398, 'slat': 4399, 'jackmen': 4400, 'moisty': 4401, 'plakat': 4402, 'wendelin': 4403, 'venue': 4404, 'stand': 4405, 'dyne': 4406, 'bord': 4407, 'dre': 4408, 'orillon': 4409, 'sedent': 4410, 'rattel': 4411, 'minuet': 4412, 'overview': 4413, 'auto': 4414, 'juster': 4415, 'elle': 4416, 'muvule': 4417, 'undrag': 4418, 'yodeller': 4419, 'proves': 4420, 'bage': 4421, 'lovett': 4422, 'vig': 4423, 'stuffender': 4424, 'herreid': 4425, 'lutidin': 4426, 'murderee': 4427, 'undern': 4428, 'grs': 4429, 'marmoreal': 4430, 'mildest': 4431, 'greige': 4432, 'pattern': 4433, 'partnering': 4434, 'grope': 4435, 'fetish': 4436, 'ransacking': 4437, 'spilt': 4438, 'filar': 4439, 'tl': 4440, 'fortin': 4441, 'adolf': 4442, 'lurkers': 4443, 'concert': 4444, 'skate': 4445, 'synonym': 4446, 'metae': 4447, 'max': 4448, 'camerate': 4449, 'dammer': 4450, 'fulgence': 4451, 'posit': 4452, 'beslab': 4453, 'chan': 4454, 'anyway': 4455, 'los': 4456, 'barre': 4457, 'billage': 4458, 'populists': 4459, 'tilyer': 4460, 'pension': 4461, 'disputer': 4462, 'pedagogery': 4463, 'glottis': 4464, 'preflight': 4465, 'watering': 4466, 'daters': 4467, 'france': 4468, 'winner': 4469, 'kaete': 4470, 'sandblind': 4471, 'hogger': 4472, 'voraz': 4473, 'snapped': 4474, 'bushlands': 4475, 'sovietise': 4476, 'formatters': 4477, 'identities': 4478, 'askile': 4479, 'sor': 4480, 'paris': 4481, 'vented': 4482, 'kop': 4483, 'parget': 4484, 'jamtland': 4485, 'infare': 4486, 'told': 4487, 'amt': 4488, 'boycott': 4489, 'sensible': 4490, 'bestseller': 4491, 'cheeseburger': 4492, 'ger': 4493, 'ragnarok': 4494, 'trials': 4495, 'fellow': 4496, 'kids': 4497, 'tweets': 4498, 'hevi': 4499, 'racial': 4500, 'profiling': 4501, 'notaeum': 4502, 'faster': 4503, 'kotlik': 4504, 'traditioner': 4505, 'forwoden': 4506, 'koppen': 4507, 'forfare': 4508, 'styrax': 4509, 'stare': 4510, 'bassett': 4511, 'perfecta': 4512, 'struck': 4513, 'update': 4514, 'anglish': 4515, 'thorps': 4516, 'hammer': 4517, 'dude': 4518, 'hunder': 4519, 'knepper': 4520, 'storden': 4521, 'eyes': 4522, 'hallo': 4523, 'supplanter': 4524, 'guess': 4525, 'hon': 4526, 'tundras': 4527, 'gallas': 4528, 'dogget': 4529, 'pinner': 4530, 'bda': 4531, 'isidor': 4532, 'hakdar': 4533, 'bestrut': 4534, 'cakra': 4535, 'sidman': 4536, 'sida': 4537, 'usfl': 4538, 'sered': 4539, 'fortread': 4540, 'klaus': 4541, 'real': 4542, 'remanet': 4543, 'clancy': 4544, 'tangerine': 4545, 'shirts': 4546, 'bent': 4547, 'fc': 4548, 'lassus': 4549, 'cheyenne': 4550, 'hulen': 4551, 'suite': 4552, 'capital': 4553, 'tate': 4554, 'angie': 4555, 'stickit': 4556, 'riffler': 4557, 'strid': 4558, 'grundlov': 4559, 'rehandle': 4560, 'trippet': 4561, 'grundyist': 4562, 'gs': 4563, 'misfare': 4564, 'sticker': 4565, 'redan': 4566, 'angelika': 4567, 'donee': 4568, 'underworker': 4569, 'neighed': 4570, 'princesse': 4571, 'giftie': 4572, 'miniseries': 4573, 'searest': 4574, 'officialty': 4575, 'factor': 4576, 'dobro': 4577, 'deaneries': 4578, 'arranger': 4579, 'events': 4580, 'fenmen': 4581, 'ligeti': 4582, 'talented': 4583, 'pit': 4584, 'gullygut': 4585, 'mta': 4586, 'nugent': 4587, 'svea': 4588, 'overdrives': 4589, 'taxa': 4590, 'morsel': 4591, 'selvage': 4592, 'greasy': 4593, 'spoon': 4594, 'telfords': 4595, 'junior': 4596, 'journalizer': 4597, 'sild': 4598, 'pokers': 4599, 'bunsen': 4600, 'keres': 4601, 'page': 4602, 'app': 4603, 'julien': 4604, 'animallike': 4605, 'snickers': 4606, 'dechen': 4607, 'copenhagen': 4608, 'foetid': 4609, 'fee': 4610, 'svan': 4611, 'lynen': 4612, 'tragule': 4613, 'jinsen': 4614, 'wordages': 4615, 'suede': 4616, 'ferned': 4617, 'stalk': 4618, 'wylde': 4619, 'innholder': 4620, 'skyler': 4621, 'saks': 4622, 'masker': 4623, 'stv': 4624, 'pose': 4625, 'kabiet': 4626, 'puttee': 4627, 'bagnet': 4628, 'snubbee': 4629, 'lyte': 4630, 'plantation': 4631, 'toilet': 4632, 'pause': 4633, 'heft': 4634, 'suto': 4635, 'inbending': 4636, 'toilette': 4637, 'ivorist': 4638, 'caste': 4639, 'lyburn': 4640, 'ka': 4641, 'sounded': 4642, 'mongol': 4643, 'smite': 4644, 'mealmen': 4645, 'bebump': 4646, 'inkom': 4647, 'speeded': 4648, 'busk': 4649, 'nik': 4650, 'venite': 4651, 'halte': 4652, 'klippe': 4653, 'mule': 4654, 'ringeye': 4655, 'hals': 4656, 'affa': 4657, 'rammed': 4658, 'strategize': 4659, 'undersetter': 4660, 'ir': 4661, 'limelight': 4662, 'grit': 4663, 'jillet': 4664, 'stereotypist': 4665, 'sodom': 4666, 'banked': 4667, 'arabele': 4668, 'kafir': 4669, 'munific': 4670, 'mobil': 4671, 'shame': 4672, 'lat': 4673, 'cannet': 4674, 'pc': 4675, 'sakeret': 4676, 'underdrift': 4677, 'document': 4678, 'jobbet': 4679, 'socialize': 4680, 'rodney': 4681, 'algerine': 4682, 'helge': 4683, 'tanks': 4684, 'devilet': 4685, 'whatabouts': 4686, 'forsar': 4687, 'lattermint': 4688, 'bismer': 4689, 'maddens': 4690, 'forsaker': 4691, 'rue': 4692, 'downstreet': 4693, 'vedro': 4694, 'overburdening': 4695, 'naive': 4696, 'reset': 4697, 'canuck': 4698, 'event': 4699, 'besayle': 4700, 'fedora': 4701, 'saltest': 4702, 'lavaret': 4703, 'association': 4704, 'denture': 4705, 'cod': 4706, 'vedist': 4707, 'germans': 4708, 'vse': 4709, 'cuisine': 4710, 'colonizer': 4711, 'disp': 4712, 'comic': 4713, 'sans': 4714, 'share': 4715, 'bureaucratic': 4716, 'sandaled': 4717, 'note': 4718, 'hillfort': 4719, 'hirst': 4720, 'herson': 4721, 'hooter': 4722, 'battlefront': 4723, 'arma': 4724, 'overwatch': 4725, 'subg': 4726, 'bose': 4727, 'eli': 4728, 'wordmen': 4729, 'tetter': 4730, 'bodd': 4731, 'work': 4732, 'sisel': 4733, 'attune': 4734, 'feverwort': 4735, 'mayo': 4736, 'verge': 4737, 'etherous': 4738, 'documentary': 4739, 'westbrook': 4740, 'baptist': 4741, 'church': 4742, 'unhold': 4743, 'wbc': 4744, 'protest': 4745, 'prostern': 4746, 'trusten': 4747, 'product': 4748, 'forgiver': 4749, 'brides': 4750, 'synonyme': 4751, 'bitcher': 4752, 'hollanders': 4753, 'hosteled': 4754, 'int': 4755, 'spruit': 4756, 'cat': 4757, 'kaden': 4758, 'overawning': 4759, 'inlaut': 4760, 'vergne': 4761, 'make': 4762, 'lagting': 4763, 'horn': 4764, 'fordone': 4765, 'patrolled': 4766, 'kironde': 4767, 'bing': 4768, 'bangkok': 4769, 'airways': 4770, 'fit': 4771, 'frase': 4772, 'undershrieve': 4773, 'fordrive': 4774, 'oppose': 4775, 'swivels': 4776, 'corrente': 4777, 'numberplate': 4778, 'dur': 4779, 'kamerad': 4780, 'appriser': 4781, 'sinjer': 4782, 'grethel': 4783, 'dingman': 4784, 'k9': 4785, 'nesta': 4786, 'gung': 4787, 'liptauer': 4788, 'einkanter': 4789, 'villate': 4790, 'meerkat': 4791, 'stinge': 4792, 'bf': 4793, 'fugal': 4794, 'upbrast': 4795, 'delist': 4796, 'producers': 4797, 'oehlenschlger': 4798, 'prejudice': 4799, 'kala': 4800, 'consomme': 4801, 'yank': 4802, 'miterer': 4803, 'yferre': 4804, 'jah': 4805, 'usan': 4806, 'mc': 4807, 'hares': 4808, 'luben': 4809, 'bulder': 4810, 'nonvoting': 4811, 'begin': 4812, 'demark': 4813, 'valdemar': 4814, 'tatterwag': 4815, 'sinner': 4816, 'lysander': 4817, 'vern': 4818, 'friedens': 4819, 'anne': 4820, 'mee': 4821, 'bundlet': 4822, 'bind': 4823, 'jeane': 4824, 'leet': 4825, 'milden': 4826, 'lashed': 4827, 'zero': 4828, 'delieret': 4829, 'offen': 4830, 'importee': 4831, 'ovey': 4832, 'verner': 4833, 'pretties': 4834, 'expeditionary': 4835, 'festivally': 4836, 'doom': 4837, 'eternal': 4838, 'sarnen': 4839, 'spret': 4840, 'marvel': 4841, 'mythologic': 4842, 'wars': 4843, 'universe': 4844, 'russkie': 4845, 'ericka': 4846, 'heb': 4847, 'slipper': 4848, 'montage': 4849, 'role': 4850, 'ur': 4851, 'sheikh': 4852, 'startup': 4853, 'hindering': 4854, 'salet': 4855, 'dong': 4856, 'stamens': 4857, 'limo': 4858, 'gigi': 4859, 'cigarette': 4860, 'casino': 4861, 'embeds': 4862, 'medford': 4863, 'lovee': 4864, 'messerschmitt': 4865, 'regioned': 4866, 'fhrer': 4867, 'remarket': 4868, 'stately': 4869, 'forswearer': 4870, 'inkle': 4871, 'fuk': 4872, 'ingar': 4873, 'notate': 4874, 'colature': 4875, 'foldure': 4876, 'syrups': 4877, 'kibe': 4878, 'montages': 4879, 'loyaler': 4880, 'deepen': 4881, 'offered': 4882, 'bindlet': 4883, 'energic': 4884, 'critism': 4885, 'hinkel': 4886, 'fossette': 4887, 'blink': 4888, 'pathetist': 4889, 'skyed': 4890, 'alive': 4891, 'djave': 4892, 'adventure': 4893, 'snakelet': 4894, 'click': 4895, 'manser': 4896, 'haven': 4897, 'evanid': 4898, 'broccoli': 4899, 'materialiser': 4900, 'better': 4901, 'analyst': 4902, 'nj': 4903, 'popple': 4904, 'blare': 4905, 'hers': 4906, 'warmest': 4907, 'fortalice': 4908, 'putage': 4909, 'maundful': 4910, 'hist': 4911, 'representee': 4912, 'flyer': 4913, 'adhering': 4914, 'joette': 4915, 'aaaa': 4916, 'leaflet': 4917, 'feedbags': 4918, \"'em\": 4919, 'coming': 4920, 'mandats': 4921, 'rivermen': 4922, 'tagged': 4923, 'kampseen': 4924, 'trigonella': 4925, 'lunar': 4926, 'move': 4927, 'brutalities': 4928, 'chaminade': 4929, 'financiere': 4930, 'kanal': 4931, 'yay': 4932, 'fieldale': 4933, 'froglet': 4934, 'signet': 4935, 'taffel': 4936, 'lesko': 4937, 'mater': 4938, 'starik': 4939, 'sirventes': 4940, 'tankroom': 4941, 'chains': 4942, 'credit': 4943, 'undig': 4944, 'pien': 4945, 'tracking': 4946, 'verlee': 4947, 'buplever': 4948, 'objective': 4949, 'ultragood': 4950, 'libitum': 4951, 'kirkmen': 4952, 'moses': 4953, 'platerer': 4954, 'borderer': 4955, 'garde': 4956, 'vg': 4957, 'das': 4958, 'knockwurst': 4959, 'deina': 4960, 'oder': 4961, 'bist': 4962, 'nur': 4963, 'froh': 4964, 'mich': 4965, 'sephen': 4966, 'vires': 4967, 'll': 4968, 'brulot': 4969, 'ormand': 4970, 'sandwich': 4971, 'undear': 4972, 'seedsmen': 4973, 'danforth': 4974, 'skin': 4975, 'stimulating': 4976, 'tiberine': 4977, 'acneform': 4978, 'bygo': 4979, 'thegn': 4980, 'smiting': 4981, 'awe': 4982, 'rerig': 4983, 'verger': 4984, 'biafra': 4985, 'sayner': 4986, 'ouvre': 4987, 'gingivae': 4988, 'mordent': 4989, 'dungan': 4990, 'duty': 4991, 'tapholes': 4992, 'gorum': 4993, 'antholite': 4994, 'realiser': 4995, 'kellene': 4996, 'outrider': 4997, 'puritans': 4998, 'truffe': 4999, 'amoralize': 5000, 'republicans': 5001, 'evangelical': 5002, 'phd': 5003, 'glacieret': 5004, 'angelate': 5005, 'reel': 5006, 'whesten': 5007, 'concrete': 5008, 'gasser': 5009, 'phip': 5010, 'makes': 5011, 'sense': 5012, 'rockne': 5013, 'base': 5014, 'bert': 5015, 'jargoner': 5016, 'telecon': 5017, 'strum': 5018, 'ganiats': 5019, 'lindgren': 5020, 'duvet': 5021, 'lover': 5022, 'bombe': 5023, 'spaciest': 5024, 'parterre': 5025, 'footholds': 5026, 'sallee': 5027, 'colleen': 5028, 'gravid': 5029, 'forestage': 5030, 'ntn': 5031, 'sorts': 5032, 'dogtie': 5033, 'iceland': 5034, 'rettig': 5035, 'oahu': 5036, 'gogh': 5037, 'sms': 5038, 'instantly': 5039, 'marler': 5040, 'unlimited': 5041, 'racing': 5042, 'ammo': 5043, 'abetment': 5044, 'inker': 5045, 'skull': 5046, 'vanille': 5047, 'phukked': 5048, 'sele': 5049, 'carton': 5050, 'barer': 5051, 'plasticise': 5052, 'lesage': 5053, 'foreteller': 5054, 'beetner': 5055, 'jentoft': 5056, 'hospital': 5057, 'mirkest': 5058, 'meld': 5059, 'sum': 5060, 'right': 5061, 'homester': 5062, 'runner': 5063, 'bassinet': 5064, 'flydye': 5065, 'oversetter': 5066, 'scam': 5067, 'pack': 5068, 'bodrag': 5069, 'shelve': 5070, 'underrated': 5071, 'konking': 5072, 'semirare': 5073, 'mider': 5074, 'jere': 5075, 'kindlers': 5076, 'cupcake': 5077, 'darfur': 5078, 'tartare': 5079, 'rossen': 5080, 'korea': 5081, 'thi': 5082, 'plunder': 5083, 'danelage': 5084, 'sb': 5085, 'stormbelt': 5086, 'updates': 5087, 'isdt': 5088, 'profited': 5089, 'shreve': 5090, 'antegarden': 5091, 'nazar': 5092, 'pensum': 5093, 'tinkerer': 5094, 'westerns': 5095, 'mag': 5096, 'instiller': 5097, 'caviling': 5098, 'bentlet': 5099, 'vaster': 5100, 'bridges': 5101, 'kab': 5102, 'jested': 5103, 'lusus': 5104, 'fredek': 5105, 'pratal': 5106, 'biz': 5107, 'mosk': 5108, 'wilser': 5109, 'usine': 5110, 'pot': 5111, 'scarpered': 5112, 'gladeye': 5113, 'simple': 5114, 'lt': 5115, 'nnx': 5116, 'docket': 5117, 'threat': 5118, 'surely': 5119, 'something': 5120, 'romantic': 5121, 'sexual': 5122, 'missing': 5123, 'thumbs': 5124, 'helsingor': 5125, 'dafter': 5126, 'goebbels': 5127, 'tentages': 5128, 'ofer': 5129, 'latterkin': 5130, 'digester': 5131, 'relight': 5132, 'wyve': 5133, 'revere': 5134, 'smutter': 5135, 'raftage': 5136, 'stipends': 5137, 'reordering': 5138, 'salami': 5139, 'ider': 5140, 'snop': 5141, 'firn': 5142, 'pudsey': 5143, 'glorie': 5144, 'repetoire': 5145, 'opiner': 5146, 'kammerer': 5147, 'beignet': 5148, 'dirten': 5149, 'untaste': 5150, 'oden': 5151, 'minta': 5152, 'venlin': 5153, 'night': 5154, 'theme': 5155, 'stride': 5156, 'strammel': 5157, 'humorer': 5158, 'categorizer': 5159, 'radiomen': 5160, 'mends': 5161, 'tantrik': 5162, 'sticta': 5163, 'niven': 5164, 'upstages': 5165, 'gayler': 5166, 'homer': 5167, 'overheating': 5168, 'fox': 5169, 'agenda': 5170, 'simon': 5171, 'spies': 5172, 'overleaven': 5173, 'mikron': 5174, 'humbug': 5175, 'neeger': 5176, 'norway': 5177, 'wunderbar': 5178, 'saving': 5179, 'snabby': 5180, 'mirror': 5181, 'kruller': 5182, 'costen': 5183, 'popper': 5184, 'torret': 5185, 'majos': 5186, 'spiles': 5187, 'pros': 5188, 'iuus': 5189, 'rave': 5190, 'taper': 5191, 'lofter': 5192, 'verek': 5193, 'mordvin': 5194, 'haoles': 5195, 'manor': 5196, 'stockpot': 5197, 'grammatic': 5198, 'we': 5199, 'champions': 5200, 'friends': 5201, 'sps': 5202, 'smelting': 5203, 'snider': 5204, 'distance': 5205, 'canale': 5206, 'isop': 5207, 'rolling': 5208, 'floor': 5209, 'torsk': 5210, 'edsel': 5211, 'indent': 5212, 'hah': 5213, 'religate': 5214, 'oresund': 5215, 'speiled': 5216, 'dreamt': 5217, 'befuddler': 5218, 'pironi': 5219, 'forecome': 5220, 'tychite': 5221, 'avoset': 5222, 'renest': 5223, 'longtimer': 5224, 'fordize': 5225, 'dave': 5226, 'chapelled': 5227, 'heads': 5228, 'bidet': 5229, 'hades': 5230, 'fload': 5231, 'agister': 5232, 'itch': 5233, 'originalities': 5234, 'ingest': 5235, 'lutfisk': 5236, 'mcg': 5237, 'representative': 5238, 'firmaments': 5239, 'slides': 5240, 'tuskers': 5241, 'norah': 5242, 'brear': 5243, 'formidable': 5244, 'swungen': 5245, 'uniform': 5246, 'busker': 5247, 'libelees': 5248, 'shirt': 5249, 'inverse': 5250, 'artier': 5251, 'uk': 5252, 'jack': 5253, 'acceptees': 5254, 'val': 5255, 'talent': 5256, 'wildcat': 5257, 'priseres': 5258, 'herter': 5259, 'invitees': 5260, 'sparkles': 5261, 'ardme': 5262, 'ski': 5263, 'folkestone': 5264, 'materiel': 5265, 'britisher': 5266, 'tyranni': 5267, 'marxism': 5268, 'hybrid': 5269, 'pusher': 5270, 'isus': 5271, 'darkens': 5272, 'landing': 5273, 'bested': 5274, 'outen': 5275, 'birkies': 5276, 'julis': 5277, 'borries': 5278, 'origen': 5279, 'pk': 5280, 'sound': 5281, 'cork': 5282, 'reposited': 5283, 'pynot': 5284, 'scopet': 5285, 'tobe': 5286, 'vigs': 5287, 'jewelry': 5288, 'sympatric': 5289, 'savine': 5290, 'thailand': 5291, 'arvell': 5292, 'dackered': 5293, 'minong': 5294, 'rilke': 5295, 'gude': 5296, 'shout': 5297, 'selene': 5298, 'grillparzer': 5299, 'airpark': 5300, 'ef': 5301, 'opium': 5302, 'brush': 5303, 'dynamist': 5304, 'interester': 5305, 'tun': 5306, 'ortrud': 5307, 'eastering': 5308, 'kind': 5309, 'awalt': 5310, 'elish': 5311, 'shitten': 5312, 'rat': 5313, 'ballade': 5314, 'levelland': 5315, 'forelady': 5316, 'nostalgia': 5317, 'knippa': 5318, 'unstar': 5319, 'summar': 5320, 'khondi': 5321, 'lasser': 5322, 'needless': 5323, 'say': 5324, 'forold': 5325, 'flambeed': 5326, 'dimensioned': 5327, 'face': 5328, 'swap': 5329, 'bt': 5330, 'hartals': 5331, 'kristiansand': 5332, 'boldine': 5333, 'beige': 5334, 'barkpeel': 5335, 'villaget': 5336, 'mobile': 5337, 'term': 5338, 'vener': 5339, 'dse': 5340, 'kenn': 5341, 'powerable': 5342, 'tomorrow': 5343, 'vitus': 5344, 'khud': 5345, 'rasmussen': 5346, 'silage': 5347, 'annalen': 5348, 'pistol': 5349, 'hostile': 5350, 'takeover': 5351, 'lieus': 5352, 'problematist': 5353, 'absurder': 5354, 'absurdities': 5355, 'swisser': 5356, 'canens': 5357, 'gondoliere': 5358, 'nre': 5359, 'knurs': 5360, 'scenarize': 5361, 'kinna': 5362, 'kelek': 5363, 'sartor': 5364, 'beriber': 5365, 'tezkere': 5366, 'diller': 5367, 'sink': 5368, 'stirrer': 5369, 'vara': 5370, 'goda': 5371, 'fern': 5372, 'uphold': 5373, 'guards': 5374, 'suffete': 5375, 'helmet': 5376, 'troner': 5377, 'skilty': 5378, 'damme': 5379, 'overhauler': 5380, 'moister': 5381, 'benote': 5382, 'eckel': 5383, 'torpedoer': 5384, 'evie': 5385, 'treddle': 5386, 'savager': 5387, 'hands': 5388, 'down': 5389, 'blitt': 5390, 'bjart': 5391, 'moderator': 5392, 'fagen': 5393, 'blackface': 5394, 'drubber': 5395, 'jiber': 5396, 'askov': 5397, 'circlejerk': 5398, 'bagdad': 5399, 'dabbled': 5400, 'needs': 5401, 'yp': 5402, 'rull': 5403, 'tourneying': 5404, 'cyclide': 5405, 'bovld': 5406, 'paranoia': 5407, 'people': 5408, 'bilder': 5409, 'smoko': 5410, 'automatism': 5411, 'platan': 5412, 'forset': 5413, 'danene': 5414, 'froude': 5415, 'augerer': 5416, 'malt': 5417, 'marvels': 5418, 'avengers': 5419, 'kopi': 5420, 'valhalla': 5421, 'honest': 5422, 'drafting': 5423, 'college': 5424, 'sansk': 5425, 'skeining': 5426, 'gillar': 5427, 'grimmer': 5428, 'nicola': 5429, 'lie': 5430, 'kaas': 5431, 'mini': 5432, 'lobbyist': 5433, 'nog': 5434, 'kapa': 5435, 'misuser': 5436, 'europe': 5437, 'doubling': 5438, 'subscribed': 5439, 'milligan': 5440, 'skien': 5441, 'ricker': 5442, 'onanist': 5443, 'lunt': 5444, 'klara': 5445, 'westling': 5446, 'imperialist': 5447, 'honer': 5448, 'hosteller': 5449, 'album': 5450, 'grignet': 5451, 'smell': 5452, 'behring': 5453, 'thank': 5454, 'approve': 5455, 'boycotted': 5456, 'television': 5457, 'xn': 5458, 'islandlike': 5459, 'donau': 5460, 'sandstorm': 5461, 'stay': 5462, 'classy': 5463, 'menes': 5464, 'streng': 5465, 'democratism': 5466, 'fastening': 5467, 'universally': 5468, 'constitutioner': 5469, 'oroide': 5470, 'garnet': 5471, 'emet': 5472, 'smart': 5473, 'member': 5474, 'vitis': 5475, 'papas': 5476, 'tested': 5477, 'motherfucker': 5478, 'levies': 5479, 'forlanas': 5480, 'converter': 5481, 'bestow': 5482, 'puts': 5483, 'embargo': 5484, 'american': 5485, 'replaces': 5486, 'with': 5487, 'masterless': 5488, 'visual': 5489, 'marbler': 5490, 'hejaz': 5491, 'friendly': 5492, 'bittern': 5493, 'walspere': 5494, 'mystique': 5495, 'woo': 5496, 'heeley': 5497, 'sags': 5498, 'lusaka': 5499, 'game': 5500, 'skilling': 5501, 'talliage': 5502, 'sandler': 5503, 'river': 5504, 'olag': 5505, 'player': 5506, 'pollex': 5507, 'enew': 5508, 'jehovah': 5509, 'advertiser': 5510, 'officially': 5511, 'motive': 5512, 'effective': 5513, 'hehe': 5514, 'olivet': 5515, 'sendai': 5516, 'stive': 5517, 'firedog': 5518, 'galeod': 5519, 'overbattle': 5520, 'handlings': 5521, 'always': 5522, 'bright': 5523, 'staning': 5524, 'fashion': 5525, 'argh': 5526, 'zikkurat': 5527, 'ratteen': 5528, 'encinder': 5529, 'nerve': 5530, 'skift': 5531, 'teleplays': 5532, 'sletten': 5533, 'festival': 5534, 'adminstration': 5535, 'hull': 5536, 'addam': 5537, 'missilemen': 5538, 'symbolise': 5539, 'enfort': 5540, 'indart': 5541, 'capitaliser': 5542, 'rotter': 5543, 'perfectionist': 5544, 'recolor': 5545, 'bet': 5546, 'solid': 5547, 'cirrus': 5548, 'indrafts': 5549, 'menage': 5550, 'gate': 5551, 'resist': 5552, 'cammal': 5553, 'rosat': 5554, 'bolivia': 5555, 'leva': 5556, 'deden': 5557, 'inst': 5558, 'plastin': 5559, 'joe': 5560, 'juice': 5561, 'deliberately': 5562, 'stirs': 5563, 'trouble': 5564, 'account': 5565, 'director': 5566, 'muumuu': 5567, 'nsw': 5568, 'rets': 5569, 'hit': 5570, 'rider': 5571, 'mso': 5572, 'september': 5573, 'fanged': 5574, 'fascination': 5575, 'fause': 5576, 'ideta': 5577, 'kersten': 5578, 'tramper': 5579, 'kopeisk': 5580, 'sydelle': 5581, 'projet': 5582, 'candidates': 5583, 'cbs': 5584, 'cowboys': 5585, 'paperer': 5586, 'tripple': 5587, 'giraffe': 5588, 'kulla': 5589, 'prob': 5590, 'loglet': 5591, 'akh': 5592, 'myself': 5593, 'pimping': 5594, 'bullshit': 5595, 'excel': 5596, 'logis': 5597, 'platte': 5598, 'routes': 5599, 'jst': 5600, 'mekka': 5601, 'tynd': 5602, 'mauve': 5603, 'inwind': 5604, 'nvh': 5605, 'messias': 5606, 'durene': 5607, 'larget': 5608, 'liker': 5609, 'flair': 5610, 'dragee': 5611, 'grotesk': 5612, 'zones': 5613, 'hol': 5614, 'animation': 5615, 'hunter': 5616, 'thompsons': 5617, 'routine': 5618, 'snup': 5619, 'aflare': 5620, 'maritime': 5621, 'skelet': 5622, 'impel': 5623, 'family': 5624, 'drat': 5625, 'gasmaker': 5626, 'postlude': 5627, 'udele': 5628, 'dhl': 5629, 'gils': 5630, 'bring': 5631, 'addresser': 5632, 'brev': 5633, 'cornet': 5634, 'fete': 5635, 'underhole': 5636, 'wunna': 5637, 'tillinger': 5638, 'kv': 5639, 'kg': 5640, 'eched': 5641, 'serenes': 5642, 'general': 5643, 'bebaste': 5644, 'populares': 5645, 'pleaser': 5646, 'ledge': 5647, 'treppe': 5648, 'trine': 5649, 'praesens': 5650, 'comrade': 5651, 'fantails': 5652, 'loop': 5653, 'insanity': 5654, 'turkism': 5655, 'fatten': 5656, 'ataturk': 5657, 'vision': 5658, 'underlinings': 5659, 'fort': 5660, 'resiner': 5661, 'preposter': 5662, 'forlive': 5663, 'bornane': 5664, 'features': 5665, 'rust': 5666, 'performant': 5667, 'metalled': 5668, 'balance': 5669, 'tempel': 5670, 'nse': 5671, 'drugs': 5672, 'pamperer': 5673, 'sanderling': 5674, 'boland': 5675, 'research': 5676, 'scotland': 5677, 'drink': 5678, 'henden': 5679, 'hugh': 5680, 'five': 5681, 'malone': 5682, 'hamster': 5683, 'dragline': 5684, 'bland': 5685, 'ansate': 5686, 'ingiver': 5687, 'trouser': 5688, 'valer': 5689, 'rillet': 5690, 'intelligent': 5691, 'erasmus': 5692, 'vildly': 5693, 'krogh': 5694, 'bider': 5695, 'desperation': 5696, 'fugere': 5697, 'rattened': 5698, 'potentilla': 5699, 'penster': 5700, 'undisputed': 5701, 'fenester': 5702, 'sombre': 5703, 'portment': 5704, 'costa': 5705, 'rica': 5706, 'minimum': 5707, 'funny': 5708, 'barken': 5709, 'pylle': 5710, 'ligule': 5711, 'concio': 5712, 'narwhal': 5713, 'harrar': 5714, 'sattar': 5715, 'undure': 5716, 'australian': 5717, 'mishandled': 5718, 'opdu': 5719, 'offhand': 5720, 'viborg': 5721, 'dali': 5722, 'torn': 5723, 'shiv': 5724, 'granted': 5725, 'parer': 5726, 'overdrive': 5727, 'appet': 5728, 'delft': 5729, 'cartan': 5730, 'brian': 5731, 'slaby': 5732, 'aerier': 5733, 'indwelt': 5734, 'ts': 5735, 'mat': 5736, 'hela': 5737, 'plundered': 5738, 'taa': 5739, 'edt': 5740, 'vorant': 5741, 'almont': 5742, 'junger': 5743, 'integration': 5744, 'somalia': 5745, 'womanlier': 5746, 'gift': 5747, 'finsen': 5748, 'assimilate': 5749, 'radar': 5750, 'sprenge': 5751, 'berber': 5752, 'forwander': 5753, 'ml': 5754, 'outline': 5755, 'inturning': 5756, 'profit': 5757, 'radial': 5758, 'igdyr': 5759, 'mafia': 5760, 'storm': 5761, 'superman': 5762, 'gear': 5763, 'sansone': 5764, 'heredes': 5765, 'levee': 5766, 'skyrin': 5767, 'belongs': 5768, 'sords': 5769, 'erke': 5770, 'elve': 5771, 'graffer': 5772, 'khalifat': 5773, 'prickly': 5774, 'nitter': 5775, 'kantner': 5776, 'ridgeling': 5777, 'pisk': 5778, 'ps': 5779, 'league': 5780, 'legends': 5781, 'discede': 5782, 'stream': 5783, 'shots': 5784, 'fired': 5785, 'gezira': 5786, 'strength': 5787, 'uret': 5788, 'querent': 5789, 'dit': 5790, 'mcdonald': 5791, 'kludge': 5792, 'asian': 5793, 'zinder': 5794, 'kermit': 5795, 'eurovision': 5796, 'soldered': 5797, 'horney': 5798, 'gemses': 5799, 'dresses': 5800, 'hearses': 5801, 'vile': 5802, 'kinsler': 5803, 'instant': 5804, 'thomas': 5805, 'astrer': 5806, 'fader': 5807, 'uppent': 5808, 'nutlet': 5809, 'jobcentre': 5810, 'servicewomen': 5811, 'wistrup': 5812, 'jen': 5813, 'indirected': 5814, 'stormer': 5815, 'nodiak': 5816, 'nitella': 5817, 'stresser': 5818, 'ager': 5819, 'glop': 5820, 'filmed': 5821, 'fustet': 5822, 'creme': 5823, 'ingredients': 5824, 'rt': 5825, 'fortlet': 5826, 'pander': 5827, 'gambrill': 5828, 'achenes': 5829, 'brise': 5830, 'bike': 5831, 'brothers': 5832, 'unite': 5833, 'hder': 5834, 'logger': 5835, 'scrime': 5836, 'l5': 5837, 'roitelet': 5838, 'bullet': 5839, 'lofted': 5840, 'danny': 5841, 'sorensen': 5842, 'coach': 5843, 'zonic': 5844, 'tenet': 5845, 'ell': 5846, 'dearth': 5847, 'maul': 5848, 'dueling': 5849, 'happiest': 5850, 'countries': 5851, 'cnn': 5852, 'amount': 5853, 'health': 5854, 'represent': 5855, 'tkt': 5856, 'uppluck': 5857, 'multurer': 5858, 'harmonist': 5859, 'springer': 5860, 'justin': 5861, 'timberlike': 5862, 'burhans': 5863, 'porringer': 5864, 'spile': 5865, 'musculature': 5866, 'tappet': 5867, 'berger': 5868, 'slenderest': 5869, 'gurgled': 5870, 'gravemaster': 5871, 'heusen': 5872, 'gimlet': 5873, 'historic': 5874, 'girl': 5875, 'fortune': 5876, 'paul': 5877, 'cojones': 5878, 'oral': 5879, 'history': 5880, 'vorster': 5881, 'style': 5882, 'originant': 5883, 'heimdal': 5884, 'bolded': 5885, 'bifrost': 5886, 'mott': 5887, 'aidant': 5888, 'mosso': 5889, 'hd': 5890, 'rounder': 5891, 'had': 5892, 'then': 5893, 'took': 5894, 'away': 5895, 'prostitution': 5896, 'blind': 5897, 'fellfare': 5898, 'marathoner': 5899, 'striations': 5900, 'rte': 5901, 'kal': 5902, 'mar': 5903, 'flasker': 5904, 'mermen': 5905, 'proud': 5906, 'crap': 5907, 'tolbert': 5908, 'videotex': 5909, 'breaking': 5910, 'telephoner': 5911, 'asperated': 5912, 'orlov': 5913, 'chetif': 5914, 'falser': 5915, 'mandom': 5916, 'marica': 5917, 'plzen': 5918, 'tune': 5919, 'md': 5920, 'menken': 5921, 'discussion': 5922, 'vidame': 5923, 'prisca': 5924, 'stot': 5925, 'redded': 5926, 'lode': 5927, 'grounding': 5928, 'soaked': 5929, 'bleach': 5930, 'skidded': 5931, 'amadi': 5932, 'inna': 5933, 'roller': 5934, 'nationless': 5935, 'israel': 5936, 'unofficial': 5937, 'dags': 5938, 'rb': 5939, 'estonia': 5940, 'hub': 5941, 'governance': 5942, 'model': 5943, 'forgers': 5944, 'lawgiver': 5945, 'privative': 5946, 'cannabis': 5947, 'vigny': 5948, 'klavier': 5949, 'redheart': 5950, 'neetup': 5951, 'promenade': 5952, 'metoxeny': 5953, 'mah': 5954, 'ethnish': 5955, 'juliet': 5956, 'tigger': 5957, 'sage': 5958, 'vintager': 5959, 'adeling': 5960, 'fruiterer': 5961, 'biffin': 5962, 'trailered': 5963, 'jobina': 5964, 'sambar': 5965, 'sharpe': 5966, 'starstruck': 5967, 'smiter': 5968, 'japha': 5969, 'tinstone': 5970, 'potations': 5971, 'tab': 5972, 'ooplast': 5973, 'a1': 5974, 'voltage': 5975, 'illa': 5976, 'okta': 5977, 'fil': 5978, 'kovar': 5979, 'flagstone': 5980, 'oldstyle': 5981, 'debater': 5982, 'bergere': 5983, 'imagen': 5984, 'binder': 5985, 'hordeate': 5986, 'forb': 5987, 'hash': 5988, 'kirklin': 5989, 'shelden': 5990, 'upgrave': 5991, 'lockout': 5992, 'seskin': 5993, 'jsw': 5994, 'vasa': 5995, 'sandbag': 5996, 'overfallen': 5997, 'leglen': 5998, 'jwahar': 5999, 'ukraine': 6000, 'skilder': 6001, 'yah': 6002, 'consistent': 6003, 'excellent': 6004, 'reflecter': 6005, 'harshen': 6006, 'dermoid': 6007, 'andrade': 6008, 'hang': 6009, 'pinder': 6010, 'upstood': 6011, 'apathist': 6012, 'felten': 6013, 'natter': 6014, 'daylight': 6015, 'patise': 6016, 'tige': 6017, 'frigid': 6018, 'ddr': 6019, 'henghold': 6020, 'gater': 6021, 'vane': 6022, 'skt': 6023, 'selvedges': 6024, 'ruben': 6025, 'nationaliser': 6026, 'toking': 6027, 'beplaster': 6028, 'moling': 6029, 'mlles': 6030, 'dorbug': 6031, 'destruction': 6032, 'catch': 6033, 'fm': 6034, 'friskers': 6035, 'democratic': 6036, \"e'er\": 6037, 'chok': 6038, 'ub': 6039, 'ua': 6040, 'signing': 6041, 'vin': 6042, 'bordeaux': 6043, 'vine': 6044, 'scorer': 6045, 'violino': 6046, 'undeft': 6047, 'praiser': 6048, 'mm': 6049, 'representationes': 6050, 'donum': 6051, 'grav': 6052, 'startler': 6053, 'clarette': 6054, 'ravc': 6055, 'dudes': 6056, 'swinger': 6057, 'aarrghh': 6058, 'ortrude': 6059, 'jl': 6060, 'tristan': 6061, 'grab': 6062, 'habet': 6063, 'rapport': 6064, 'fricke': 6065, 'cuppen': 6066, 'mangel': 6067, 'jert': 6068, 'resweeten': 6069, 'offeree': 6070, 'veteran': 6071, 'flange': 6072, 'filasse': 6073, 'ops': 6074, 'free': 6075, 'zone': 6076, 'barbaric': 6077, 'net': 6078, 'stammer': 6079, 'dumper': 6080, 'pedo': 6081, 'pliske': 6082, 'sarthe': 6083, 'mobbers': 6084, 'jokes': 6085, 'kiosk': 6086, 'scopp': 6087, 'enstore': 6088, 'emane': 6089, 'sprang': 6090, 'pricked': 6091, 'stealthier': 6092, 'promiser': 6093, 'nidget': 6094, 'piller': 6095, 'premis': 6096, 'meddle': 6097, 'unheld': 6098, 'forego': 6099, 'nighed': 6100, 'reassay': 6101, 'tinge': 6102, 'lcdr': 6103, 'backsides': 6104, 'mur': 6105, 'aget': 6106, 'kidlet': 6107, 'orationer': 6108, 'jovi': 6109, 'thestius': 6110, 'spr': 6111, 'osse': 6112, 'lysine': 6113, 'story': 6114, 'cheese': 6115, 'cakes': 6116, 'studiers': 6117, 'ruse': 6118, 'kelt': 6119, 'nan': 6120}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqNlCi5nn71M",
        "colab_type": "code",
        "outputId": "3cdade01-a2b1-4bf5-cbb4-7a0e4c54034b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.41.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvMYqskUGeo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Concatenate\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znStVwbnGmG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras.layers import CuDNNGRU,CuDNNLSTM,GlobalMaxPooling1D,GlobalAveragePooling1D\n",
        "from sklearn.utils import class_weight\n",
        "class Attention(Layer):\n",
        "    def __init__(self,step_dim=20,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, Dropout\n",
        "\n",
        "#max_len=\n",
        "\n",
        "def BidLstm(maxlen, max_features, embed_size):\n",
        "    inp1 = Input(shape=(maxlen, ))\n",
        "    #inp2=Input(shape=(1,))\n",
        "    x1=Embedding(max_words+1,embed_size)(inp1)\n",
        "    #x1 = Embedding(max_words + 1,embed_size,weights=[embedding_matrix_1],\n",
        "    #              trainable=True)(inp1)\n",
        "    # x2 = Embedding(len(tok.word_index) + 1,embed_size_2,weights=[embedding_matrix_2],\n",
        "    #                trainable=True)(inp1)\n",
        "    # x3 = Embedding(len(tok.word_index) + 1,embed_size_3,weights=[embedding_matrix_3],\n",
        "    #                trainable=True)(inp1)\n",
        "    # x1 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x1)\n",
        "    # x2 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x2)\n",
        "    # x3 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
        "    #                        recurrent_dropout=0.4))(x3)   \n",
        "    #x1 = Attention(maxlen)(x1)\n",
        "    # x2 = Attention(maxlen)(x2)\n",
        "    # x3 = Attention(maxlen)(x3)\n",
        "    # x=  Concatenate()([x1,x2,x3])\n",
        "    # x1=MultiHead(layer=keras.layers.Bidirectional(keras.layers.CuDNNLSTM(units=200), name='LSTM'),\n",
        "    # layer_num=5,\n",
        "    # reg_index=[1, 4],\n",
        "    # reg_slice=(slice(None, None), slice(32, 48)),\n",
        "    # reg_factor=0.1,\n",
        "    # name='Multi-Head-Attention')(x1)\n",
        "    x1 = CuDNNLSTM(256, return_sequences=True)(x1)   \n",
        "    x1 = SeqSelfAttention(kernel_regularizer=keras.regularizers.l2(1e-4),\n",
        "                    bias_regularizer=keras.regularizers.l1(1e-4),\n",
        "                    attention_regularizer_weight=1e-4,\n",
        "                    name='Attention')(x1) \n",
        "    \n",
        "    x2=  GlobalMaxPooling1D()(x1)\n",
        "    x3= GlobalAveragePooling1D()(x1)\n",
        "    x=  Concatenate()([x2,x3])\n",
        "    x = Dropout(0.1)(x)\n",
        "    #x = Attention(maxlen)(x)\n",
        "    # layer = Dense(600,name='FC1')(x)\n",
        "    # layer = Dense(300,activation='relu')(layer)\n",
        "    layer = Dense(128,activation='relu')(x)\n",
        " #   layer = BatchNormalization(name = 'BN1')(layer)\n",
        "    #layer = Activation('relu')(layer)\n",
        "    #layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(64,name='FC2')(layer)\n",
        "#    layer = BatchNormalization(name = 'BN2')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "   # layer=  Concatenate()([layer,inp2])\n",
        "    # layer=Dense(256,activation='relu')(layer)\n",
        "    # layer=Dense(128,activation='relu')(layer)\n",
        "    layer = Dense(1,name='out_layer',activation='sigmoid')(layer)\n",
        "\n",
        "    model = Model(inputs=[inp1],outputs=layer)\n",
        "\n",
        "    return model\n",
        "model_bi=BidLstm(max_len,max_features=max_words,embed_size=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNt2iKeEGrgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0545cad4-9220-4d03-a640-3cc6b0f8a5ea"
      },
      "source": [
        "model_bi.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc',km.f1_score()])"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable_36:0' shape=() dtype=int32> tp\n",
            "tracking <tf.Variable 'Variable_37:0' shape=() dtype=int32> fp\n",
            "tracking <tf.Variable 'Variable_38:0' shape=() dtype=int32> tp\n",
            "tracking <tf.Variable 'Variable_39:0' shape=() dtype=int32> fn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjQYKV-kGwPO",
        "colab_type": "code",
        "outputId": "273e20be-b59f-4a2d-bb4d-c3dea6cbafd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model_bi.summary()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 45)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 45, 300)      900300      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)        (None, 45, 256)      571392      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention (SeqSelfAttention)    (None, 45, 256)      16449       cu_dnnlstm_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_9 (GlobalM (None, 256)          0           Attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_9 (Glo (None, 256)          0           Attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 512)          0           global_max_pooling1d_9[0][0]     \n",
            "                                                                 global_average_pooling1d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 512)          0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          65664       dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "FC2 (Dense)                     (None, 64)           8256        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 64)           0           FC2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 64)           0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "out_layer (Dense)               (None, 1)            65          dropout_18[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,562,126\n",
            "Trainable params: 1,562,126\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhqzfTntGyHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1a3cDLzG09-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "766eb7f3-7ae1-4b5e-a945-86c31f5014f0"
      },
      "source": [
        "print(class_weights)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.5733964700817907, 1: 3.906158357771261}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1xKGqI9mETl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights[1]=3.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpE0RLEG23A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp_filepath='/content/drive/My Drive/offenseval/'+'checkpoints/lstm_model_2020a_danish.h5'\n",
        "cp_check_point=keras.callbacks.ModelCheckpoint(cp_filepath, monitor='val_f1_score', verbose=0, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
        "es = EarlyStopping(monitor='val_f1_score', mode='max', min_delta=0,patience=2,restore_best_weights=True)\n",
        "reduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8_JSdcG8hP",
        "colab_type": "code",
        "outputId": "465fc2b4-1b1e-41f0-adf5-1a834a2b4878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model_bi.fit([sequences_matrix_train],y_train,validation_data=([sequences_matrix_dev],y_dev),epochs=2,batch_size=32,class_weight=class_weights,callbacks=[es,cp_check_point])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 297 samples\n",
            "Epoch 1/2\n",
            "2664/2664 [==============================] - 3s 1ms/step - loss: 0.6692 - acc: 0.8074 - f1_score: 0.1107 - val_loss: 0.6536 - val_acc: 0.7374 - val_f1_score: 0.2747\n",
            "Epoch 2/2\n",
            "2664/2664 [==============================] - 1s 540us/step - loss: 0.5549 - acc: 0.7920 - f1_score: 0.3653 - val_loss: 0.4682 - val_acc: 0.8620 - val_f1_score: 0.5548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd503700f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbDV_eeDG_Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds_dl=model_bi.predict(sequences_matrix_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfsVlw4_HppI",
        "colab_type": "code",
        "outputId": "e6f3e52b-c29e-4ae3-fb84-09997d371846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model_bi.predict(sequences_matrix_dev, batch_size=30, verbose=1)\n",
        "\n",
        "print(classification_report(y_dev, y_pred.round(),digits=4))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 0s 128us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9176    0.9213    0.9194       254\n",
            "           1     0.5238    0.5116    0.5176        43\n",
            "\n",
            "    accuracy                         0.8620       297\n",
            "   macro avg     0.7207    0.7164    0.7185       297\n",
            "weighted avg     0.8606    0.8620    0.8613       297\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2825HggFjUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=model_bi.predict([sequences_matrix_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hmiCe_BlHMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2601d784-1479-4d99-e9a3-4f043823488d"
      },
      "source": [
        "print(classification_report(y_test, preds.round(),digits=4))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9234    0.8785    0.9004       288\n",
            "           1     0.3636    0.4878    0.4167        41\n",
            "\n",
            "    accuracy                         0.8298       329\n",
            "   macro avg     0.6435    0.6831    0.6585       329\n",
            "weighted avg     0.8536    0.8298    0.8401       329\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5UI8EUEFm6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=[]\n",
        "for i in range(len(preds)):\n",
        "  if preds[i].round()==1:\n",
        "    a.append(\"OFF\")\n",
        "  else:\n",
        "    a.append(\"NOT\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC-sQVa9GRsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame({\"ids\":test_data['id'],\"preds\":a},index=None)\n",
        "df.to_csv(root_path+'/non_english_data/Danish/submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_LAoXWHglb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}