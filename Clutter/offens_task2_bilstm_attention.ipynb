{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/asking28/offenseval2020/blob/master/offens_task2_bilstm_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "8urmVSlSm02S",
    "outputId": "c7287468-ba21-4ca3-ee36-5d5184c5da20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BC0MP4MaVupE",
    "outputId": "e35ea401-26f0-4e2e-a70d-d63bbb8d979c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Y7j_RhDe0olO",
    "outputId": "141cce8b-bd07-4357-a044-a2b8db3ec863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.18.2)\n",
      "Installing collected packages: keras-metrics\n",
      "Successfully installed keras-metrics-1.1.0\n",
      "Collecting keras-self-attention\n",
      "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.2)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=41e1f656cba816107e21d292f84a6065d8bb84e04e833b1795919cac15eb2391\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.42.0\n",
      "Collecting extra-keras-metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/82/0f/b3b2ab62df1b85f753d9a8f0eb29f2e333d085d75a160751b1591be18053/extra_keras_metrics-1.3.1.tar.gz\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (2.3.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.18.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (2.10.0)\n",
      "Building wheels for collected packages: extra-keras-metrics\n",
      "  Building wheel for extra-keras-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for extra-keras-metrics: filename=extra_keras_metrics-1.3.1-cp36-none-any.whl size=13091 sha256=09079e86548513c326b3283aa47cbc869feeecd17328adb1615ea6c647bf52f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/48/f1/b4/a9f81578416b99274b6d5b34fdc92d9bd82b6be99efa965b17\n",
      "Successfully built extra-keras-metrics\n",
      "Installing collected packages: extra-keras-metrics\n",
      "Successfully installed extra-keras-metrics-1.3.1\n",
      "Collecting keras-multi-head\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (1.18.2)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-multi-head) (2.3.1)\n",
      "Collecting keras-self-attention==0.41.0\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-multi-head) (2.10.0)\n",
      "Building wheels for collected packages: keras-multi-head, keras-self-attention\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=c2f8943347a03c7e1c478fc4306839297f017d72c82db64d1361f84827a51a83\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=3125f85f2f7c484e5cef8b7b94698d75339c8bdbd8ce834e06b7cdf2e4a3e56e\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
      "Successfully built keras-multi-head keras-self-attention\n",
      "Installing collected packages: keras-self-attention, keras-multi-head\n",
      "  Found existing installation: keras-self-attention 0.42.0\n",
      "    Uninstalling keras-self-attention-0.42.0:\n",
      "      Successfully uninstalled keras-self-attention-0.42.0\n",
      "Successfully installed keras-multi-head-0.22.0 keras-self-attention-0.41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_metrics\n",
    "!pip install keras-self-attention\n",
    "!pip install extra-keras-metrics\n",
    "!pip install keras-multi-head\n",
    "import keras_metrics as km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "NrBojVXl0Mnq",
    "outputId": "823f328c-07ac-4dce-f8fb-b700b1588084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting focal-loss\n",
      "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
      "Installing collected packages: focal-loss\n",
      "Successfully installed focal-loss-0.0.2\n",
      "Collecting keras-tcn==2.8.3\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.18.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
      "Installing collected packages: keras-tcn\n",
      "Successfully installed keras-tcn-2.8.3\n"
     ]
    }
   ],
   "source": [
    "!pip install focal-loss\n",
    "!pip install keras-tcn==2.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "KzhRFUFJoARV",
    "outputId": "666894ac-9c00-4a15-eb97-2e42b448e4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.18.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=a508c7d57bceb163bb35054d71ec65aaadc768ee99cf83ac86211a618610dcc6\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_metrics\n",
    "!pip install emoji\n",
    "import keras_metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p9x5GAv2m-n6",
    "outputId": "6fc9d55c-15db-4cbd-ac38-13b24ff313f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Conv1D, Conv2D\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "from keras_multi_head import MultiHead\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
    "from keras.layers import average\n",
    "import tensorflow_hub as hub\n",
    "from keras.layers import Average\n",
    "from keras.layers import Concatenate\n",
    "nltk.download('punkt')\n",
    "from numpy import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from keras.layers import SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import CuDNNGRU,CuDNNLSTM,GlobalMaxPool1D,GlobalAveragePooling1D\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from focal_loss import BinaryFocalLoss\n",
    "#plt.switch_backend('agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNryX5AgoDQc"
   },
   "outputs": [],
   "source": [
    "root_path='/content/drive/My Drive/offenseval/2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4KH3MBhoGJG"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UeuSDrPoLHE"
   },
   "outputs": [],
   "source": [
    "file_name = root_path+\"/OffenseEval2020Data/task_b_distant.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oI5wHuDoUE7"
   },
   "outputs": [],
   "source": [
    "# with ZipFile(file_name,'r') as zip:\n",
    "#   zip.printdir()\n",
    "#   zip.extractall(root_path,pwd=b'sem2020-t12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAB16jAwogy8"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/content/drive/My Drive/offenseval/2020/task_b_train_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK2p_xzL03d_"
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('/content/drive/My Drive/offenseval/2020/test_b_tweets.tsv',delimiter='\\t',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2o2GerUGUZOB"
   },
   "outputs": [],
   "source": [
    "test_labels=pd.read_csv('/content/drive/My Drive/offenseval/2020/englishB-goldlabels.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nzh0216PGN5a",
    "outputId": "5b1f636c-00bb-4baf-f9b0-8a6a2fc2b005"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "t4Tbp8F-3XvQ",
    "outputId": "7c96293d-4983-4f1a-e773-a5e2fb14d78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  ...                                              clean\n",
      "0  user trump is a fucking idiot his dementia is ...  ...  user trump is a fucking idiot his dementia is ...\n",
      "1  user hell yes his grinned and thumbs up are di...  ...  user hell yes his grinned and thumbs up are di...\n",
      "2  user cannon wait to see the shit show his deat...  ...  user cannon wait to see the shit show his deat...\n",
      "3  user user user this guys is dumb check his lat...  ...  user user user this guys is dumb check his lat...\n",
      "4            user user fuck him better than his hoes  ...            user user fuck him better than his hoes\n",
      "\n",
      "[5 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5OC5x2lW3kDj",
    "outputId": "981c5099-9f3e-45eb-c1f1-04414a8d99ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                              tweet\n",
      "0  BC0  Then to top it completely the fuck off my trai...\n",
      "1  BC1  To which, of course, many Slovenes will respon...\n",
      "2  BC2   @USER it means go away with your sorry ass kkkkk\n",
      "3  BC3  @USER @USER And he’s closer to trump’s ass. Gr...\n",
      "4  BC4  Looking back at old photos of me makes me phys...\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W6VopAAahv2c",
    "outputId": "a7c3626a-1ad8-4935-935e-b222ae2bcaa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah not going to lie lion king had me in fucking pieces :face_with_tears_of_joy:'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H5PAK58qZl8c",
    "outputId": "fe207da1-8b29-44ad-b0be-06082b0f5c09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5695857297677659"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pf3ey4KDqjPa"
   },
   "source": [
    "## Twitter Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "sUZMDz7bqbj6",
    "outputId": "521c312b-2fef-4dc4-d55c-db7d23b16989"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/Sentimix/word2vec_twitter_tokens.bin', binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OaAQ6sepqoFR",
    "outputId": "00643c66-3c4f-4a65-8fbc-dd666e7187b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['fuck'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSzr_yTlquRV"
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mV9PIibOqqwJ",
    "outputId": "4dc97cd4-cee7-48bd-b0f3-8088c0bf38d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.38.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBtzr1Plqy_i"
   },
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern,with_space=False):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    if with_space==False:\n",
    "      for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    else:\n",
    "      for i in r:\n",
    "        input_txt = re.sub(i, ' ', input_txt)\n",
    "    return input_txt \n",
    "\n",
    "import emoji\n",
    "import pickle\n",
    "import re\n",
    "with open('/content/drive/My Drive/Sentimix/helper_data/contractions.pkl','rb')as f:\n",
    "  contractions=pickle.load(f)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "contractions=Counter(contractions)\n",
    "with open('/content/drive/My Drive/Sentimix/helper_data/acronyms.pkl','rb')as f:\n",
    "  acronyms=pickle.load(f)\n",
    "acronyms=Counter(acronyms)\n",
    "def acronym(df,column):\n",
    "  s_l=[]\n",
    "  for i in tqdm(range(df.shape[0])):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if acronyms[word]!=0:\n",
    "        w_l.append(acronyms[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "with open('/content/drive/My Drive/Sentimix/hinglish_to_english.pickle','rb')as f:\n",
    "  hing_to_eng=pickle.load(f)\n",
    "hing_to_eng=Counter(hing_to_eng)\n",
    "def hindi_se_english(df,column):\n",
    "  s_l=[]\n",
    "  for i in tqdm(range(df.shape[0])):\n",
    "    w_l=[]\n",
    "    sent=str(df[column][i])\n",
    "    for word in sent.split():\n",
    "      if hing_to_eng[word]!=0:\n",
    "        w_l.append(hing_to_eng[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "with open('/content/drive/My Drive/Sentimix/Hinglish_utils/Hinglish_Profanity_dict.pkl', 'rb') as handle:\n",
    "    cuss_dict=pickle.load(handle)\n",
    "cuss_dict=Counter(cuss_dict)\n",
    "def replace_cuss(df,column):\n",
    "  s_l=[]\n",
    "  for i in tqdm(range(df.shape[0])):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if cuss_dict[word]!=0:\n",
    "        w_l.append('abuse')\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "def remove_contraction(df,column):\n",
    "  s_l=[]\n",
    "  for i in tqdm(range(df.shape[0])):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if contractions[word]!=0:\n",
    "        w_l.append(contractions[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "def remove_pattern_rep(input_txt, pattern,rep_pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "      input_txt = re.sub(i, rep_pattern, input_txt)\n",
    "\n",
    "    return input_txt \n",
    "def cleaning(data_f,cleaning_col,new_col):\n",
    "  data_f.reset_index(drop=True,inplace=True)\n",
    "  for i in tqdm(range(data_f.shape[0])):\n",
    "    data_f[cleaning_col][i]=emoji.demojize(str(data_f[cleaning_col][i]))\n",
    "  # #data_f[cleaning_col]=replace_cuss(data_f,cleaning_col)\n",
    "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[cleaning_col],\"_\",with_space=True)\n",
    "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"-\",with_space=True)\n",
    "  # data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\":\",with_space=True)\n",
    "  # data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"@[\\w]*\",\"<USR>\")\n",
    "  # data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"http\\S+\",\"<URL>\")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[cleaning_col], \"[0-9]+\",\"<NUM>\")\n",
    "  #data_f[new_col]=hindi_se_english(data_f,cleaning_col)\n",
    "  data_f[new_col]=remove_contraction(data_f,new_col)\n",
    "  data_f[new_col]=acronym(data_f,new_col)\n",
    "  data_f[new_col]=data_f[new_col].str.replace(\"[^a-zA-Z]<>\", \" \")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"~\",with_space=False)\n",
    "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"!\",with_space=True)\n",
    "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \".\",with_space=True)\n",
    "  #data_f[new_col] = data_f[new_col].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "  #data_f.drop(['text'],inplace=True)\n",
    "  return data_f\n",
    "import numpy as np\n",
    "#a=cleaning(df_chunky[0],'text','clean_col')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "zRZvwQJq4VWH",
    "outputId": "d6ef7bc0-a825-4a2d-92f2-a67e583b7cfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_col</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user trump is a fucking idiot his dementia is ...</td>\n",
       "      <td>0.230133</td>\n",
       "      <td>@user trump is a fucking idiot his dementia is...</td>\n",
       "      <td>['user', 'trump', 'is', 'a', 'fucking', 'idiot...</td>\n",
       "      <td>user trump is a fucking idiot his dementia is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user hell yes his grinned and thumbs up are di...</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>@user hell yes! his grinned and thumbs up are ...</td>\n",
       "      <td>['user', 'hell', 'yes', 'his', 'grinned', 'and...</td>\n",
       "      <td>user hell yes his grinned and thumbs up are di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user cannon wait to see the shit show his deat...</td>\n",
       "      <td>0.229661</td>\n",
       "      <td>@user cannot wait to see the shit show his dea...</td>\n",
       "      <td>['user', 'cannon', 'wait', 'to', 'see', 'the',...</td>\n",
       "      <td>user cannon wait to see the shit show his deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user user user this guys is dumb check his lat...</td>\n",
       "      <td>0.169093</td>\n",
       "      <td>@user @user @user this guys is dumb check his ...</td>\n",
       "      <td>['user', 'user', 'user', 'this', 'guys', 'is',...</td>\n",
       "      <td>user user user this guys is dumb check his lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user user fuck him better than his hoes</td>\n",
       "      <td>0.274980</td>\n",
       "      <td>@user @user fuck him better than his hoes</td>\n",
       "      <td>['user', 'user', 'fuck', 'him', 'better', 'tha...</td>\n",
       "      <td>user user fuck him better than his hoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...                                              clean\n",
       "0  user trump is a fucking idiot his dementia is ...  ...  user trump is a fucking idiot his dementia is ...\n",
       "1  user hell yes his grinned and thumbs up are di...  ...  user hell yes his grinned and thumbs up are di...\n",
       "2  user cannon wait to see the shit show his deat...  ...  user cannon wait to see the shit show his deat...\n",
       "3  user user user this guys is dumb check his lat...  ...  user user user this guys is dumb check his lat...\n",
       "4            user user fuck him better than his hoes  ...            user user fuck him better than his hoes\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LGDHrflq20M"
   },
   "outputs": [],
   "source": [
    "# train_data=cleaning(train_data,'text','clean_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TIoWCCeQ4dct",
    "outputId": "7bbd62d1-a448-4a7a-a3be-cc339874dd4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1422/1422 [00:00<00:00, 2697.20it/s]\n",
      "100%|██████████| 1422/1422 [00:00<00:00, 31786.38it/s]\n",
      "100%|██████████| 1422/1422 [00:00<00:00, 28650.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data=cleaning(test_data,'tweet','clean_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "id_4L9xz33E4",
    "outputId": "2bca75ce-94dc-4a4d-afc1-cdbe209225e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 19.4MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 20kB 1.7MB/s eta 0:00:02\r",
      "\u001b[K     |▌                               | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 40kB 1.7MB/s eta 0:00:02\r",
      "\u001b[K     |▉                               | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 61kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 81kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 92kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 225kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 235kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 245kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 256kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 266kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 276kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 286kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 296kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 307kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 317kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 327kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 337kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 348kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 358kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 368kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 378kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 389kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 399kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 409kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 419kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 430kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 440kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 450kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 460kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 471kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 481kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 491kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 501kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 512kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 522kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 532kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 542kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 552kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 563kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 573kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 583kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 593kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 604kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 614kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 624kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 634kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 645kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 655kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 665kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 675kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 686kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 696kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 706kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 716kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 727kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 737kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 747kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 757kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 768kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 778kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 788kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 798kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 808kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 819kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 829kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 839kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 849kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 860kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 870kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 880kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 890kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 901kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 911kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 921kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 931kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 942kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 952kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 962kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 972kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 983kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 993kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 1.0MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.0MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 1.0MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.0MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 1.0MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 1.1MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.2MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.3MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.4MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.5MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 1.6MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.7MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.8MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s \n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rTUBNrc436EY",
    "outputId": "8960232e-8b5e-4301-fb32-8ccd26e5f87e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "{'fucks', 'fuck'}\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(distance=1)\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(['fuckk'])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpClcOZY4AlK"
   },
   "outputs": [],
   "source": [
    "def spell_check(df):\n",
    "  for i in range(df.shape[0]):\n",
    "    if i%100000==0:\n",
    "      print(\"Reached {0}, percent {1}\".format(i,float(i/df.shape[0])*100))\n",
    "    words=df['text'][i].split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    l=[]\n",
    "    for word in words:\n",
    "      if word in misspelled:\n",
    "        word=spell.correction(word)\n",
    "      else:\n",
    "        word=word\n",
    "      l.append(word)\n",
    "    #words=[spell.correction(word) for word in words]\n",
    "    df['text'][i]=' '.join(word for word in l)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4X7VlDmI4ERd"
   },
   "outputs": [],
   "source": [
    "def spell_collection(df):\n",
    "  spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', df)\n",
    "  return spell_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WpykSeAr4Jos"
   },
   "outputs": [],
   "source": [
    "test_data['text']=test_data['clean_col'].apply(spell_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPumBAb-5d_U"
   },
   "outputs": [],
   "source": [
    "# train_data['text']=train_data['clean_col'].apply(spell_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aHbjLfVa5lYa",
    "outputId": "fac900f5-41fb-4a14-f2c4-dc8b2ed2c54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 0, percent 0.0\n"
     ]
    }
   ],
   "source": [
    "test_data=spell_check(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwAvQzik5lWI"
   },
   "outputs": [],
   "source": [
    "# train_data=spell_check(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SvmtMOXorBH7",
    "outputId": "0dd4442d-8438-44e5-fca8-cc0011cca24b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'clean_col', 'tokens', 'clean'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkHnhdPVxHkc"
   },
   "outputs": [],
   "source": [
    "# df_temp=pd.DataFrame({'text':train_data['clean_col'],'label':train_data['average']})\n",
    "# df_temp.to_csv('/content/drive/My Drive/offenseval/2020/tas_b_2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCFZ2MvY5uf7"
   },
   "source": [
    "## Levenstein corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "iWdGUJ1p5ztw",
    "outputId": "ee1197d8-9f74-400b-bb47-25a9ad5a48df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '1080', '&c', '10-point', '10th']\n",
      "['jigaboo', 'mound of venus', 'asslover', 's&m', 'queaf']\n",
      "Total english words: 466544\n",
      "Total bad words: 1617\n",
      "create symspell dict...\n",
      "total words processed: 467594\n",
      "total unique words in corpus: 467394\n",
      "total items in dictionary (corpus words and deletions): 20250415\n",
      "  edit distance for deletions: 2\n",
      "  length of longest word in corpus: 45\n"
     ]
    }
   ],
   "source": [
    "import re, random\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "to_sample = False # if you're impatient switch this flag\n",
    "\n",
    "def spacy_tokenize(text):\n",
    "    return [token.text for token in nlp.tokenizer(text)]\n",
    "    \n",
    "def dameraulevenshtein(seq1, seq2):\n",
    "    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n",
    "    This method has not been modified from the original.\n",
    "    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n",
    "    This distance is the number of additions, deletions, substitutions,\n",
    "    and transpositions needed to transform the first sequence into the\n",
    "    second. Although generally used with strings, any sequences of\n",
    "    comparable objects will work.\n",
    "    Transpositions are exchanges of *consecutive* characters; all other\n",
    "    operations are self-explanatory.\n",
    "    This implementation is O(N*M) time and O(M) space, for N and M the\n",
    "    lengths of the two sequences.\n",
    "    >>> dameraulevenshtein('ba', 'abc')\n",
    "    2\n",
    "    >>> dameraulevenshtein('fee', 'deed')\n",
    "    2\n",
    "    It works with arbitrary sequences too:\n",
    "    >>> dameraulevenshtein('abcd', ['b', 'a', 'c', 'd', 'e'])\n",
    "    2\n",
    "    \"\"\"\n",
    "    # codesnippet:D0DE4716-B6E6-4161-9219-2903BF8F547F\n",
    "    # Conceptually, this is based on a len(seq1) + 1 * len(seq2) + 1 matrix.\n",
    "    # However, only the current and two previous rows are needed at once,\n",
    "    # so we only store those.\n",
    "    oneago = None\n",
    "    thisrow = list(range(1, len(seq2) + 1)) + [0]\n",
    "    for x in range(len(seq1)):\n",
    "        # Python lists wrap around for negative indices, so put the\n",
    "        # leftmost column at the *end* of the list. This matches with\n",
    "        # the zero-indexed strings and saves extra calculation.\n",
    "        twoago, oneago, thisrow = (oneago, thisrow, [0] * len(seq2) + [x + 1])\n",
    "        for y in range(len(seq2)):\n",
    "            delcost = oneago[y] + 1\n",
    "            addcost = thisrow[y - 1] + 1\n",
    "            subcost = oneago[y - 1] + (seq1[x] != seq2[y])\n",
    "            thisrow[y] = min(delcost, addcost, subcost)\n",
    "            # This block deals with transpositions\n",
    "            if (x > 0 and y > 0 and seq1[x] == seq2[y - 1]\n",
    "                    and seq1[x - 1] == seq2[y] and seq1[x] != seq2[y]):\n",
    "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
    "    return thisrow[len(seq2) - 1]\n",
    "\n",
    "\n",
    "class SymSpell:\n",
    "    def __init__(self, max_edit_distance=3, verbose=0):\n",
    "        self.max_edit_distance = max_edit_distance\n",
    "        self.verbose = verbose\n",
    "        # 0: top suggestion\n",
    "        # 1: all suggestions of smallest edit distance\n",
    "        # 2: all suggestions <= max_edit_distance (slower, no early termination)\n",
    "\n",
    "        self.dictionary = {}\n",
    "        self.longest_word_length = 0\n",
    "\n",
    "    def get_deletes_list(self, w):\n",
    "        \"\"\"given a word, derive strings with up to max_edit_distance characters\n",
    "           deleted\"\"\"\n",
    "\n",
    "        deletes = []\n",
    "        queue = [w]\n",
    "        for d in range(self.max_edit_distance):\n",
    "            temp_queue = []\n",
    "            for word in queue:\n",
    "                if len(word) > 1:\n",
    "                    for c in range(len(word)):  # character index\n",
    "                        word_minus_c = word[:c] + word[c + 1:]\n",
    "                        if word_minus_c not in deletes:\n",
    "                            deletes.append(word_minus_c)\n",
    "                        if word_minus_c not in temp_queue:\n",
    "                            temp_queue.append(word_minus_c)\n",
    "            queue = temp_queue\n",
    "\n",
    "        return deletes\n",
    "\n",
    "    def create_dictionary_entry(self, w):\n",
    "        '''add word and its derived deletions to dictionary'''\n",
    "        # check if word is already in dictionary\n",
    "        # dictionary entries are in the form: (list of suggested corrections,\n",
    "        # frequency of word in corpus)\n",
    "        new_real_word_added = False\n",
    "        if w in self.dictionary:\n",
    "            # increment count of word in corpus\n",
    "            self.dictionary[w] = (self.dictionary[w][0], self.dictionary[w][1] + 1)\n",
    "        else:\n",
    "            self.dictionary[w] = ([], 1)\n",
    "            self.longest_word_length = max(self.longest_word_length, len(w))\n",
    "\n",
    "        if self.dictionary[w][1] == 1:\n",
    "            # first appearance of word in corpus\n",
    "            # n.b. word may already be in dictionary as a derived word\n",
    "            # (deleting character from a real word)\n",
    "            # but counter of frequency of word in corpus is not incremented\n",
    "            # in those cases)\n",
    "            new_real_word_added = True\n",
    "            deletes = self.get_deletes_list(w)\n",
    "            for item in deletes:\n",
    "                if item in self.dictionary:\n",
    "                    # add (correct) word to delete's suggested correction list\n",
    "                    self.dictionary[item][0].append(w)\n",
    "                else:\n",
    "                    # note frequency of word in corpus is not incremented\n",
    "                    self.dictionary[item] = ([w], 0)\n",
    "\n",
    "        return new_real_word_added\n",
    "\n",
    "    def create_dictionary_from_arr(self, arr, token_pattern=r'[a-z]+'):\n",
    "        total_word_count = 0\n",
    "        unique_word_count = 0\n",
    "\n",
    "        for line in arr:\n",
    "            # separate by words by non-alphabetical characters\n",
    "            words = re.findall(token_pattern, line.lower())\n",
    "            for word in words:\n",
    "                total_word_count += 1\n",
    "                if self.create_dictionary_entry(word):\n",
    "                    unique_word_count += 1\n",
    "\n",
    "        print(\"total words processed: %i\" % total_word_count)\n",
    "        print(\"total unique words in corpus: %i\" % unique_word_count)\n",
    "        print(\"total items in dictionary (corpus words and deletions): %i\" % len(self.dictionary))\n",
    "        print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
    "        print(\"  length of longest word in corpus: %i\" % self.longest_word_length)\n",
    "        return self.dictionary\n",
    "\n",
    "    def create_dictionary(self, fname):\n",
    "        total_word_count = 0\n",
    "        unique_word_count = 0\n",
    "\n",
    "        with open(fname) as file:\n",
    "            for line in file:\n",
    "                # separate by words by non-alphabetical characters\n",
    "                words = re.findall('[a-z]+', line.lower())\n",
    "                for word in words:\n",
    "                    total_word_count += 1\n",
    "                    if self.create_dictionary_entry(word):\n",
    "                        unique_word_count += 1\n",
    "\n",
    "        print(\"total words processed: %i\" % total_word_count)\n",
    "        print(\"total unique words in corpus: %i\" % unique_word_count)\n",
    "        print(\"total items in dictionary (corpus words and deletions): %i\" % len(self.dictionary))\n",
    "        print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
    "        print(\"  length of longest word in corpus: %i\" % self.longest_word_length)\n",
    "        return self.dictionary\n",
    "\n",
    "    def get_suggestions(self, string, silent=False):\n",
    "        \"\"\"return list of suggested corrections for potentially incorrectly\n",
    "           spelled word\"\"\"\n",
    "        if (len(string) - self.longest_word_length) > self.max_edit_distance:\n",
    "            if not silent:\n",
    "                print(\"no items in dictionary within maximum edit distance\")\n",
    "            return []\n",
    "\n",
    "        suggest_dict = {}\n",
    "        min_suggest_len = float('inf')\n",
    "\n",
    "        queue = [string]\n",
    "        q_dictionary = {}  # items other than string that we've checked\n",
    "\n",
    "        while len(queue) > 0:\n",
    "            q_item = queue[0]  # pop\n",
    "            queue = queue[1:]\n",
    "\n",
    "            # early exit\n",
    "            if ((self.verbose < 2) and (len(suggest_dict) > 0) and\n",
    "                    ((len(string) - len(q_item)) > min_suggest_len)):\n",
    "                break\n",
    "\n",
    "            # process queue item\n",
    "            if (q_item in self.dictionary) and (q_item not in suggest_dict):\n",
    "                if self.dictionary[q_item][1] > 0:\n",
    "                    # word is in dictionary, and is a word from the corpus, and\n",
    "                    # not already in suggestion list so add to suggestion\n",
    "                    # dictionary, indexed by the word with value (frequency in\n",
    "                    # corpus, edit distance)\n",
    "                    # note q_items that are not the input string are shorter\n",
    "                    # than input string since only deletes are added (unless\n",
    "                    # manual dictionary corrections are added)\n",
    "                    assert len(string) >= len(q_item)\n",
    "                    suggest_dict[q_item] = (self.dictionary[q_item][1],\n",
    "                                            len(string) - len(q_item))\n",
    "                    # early exit\n",
    "                    if (self.verbose < 2) and (len(string) == len(q_item)):\n",
    "                        break\n",
    "                    elif (len(string) - len(q_item)) < min_suggest_len:\n",
    "                        min_suggest_len = len(string) - len(q_item)\n",
    "\n",
    "                # the suggested corrections for q_item as stored in\n",
    "                # dictionary (whether or not q_item itself is a valid word\n",
    "                # or merely a delete) can be valid corrections\n",
    "                for sc_item in self.dictionary[q_item][0]:\n",
    "                    if sc_item not in suggest_dict:\n",
    "\n",
    "                        # compute edit distance\n",
    "                        # suggested items should always be longer\n",
    "                        # (unless manual corrections are added)\n",
    "                        assert len(sc_item) > len(q_item)\n",
    "\n",
    "                        # q_items that are not input should be shorter\n",
    "                        # than original string\n",
    "                        # (unless manual corrections added)\n",
    "                        assert len(q_item) <= len(string)\n",
    "\n",
    "                        if len(q_item) == len(string):\n",
    "                            assert q_item == string\n",
    "                            item_dist = len(sc_item) - len(q_item)\n",
    "\n",
    "                        # item in suggestions list should not be the same as\n",
    "                        # the string itself\n",
    "                        assert sc_item != string\n",
    "\n",
    "                        # calculate edit distance using, for example,\n",
    "                        # Damerau-Levenshtein distance\n",
    "                        item_dist = dameraulevenshtein(sc_item, string)\n",
    "\n",
    "                        # do not add words with greater edit distance if\n",
    "                        # verbose setting not on\n",
    "                        if (self.verbose < 2) and (item_dist > min_suggest_len):\n",
    "                            pass\n",
    "                        elif item_dist <= self.max_edit_distance:\n",
    "                            assert sc_item in self.dictionary  # should already be in dictionary if in suggestion list\n",
    "                            suggest_dict[sc_item] = (self.dictionary[sc_item][1], item_dist)\n",
    "                            if item_dist < min_suggest_len:\n",
    "                                min_suggest_len = item_dist\n",
    "\n",
    "                        # depending on order words are processed, some words\n",
    "                        # with different edit distances may be entered into\n",
    "                        # suggestions; trim suggestion dictionary if verbose\n",
    "                        # setting not on\n",
    "                        if self.verbose < 2:\n",
    "                            suggest_dict = {k: v for k, v in suggest_dict.items() if v[1] <= min_suggest_len}\n",
    "\n",
    "            # now generate deletes (e.g. a substring of string or of a delete)\n",
    "            # from the queue item\n",
    "            # as additional items to check -- add to end of queue\n",
    "            assert len(string) >= len(q_item)\n",
    "\n",
    "            # do not add words with greater edit distance if verbose setting\n",
    "            # is not on\n",
    "            if (self.verbose < 2) and ((len(string) - len(q_item)) > min_suggest_len):\n",
    "                pass\n",
    "            elif (len(string) - len(q_item)) < self.max_edit_distance and len(q_item) > 1:\n",
    "                for c in range(len(q_item)):  # character index\n",
    "                    word_minus_c = q_item[:c] + q_item[c + 1:]\n",
    "                    if word_minus_c not in q_dictionary:\n",
    "                        queue.append(word_minus_c)\n",
    "                        q_dictionary[word_minus_c] = None  # arbitrary value, just to identify we checked this\n",
    "\n",
    "        # queue is now empty: convert suggestions in dictionary to\n",
    "        # list for output\n",
    "        if not silent and self.verbose != 0:\n",
    "            print(\"number of possible corrections: %i\" % len(suggest_dict))\n",
    "            print(\"  edit distance for deletions: %i\" % self.max_edit_distance)\n",
    "\n",
    "        # output option 1\n",
    "        # sort results by ascending order of edit distance and descending\n",
    "        # order of frequency\n",
    "        #     and return list of suggested word corrections only:\n",
    "        # return sorted(suggest_dict, key = lambda x:\n",
    "        #               (suggest_dict[x][1], -suggest_dict[x][0]))\n",
    "\n",
    "        # output option 2\n",
    "        # return list of suggestions with (correction,\n",
    "        #                                  (frequency in corpus, edit distance)):\n",
    "        as_list = suggest_dict.items()\n",
    "        # outlist = sorted(as_list, key=lambda (term, (freq, dist)): (dist, -freq))\n",
    "        outlist = sorted(as_list, key=lambda x: (x[1][1], -x[1][0]))\n",
    "\n",
    "        if self.verbose == 0:\n",
    "            return outlist[0]\n",
    "        else:\n",
    "            return outlist\n",
    "\n",
    "        '''\n",
    "        Option 1:\n",
    "        ['file', 'five', 'fire', 'fine', ...]\n",
    "        Option 2:\n",
    "        [('file', (5, 0)),\n",
    "         ('five', (67, 1)),\n",
    "         ('fire', (54, 1)),\n",
    "         ('fine', (17, 1))...]  \n",
    "        '''\n",
    "\n",
    "    def best_word(self, s, silent=False):\n",
    "        try:\n",
    "            return self.get_suggestions(s, silent)[0]\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def spell_corrector(word_list, words_d) -> str:\n",
    "    result_list = []\n",
    "    for word in word_list:\n",
    "        if word not in words_d:\n",
    "            suggestion = ss.best_word(word, silent=True)\n",
    "            if suggestion is not None:\n",
    "                result_list.append(suggestion)\n",
    "        else:\n",
    "            result_list.append(word)\n",
    "            \n",
    "    return \" \".join(result_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # build symspell tree \n",
    "    ss = SymSpell(max_edit_distance=2)\n",
    "    \n",
    "    # fetch list of bad words\n",
    "    with open('/content/drive/My Drive/offenseval/2020/cleaner_data/bad-words.csv') as bf:\n",
    "        bad_words = bf.readlines()\n",
    "    bad_words = [word.strip() for word in bad_words]    \n",
    "    \n",
    "    # fetch english words dictionary\n",
    "    with open('/content/drive/My Drive/offenseval/2020/cleaner_data/english_words_479k.txt') as f:\n",
    "        words = f.readlines()\n",
    "    eng_words = [word.strip() for word in words]\n",
    "    \n",
    "    # Print some examples\n",
    "    print(eng_words[:5])\n",
    "    print(bad_words[:5])\n",
    "\n",
    "    print('Total english words: {}'.format(len(eng_words)))\n",
    "    print('Total bad words: {}'.format(len(bad_words)))\n",
    "    \n",
    "    print('create symspell dict...')\n",
    "    \n",
    "    if to_sample:\n",
    "        # sampling from list for kernel runtime\n",
    "        sample_idxs = random.sample(range(len(eng_words)), 100)\n",
    "        eng_words = [eng_words[i] for i in sorted(sample_idxs)] + \\\n",
    "            'to infinity and beyond'.split() # make sure our sample misspell is in there\n",
    "    \n",
    "    all_words_list = list(set(bad_words + eng_words))\n",
    "    silence = ss.create_dictionary_from_arr(all_words_list, token_pattern=r'.+')\n",
    "    \n",
    "    # create a dictionary of rightly spelled words for lookup\n",
    "    words_dict = {k: 0 for k in all_words_list}\n",
    "    \n",
    "    sample_text = 'to infifity and byond'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "YGuKOFwV540g",
    "outputId": "250369e2-e599-4d42-a5a7-2958a535e6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run spell checker...\n",
      "\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test_data['tokens'] = test_data['text'].apply(spacy_tokenize)\n",
    "    \n",
    "print('run spell checker...')\n",
    "print()\n",
    "#print('original text: ' + sample_text)\n",
    "print()\n",
    "test_data['clean'] = test_data.apply(lambda row:spell_corrector(row['tokens'],words_dict),axis=1)\n",
    "#print('corrected text: ' + correct_text)\n",
    "\n",
    "print('Done.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yK44oYbI56Ur",
    "outputId": "43a58365-faa3-410b-ffa4-a66fe60d3664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run spell checker...\n",
      "\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_data['tokens'] = train_data['text'].apply(spacy_tokenize)\n",
    "    \n",
    "print('run spell checker...')\n",
    "print()\n",
    "#print('original text: ' + sample_text)\n",
    "print()\n",
    "train_data['clean'] = train_data.apply(lambda row:spell_corrector(row['tokens'],words_dict),axis=1)\n",
    "#print('corrected text: ' + correct_text)\n",
    "\n",
    "print('Done.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sx5j-JRL9CMt"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv('/content/drive/My Drive/offenseval/2020/task_b_train_2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SF6uN5Njsjp8"
   },
   "source": [
    "## Tokenization and Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JR5o7mU-sdU6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqTrR_g09ba6"
   },
   "outputs": [],
   "source": [
    "y=(train_data['label']>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yc3_yfXCsn4J"
   },
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(train_data,test_size=0.2,random_state=2020,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQwtm08gQj8C"
   },
   "outputs": [],
   "source": [
    "train_data['label']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjvGZ5Gtssk5"
   },
   "outputs": [],
   "source": [
    "max_words =10000\n",
    "max_len = 25\n",
    "tok = Tokenizer(max_words)\n",
    "tok.fit_on_texts(train_data['clean'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "imD_TKccLRH0",
    "outputId": "92738206-e7b6-4e29-e636-03666bebd664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37807"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uiq2b0ZPsz1A"
   },
   "outputs": [],
   "source": [
    "sequences_train = tok.texts_to_sequences(df_train['clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_train = sequence.pad_sequences(sequences_train,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WUXbJyfs6IH"
   },
   "outputs": [],
   "source": [
    "sequences_dev = tok.texts_to_sequences(df_test['clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_dev = sequence.pad_sequences(sequences_dev,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebPoj7Ca92qC"
   },
   "outputs": [],
   "source": [
    "sequences_test = tok.texts_to_sequences(test_data['clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ic99M4p8PAQ7",
    "outputId": "864bd524-db18-4160-f062-c6b9c007e13f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70515     0.260404\n",
       "93592     0.569608\n",
       "159074    0.188805\n",
       "178163    0.263124\n",
       "85537     0.266449\n",
       "            ...   \n",
       "45291     0.240648\n",
       "18112     0.214931\n",
       "61631     0.302711\n",
       "85024     0.323634\n",
       "82062     0.351939\n",
       "Name: label, Length: 151179, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3s4k9bqks_OM"
   },
   "outputs": [],
   "source": [
    "y_train=(df_train['label']>=0.5).astype(int)\n",
    "y_dev=(df_test['label']>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PgRU5WGVHW-d",
    "outputId": "43b45f64-a195-470f-b546-aa18a344c762"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BC0</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC1</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BC2</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC3</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BC4</td>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  BC0  UNT\n",
       "1  BC1  TIN\n",
       "2  BC2  TIN\n",
       "3  BC3  TIN\n",
       "4  BC4  UNT"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMTWSr9nHTrM"
   },
   "outputs": [],
   "source": [
    "y_test=(test_labels[1]==\"UNT\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-CGTzr4tmeH"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "581UbiUntv1x"
   },
   "outputs": [],
   "source": [
    "# embeddings_index = {}\n",
    "# f = open(os.path.join('/content/drive/My Drive/IR_project/glove.6B', 'glove.6B.300d.txt'))\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUCAVslAtlOC"
   },
   "outputs": [],
   "source": [
    "word_index=tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-brG0wAts8w"
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_1 = np.zeros([max_words + 1, 300])\n",
    "# for word, i in tok.word_index.items():\n",
    "#     if word in embeddings_index.keys():\n",
    "#       if i>max_words:\n",
    "#         break\n",
    "#       embedding_matrix_1[i] = embeddings_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQXtljY4P0Kf"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_1 = np.zeros([max_words+ 1, 400])\n",
    "for word, i in tok.word_index.items():\n",
    "    if word in model:\n",
    "      if i>max_words:\n",
    "        break\n",
    "      embedding_matrix_1[i] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKp2BKRmtzus"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "lqMpyQTat4Ss",
    "outputId": "55f2d5f8-6389-4d3f-9b1e-ed55c3cb7fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.41.0)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zNjzoa2t6y4"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers import CuDNNGRU,CuDNNLSTM,GlobalMaxPooling1D,GlobalAveragePooling1D\n",
    "from sklearn.utils import class_weight\n",
    "class Attention(Layer):\n",
    "    def __init__(self,step_dim=20,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, Dropout\n",
    "\n",
    "#max_len=\n",
    "\n",
    "def BidLstm(maxlen, max_features, embed_size):\n",
    "    inp1 = Input(shape=(maxlen, ))\n",
    "    #inp2=Input(shape=(1,))\n",
    "    # x1=Embedding(len(word_index)+1,embed_size)(inp1)\n",
    "    x1 = Embedding(max_words+1,embed_size,weights=[embedding_matrix_1],\n",
    "                  trainable=False)(inp1)\n",
    "    # x2 = Embedding(len(tok.word_index) + 1,embed_size_2,weights=[embedding_matrix_2],\n",
    "    #                trainable=True)(inp1)\n",
    "    # x3 = Embedding(len(tok.word_index) + 1,embed_size_3,weights=[embedding_matrix_3],\n",
    "    #                trainable=True)(inp1)\n",
    "    # x1 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x1)\n",
    "    # x2 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x2)\n",
    "    # x3 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x3)   \n",
    "    # x1 = Attention(maxlen)(x1)\n",
    "    # x2 = Attention(maxlen)(x2)\n",
    "    # x3 = Attention(maxlen)(x3)\n",
    "    # # x=  Concatenate()([x1,x2,x3])\n",
    "    # x1=MultiHead(layer=keras.layers.Bidirectional(keras.layers.CuDNNLSTM(units=200), name='LSTM'),\n",
    "    # layer_num=5,\n",
    "    # reg_index=[1, 4],\n",
    "    # reg_slice=(slice(None, None), slice(32, 48)),\n",
    "    # reg_factor=0.1,\n",
    "    # name='Multi-Head-Attention')(x1)\n",
    "    x1 = Bidirectional(CuDNNLSTM(200, return_sequences=True))(x1)   \n",
    "    x1 = SeqSelfAttention(kernel_regularizer=keras.regularizers.l2(1e-4),\n",
    "                    bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "                    attention_regularizer_weight=1e-4,\n",
    "                    name='Attention')(x1) \n",
    "    x2=  GlobalMaxPooling1D()(x1)\n",
    "    x3= GlobalAveragePooling1D()(x1)\n",
    "    x=  Concatenate()([x2,x3])\n",
    "    x = Dropout(0.1)(x)\n",
    "    #x = Attention(maxlen)(x)\n",
    "    # layer = Dense(600,name='FC1')(x)\n",
    "    # layer = Dense(300,activation='relu')(layer)\n",
    "    layer = Dense(128,activation='relu')(x)\n",
    " #   layer = BatchNormalization(name = 'BN1')(layer)\n",
    "    #layer = Activation('relu')(layer)\n",
    "    #layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(64,name='FC2')(layer)\n",
    "#    layer = BatchNormalization(name = 'BN2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "   # layer=  Concatenate()([layer,inp2])\n",
    "    # layer=Dense(256,activation='relu')(layer)\n",
    "    # layer=Dense(128,activation='relu')(layer)\n",
    "    layer = Dense(1,name='out_layer',activation='sigmoid')(layer)\n",
    "\n",
    "    model = Model(inputs=[inp1],outputs=layer)\n",
    "\n",
    "    return model\n",
    "model_bi=BidLstm(max_len,max_features=max_words,embed_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NViEAJS9t9lX",
    "outputId": "829896e7-09cc-4858-ad0b-ff52611b4598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_52:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_53:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_54:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_55:0' shape=() dtype=int32> fn\n"
     ]
    }
   ],
   "source": [
    "model_bi.compile(optimizer='Adam',loss=BinaryFocalLoss(gamma=4),metrics=['acc',km.f1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "tT_1ZJX7uAH9",
    "outputId": "8e7634fc-6584-41b3-878d-9f32de519aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 25, 400)      4000400     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 25, 400)      963200      embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Attention (SeqSelfAttention)    (None, 25, 400)      25665       bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 400)          0           Attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 400)          0           Attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 800)          0           global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 800)          0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          102528      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "FC2 (Dense)                     (None, 64)           8256        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64)           0           FC2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 64)           0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "out_layer (Dense)               (None, 1)            65          dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,100,114\n",
      "Trainable params: 1,099,714\n",
      "Non-trainable params: 4,000,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNjivaQxa3eN"
   },
   "outputs": [],
   "source": [
    "y=(train_data['label']>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iv3iu0fjuCZC"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y),y)\n",
    "class_weights=dict(enumerate(class_weights))\n",
    "class_weights[1]=3.7\n",
    "class_weights[0]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qynlI8-Te9bU",
    "outputId": "a1f6e882-a899-4f90-e35b-0157fcf70587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5, 1: 3.7}\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmuQzEZUuEsQ"
   },
   "outputs": [],
   "source": [
    "cp_filepath='/content/drive/My Drive/offenseval/'+'checkpoints/lstm_model_2020b_big_attention.h5'\n",
    "cp_check_point=keras.callbacks.ModelCheckpoint(cp_filepath, monitor='val_f1_score', verbose=0, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', min_delta=0,patience=2,restore_best_weights=True)\n",
    "reduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "_bsiPzmFuKtE",
    "outputId": "9b4522d0-f613-475f-fe44-0b3507f7b46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151179 samples, validate on 37795 samples\n",
      "Epoch 1/2\n",
      "151179/151179 [==============================] - 10s 66us/step - loss: 0.0372 - acc: 0.7043 - f1_score: 0.4994 - val_loss: 0.0308 - val_acc: 0.7791 - val_f1_score: 0.6345\n",
      "Epoch 2/2\n",
      "151179/151179 [==============================] - 8s 52us/step - loss: 0.0281 - acc: 0.7739 - f1_score: 0.6267 - val_loss: 0.0294 - val_acc: 0.7984 - val_f1_score: 0.6586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fac32bff748>"
      ]
     },
     "execution_count": 233,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bi.fit([sequences_matrix_train],y_train,validation_data=([sequences_matrix_dev],y_dev),epochs=2,batch_size=1024,class_weight=class_weights,callbacks=[es,cp_check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sn1nq_mLuSg-"
   },
   "outputs": [],
   "source": [
    "y_preds_dl=model_bi.predict(sequences_matrix_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "NNLgNPTRyA3R",
    "outputId": "fb065d7d-6528-4c0e-beac-a89f0b162e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9779    0.7625    0.8569     29910\n",
      "           1     0.5092    0.9347    0.6593      7885\n",
      "\n",
      "    accuracy                         0.7984     37795\n",
      "   macro avg     0.7436    0.8486    0.7581     37795\n",
      "weighted avg     0.8801    0.7984    0.8157     37795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#y_pred = model_bi.predict(X_dev, batch_size=30, verbose=1)\n",
    "\n",
    "print(classification_report(y_dev, y_preds_dl.round(),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uldsIGhJyBVQ"
   },
   "outputs": [],
   "source": [
    "y_preds_test=model_bi.predict(sequences_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "U1ayly0MJLWh",
    "outputId": "f08d4ad0-60b9-4cdf-cd6d-c2513dc0997b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7247    0.8329    0.7750       850\n",
      "           1     0.6809    0.5297    0.5959       572\n",
      "\n",
      "    accuracy                         0.7110      1422\n",
      "   macro avg     0.7028    0.6813    0.6855      1422\n",
      "weighted avg     0.7071    0.7110    0.7030      1422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_test.round(),digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzUVawM-D2hL"
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in range(len(y_preds_test)):\n",
    "  if y_preds_test[i].round()==1:\n",
    "    a.append(\"UNT\")\n",
    "  else:\n",
    "    a.append(\"TIN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_D-grcMgEIFD"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'id':test_data['id'],'pred':a},index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EjbYQ-NEKOo"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/content/drive/My Drive/offenseval/2020/test_pred_b.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62l2HkluENlg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8waWEEX3P8U5"
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "WnD65MI3P_hL",
    "outputId": "4c2ce176-f6b8-4c51-db82-648bb23accb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\r",
      "\u001b[K     |████▉                           | 10kB 19.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 51kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 61kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcrP5iUyQFTN"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tBWCfMHuQHU_",
    "outputId": "d2d029b7-fbf4-411c-9906-07ec401c3d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\" *****\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUTPUT_DIR = \"\\\"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\\\"\"#@param {type:\"string\"}\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = False #@param {type:\"boolean\"}\n",
    "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
    "USE_BUCKET = False #@param {type:\"boolean\"}\n",
    "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
    "\n",
    "if USE_BUCKET:\n",
    "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    # Doesn't matter if the directory didn't exist\n",
    "    pass\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiCnqINwQcGz"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'clean'\n",
    "LABEL_COLUMN = 'label'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGkidEhZQqp-"
   },
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(train_data,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnKzK4jDRdXV"
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uebif1iRRfk8"
   },
   "outputs": [],
   "source": [
    "test_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "LEjTYFGgRhRI",
    "outputId": "c74c3edd-345e-4b03-802f-76288cb682c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "import tensorflow_hub as hub\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p38J40nBRj-Z",
    "outputId": "f9331a35-6d03-45b1-e744-3d906490dc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] where the fuck is oz ##ark season nu ##m [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] where the fuck is oz ##ark season nu ##m [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2073 1996 6616 2003 11472 17007 2161 16371 2213 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2073 1996 6616 2003 11472 17007 2161 16371 2213 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] either that or i just really am a piece of shit [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] either that or i just really am a piece of shit [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2593 2008 2030 1045 2074 2428 2572 1037 3538 1997 4485 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2593 2008 2030 1045 2074 2428 2572 1037 3538 1997 4485 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] democratic socialist might as well say you let dude ##s fuck your wide [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] democratic socialist might as well say you let dude ##s fuck your wide [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3537 6102 2453 2004 2092 2360 2017 2292 12043 2015 6616 2115 2898 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3537 6102 2453 2004 2092 2360 2017 2292 12043 2015 6616 2115 2898 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the show has plum ##met ##ed i do nt know who s a bigger na ##rc ##iss ##ist vine or turner fuck off [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the show has plum ##met ##ed i do nt know who s a bigger na ##rc ##iss ##ist vine or turner fuck off [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 2265 2038 22088 11368 2098 1045 2079 23961 2113 2040 1055 1037 7046 6583 11890 14643 2923 15351 2030 6769 6616 2125 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 2265 2038 22088 11368 2098 1045 2079 23961 2113 2040 1055 1037 7046 6583 11890 14643 2923 15351 2030 6769 6616 2125 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user do not call me a bitch i do not remember taking my panties off for your father [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user do not call me a bitch i do not remember taking my panties off for your father [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 2079 2025 2655 2033 1037 7743 1045 2079 2025 3342 2635 2026 12095 2125 2005 2115 2269 102 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 2079 2025 2655 2033 1037 7743 1045 2079 2025 3342 2635 2026 12095 2125 2005 2115 2269 102 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 130000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 130000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 140000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 140000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 150000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 150000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 160000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 160000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 170000 of 170076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 170000 of 170076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 18898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 18898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the quick ##est way to lose some shit is to think you got it like that k . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the quick ##est way to lose some shit is to think you got it like that k . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 4248 4355 2126 2000 4558 2070 4485 2003 2000 2228 2017 2288 2009 2066 2008 1047 1012 102 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 4248 4355 2126 2000 4558 2070 4485 2003 2000 2228 2017 2288 2009 2066 2008 1047 1012 102 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] world wrestling entertainment will bury every woman for the nu ##m h ##w fuck this shit sl ##ive [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] world wrestling entertainment will bury every woman for the nu ##m h ##w fuck this shit sl ##ive [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2088 4843 4024 2097 11010 2296 2450 2005 1996 16371 2213 1044 2860 6616 2023 4485 22889 3512 102 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2088 4843 4024 2097 11010 2296 2450 2005 1996 16371 2213 1044 2860 6616 2023 4485 22889 3512 102 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user user but we know better than that he is an evil man and a traitor [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user user but we know better than that he is an evil man and a traitor [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 5310 2021 2057 2113 2488 2084 2008 2002 2003 2019 4763 2158 1998 1037 17328 102 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 5310 2021 2057 2113 2488 2084 2008 2002 2003 2019 4763 2158 1998 1037 17328 102 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user how am i stupid over nu ##m to try it out [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] user user how am i stupid over nu ##m to try it out [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 2129 2572 1045 5236 2058 16371 2213 2000 3046 2009 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5310 5310 2129 2572 1045 5236 2058 16371 2213 2000 3046 2009 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i appreciate my little ass though it be moving [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i appreciate my little ass though it be moving [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 9120 2026 2210 4632 2295 2009 2022 3048 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 9120 2026 2210 4632 2295 2009 2022 3048 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 18898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 18898\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 30\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgqHGyjZRmbW"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6eqTKebUe9F"
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        #accuracy_15=tf.keras.metrics.top_k_categorical_accuracy(label_ids,predicted_labels,k=15)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "           # \"accuracy_15\":accuracy_15,\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KX60Klt3VC-H"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2zkIZ30VExM"
   },
   "outputs": [],
   "source": [
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTHGDE0lVGOX"
   },
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fK0iJUilVOcT",
    "outputId": "e2b97a02-efaf-44c9-f24f-ac802d8034ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "qCUE5hl_VQQZ",
    "outputId": "4860d93b-2e06-4ab5-c963-26b39df74068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '\"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1396c5898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '\"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1396c5898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyRr4UowVSrb"
   },
   "outputs": [],
   "source": [
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oyImkCFIVVRS",
    "outputId": "e7426d64-32fb-49f6-d9e7-2d7e081ec09d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45777377, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45777377, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.15687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.15687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7839395, step = 100 (46.365 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7839395, step = 100 (46.365 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3371257, step = 200 (28.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3371257, step = 200 (28.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2291627, step = 300 (28.314 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2291627, step = 300 (28.314 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37154636, step = 400 (28.363 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37154636, step = 400 (28.363 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.89592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.89592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4478604, step = 500 (34.532 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4478604, step = 500 (34.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33992502, step = 600 (28.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33992502, step = 600 (28.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.31526846, step = 700 (28.286 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.31526846, step = 700 (28.286 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.55771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.55771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40005714, step = 800 (28.108 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40005714, step = 800 (28.108 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.56766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.56766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12410025, step = 900 (28.028 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12410025, step = 900 (28.028 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.89013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.89013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48309702, step = 1000 (34.600 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48309702, step = 1000 (34.600 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21701448, step = 1100 (28.420 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21701448, step = 1100 (28.420 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.578563, step = 1200 (28.451 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.578563, step = 1200 (28.451 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07910059, step = 1300 (28.362 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07910059, step = 1300 (28.362 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18125947, step = 1400 (28.428 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18125947, step = 1400 (28.428 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.9022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23387262, step = 1500 (34.456 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23387262, step = 1500 (34.456 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4373548, step = 1600 (28.385 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4373548, step = 1600 (28.385 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41614228, step = 1700 (28.314 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41614228, step = 1700 (28.314 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3844446, step = 1800 (28.406 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3844446, step = 1800 (28.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16597888, step = 1900 (28.353 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16597888, step = 1900 (28.353 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32294393, step = 2000 (34.645 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32294393, step = 2000 (34.645 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41339093, step = 2100 (28.361 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41339093, step = 2100 (28.361 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14466341, step = 2200 (28.417 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14466341, step = 2200 (28.417 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44968563, step = 2300 (28.391 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44968563, step = 2300 (28.391 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22826198, step = 2400 (28.392 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22826198, step = 2400 (28.392 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27306917, step = 2500 (34.778 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27306917, step = 2500 (34.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17359766, step = 2600 (28.466 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17359766, step = 2600 (28.466 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22909625, step = 2700 (28.378 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22909625, step = 2700 (28.378 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.034954503, step = 2800 (28.406 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.034954503, step = 2800 (28.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21352942, step = 2900 (28.422 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21352942, step = 2900 (28.422 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.06643586, step = 3000 (34.768 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.06643586, step = 3000 (34.768 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.044658925, step = 3100 (28.403 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.044658925, step = 3100 (28.403 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5258404, step = 3200 (28.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5258404, step = 3200 (28.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11636345, step = 3300 (28.407 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11636345, step = 3300 (28.407 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38615647, step = 3400 (28.438 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38615647, step = 3400 (28.438 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1865995, step = 3500 (34.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1865995, step = 3500 (34.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38317394, step = 3600 (28.453 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38317394, step = 3600 (28.453 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3332913, step = 3700 (28.356 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3332913, step = 3700 (28.356 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03386665, step = 3800 (28.374 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03386665, step = 3800 (28.374 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23405004, step = 3900 (28.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23405004, step = 3900 (28.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40378818, step = 4000 (34.608 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40378818, step = 4000 (34.608 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50142264, step = 4100 (28.402 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50142264, step = 4100 (28.402 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24540813, step = 4200 (28.391 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24540813, step = 4200 (28.391 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7213321, step = 4300 (28.366 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7213321, step = 4300 (28.366 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8869993, step = 4400 (28.401 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8869993, step = 4400 (28.401 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.041478537, step = 4500 (34.506 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.041478537, step = 4500 (34.506 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24045451, step = 4600 (28.387 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24045451, step = 4600 (28.387 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1756029, step = 4700 (28.402 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1756029, step = 4700 (28.402 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04392404, step = 4800 (28.393 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04392404, step = 4800 (28.393 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26226336, step = 4900 (28.390 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26226336, step = 4900 (28.390 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39451858, step = 5000 (34.729 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39451858, step = 5000 (34.729 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2574426, step = 5100 (28.414 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2574426, step = 5100 (28.414 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40817875, step = 5200 (28.390 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40817875, step = 5200 (28.390 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6258195, step = 5300 (28.429 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6258195, step = 5300 (28.429 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.52585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43936443, step = 5400 (28.362 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43936443, step = 5400 (28.362 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019987356, step = 5500 (34.760 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019987356, step = 5500 (34.760 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4775029, step = 5600 (28.422 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4775029, step = 5600 (28.422 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.012716949, step = 5700 (28.458 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.012716949, step = 5700 (28.458 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5375285, step = 5800 (28.447 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5375285, step = 5800 (28.447 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5148174, step = 5900 (28.469 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5148174, step = 5900 (28.469 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.85791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.85791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01575112, step = 6000 (34.990 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01575112, step = 6000 (34.990 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38573354, step = 6100 (28.471 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38573354, step = 6100 (28.471 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.25201735, step = 6200 (28.460 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.25201735, step = 6200 (28.460 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.091483064, step = 6300 (28.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.091483064, step = 6300 (28.450 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43730322, step = 6400 (28.421 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43730322, step = 6400 (28.421 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17616506, step = 6500 (34.802 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17616506, step = 6500 (34.802 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2067951, step = 6600 (28.436 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2067951, step = 6600 (28.436 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32578233, step = 6700 (28.449 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32578233, step = 6700 (28.449 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08392552, step = 6800 (28.472 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08392552, step = 6800 (28.472 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22883156, step = 6900 (28.458 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22883156, step = 6900 (28.458 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.88135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39048845, step = 7000 (34.707 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39048845, step = 7000 (34.707 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0073098885, step = 7100 (28.464 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0073098885, step = 7100 (28.464 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32723165, step = 7200 (28.433 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32723165, step = 7200 (28.433 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3964042, step = 7300 (28.460 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3964042, step = 7300 (28.460 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.056031562, step = 7400 (28.423 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.056031562, step = 7400 (28.423 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5697323, step = 7500 (34.789 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5697323, step = 7500 (34.789 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01583087, step = 7600 (28.470 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.01583087, step = 7600 (28.470 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74531925, step = 7700 (28.495 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74531925, step = 7700 (28.495 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13856475, step = 7800 (28.454 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13856475, step = 7800 (28.454 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.65086377, step = 7900 (28.456 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.65086377, step = 7900 (28.456 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3804911, step = 8000 (34.769 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3804911, step = 8000 (34.769 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28842476, step = 8100 (28.525 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28842476, step = 8100 (28.525 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42925358, step = 8200 (28.509 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42925358, step = 8200 (28.509 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.64525473, step = 8300 (28.533 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.64525473, step = 8300 (28.533 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13094154, step = 8400 (28.477 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13094154, step = 8400 (28.477 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.86535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.86535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03556801, step = 8500 (34.899 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.03556801, step = 8500 (34.899 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14673617, step = 8600 (28.501 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14673617, step = 8600 (28.501 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26563206, step = 8700 (28.531 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26563206, step = 8700 (28.531 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50155246, step = 8800 (28.514 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50155246, step = 8800 (28.514 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22820279, step = 8900 (28.546 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22820279, step = 8900 (28.546 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6582043, step = 9000 (34.818 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6582043, step = 9000 (34.818 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12915948, step = 9100 (28.558 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12915948, step = 9100 (28.558 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16432968, step = 9200 (28.546 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16432968, step = 9200 (28.546 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.49926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.49926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.021872187, step = 9300 (28.577 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.021872187, step = 9300 (28.577 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2191647, step = 9400 (28.481 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2191647, step = 9400 (28.481 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9500 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.038338535, step = 9500 (34.779 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.038338535, step = 9500 (34.779 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.024471661, step = 9600 (28.520 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.024471661, step = 9600 (28.520 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.30636305, step = 9700 (28.516 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.30636305, step = 9700 (28.516 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.50879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10516729, step = 9800 (28.499 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10516729, step = 9800 (28.499 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2596506, step = 9900 (28.460 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2596506, step = 9900 (28.460 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10000 into \"/content/gdrive/My Drive/offenseval/Bert/checkpoints/\"/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.90318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.90318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8069475, step = 10000 (34.445 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8069475, step = 10000 (34.445 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24198261, step = 10100 (28.432 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24198261, step = 10100 (28.432 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.51868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60407174, step = 10200 (28.420 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60407174, step = 10200 (28.420 sec)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUG8SQLoVgDa"
   },
   "outputs": [],
   "source": [
    "EVAL_BATCH_SIZE=10\n",
    "eval_steps = int(len(test_features) / EVAL_BATCH_SIZE)\n",
    "eval_input_fn = run_classifier.input_fn_builder(\n",
    "      features=test_features,\n",
    "      seq_length=MAX_SEQ_LENGTH,\n",
    "      is_training=False,\n",
    "      drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRKRfWs_WEKx"
   },
   "outputs": [],
   "source": [
    "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SF6uN5Njsjp8"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "offens_task2_bilstm_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
